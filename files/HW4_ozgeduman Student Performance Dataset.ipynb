{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset-2 Student Performance Data Set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In this homework, subject of mathematics are used. There is one target attribute \"G3\", which shows the final grades of student. In the dataset, there are also midterm grades (G1 and G2). Since it is more difficult to predict G3 without G2 and G1, G2 and G1 are deleted from dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets:\n",
    "1 school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\n",
    "2 sex - student's sex (binary: 'F' - female or 'M' - male)\n",
    "3 age - student's age (numeric: from 15 to 22)\n",
    "4 address - student's home address type (binary: 'U' - urban or 'R' - rural)\n",
    "5 famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n",
    "6 Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)\n",
    "7 Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 “ 5th to 9th grade, 3 â€“ secondary education or 4 “ higher education)\n",
    "8 Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 “ 5th to 9th grade, 3 “ secondary education or 4 â€“ higher education)\n",
    "9 Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "10 Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "11 reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n",
    "12 guardian - student's guardian (nominal: 'mother', 'father' or 'other')\n",
    "13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "16 schoolsup - extra educational support (binary: yes or no)\n",
    "17 famsup - family educational support (binary: yes or no)\n",
    "18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "19 activities - extra-curricular activities (binary: yes or no)\n",
    "20 nursery - attended nursery school (binary: yes or no)\n",
    "21 higher - wants to take higher education (binary: yes or no)\n",
    "22 internet - Internet access at home (binary: yes or no)\n",
    "23 romantic - with a romantic relationship (binary: yes or no)\n",
    "24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "29 health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "30 absences - number of school absences (numeric: from 0 to 93)\n",
    "31 G1 - first period grade (numeric: from 0 to 20)\n",
    "31 G2 - second period grade (numeric: from 0 to 20)\n",
    "32 G3 - final grade (numeric: from 0 to 20, output target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used libraries\n",
    "library(data.table)\n",
    "library(Matrix)\n",
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(glmnet)\n",
    "library(caret)\n",
    "library(data.table)\n",
    "require(lubridate)\n",
    "library(forecast)\n",
    "library(e1071)\n",
    "library(rpart)\n",
    "require(data.table)\n",
    "require(lubridate)\n",
    "require(caret)\n",
    "library(gbm)\n",
    "library(rpart.plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading dataset\n",
    "data_set1 = read.csv(file=\"C:/Users/OZGE/OneDrive - boun.edu.tr/doktora_ders/IE582/HW4/student/student-mat.csv\",header = TRUE, sep = \";\")\n",
    "data_set1 = as.data.frame(data_set1)\n",
    "size_set1 = nrow(data_set1)\n",
    "column_set1 =ncol(data_set1)\n",
    "#training size determined as 0.70*dataset size\n",
    "train_size1 = size_set1*0.70\n",
    "#G1=MT1 notes G2=MT2 notes G3= Final notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating training set and testing set\n",
    "train_set1 = matrix(0,train_size1,column_set1)\n",
    "test_set1 = matrix(0,(size_set1-train_size1+1),column_set1)\n",
    "train_set1 = data_set1[1:train_size1,1:column_set1]\n",
    "test_set1 = data_set1[(train_size1):size_set1,1:column_set1]\n",
    "class_1_test = test_set1[,33]\n",
    "class_1_train = train_set1[,33]\n",
    "train_set1 =train_set1[,1:(column_set1-3)]\n",
    "test_set1 =test_set1[,1:(column_set1-3)]\n",
    "train_set1 =cbind(train_set1,class_1_train)\n",
    "test_set1 =cbind(test_set1,class_1_test)\n",
    "colnames(test_set1)[31] = 'Final_note'\n",
    "colnames(train_set1)[31] = 'Final_note'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1 - Lasso Regression\n",
    "#lambda is determined between 0.00001 and 0.001 with 6 values\n",
    "lambda_seq = c(seq(0.00001,0.001,length=6))\n",
    "train_set1=data.frame(train_set1)\n",
    "set.seed(1)\n",
    "n_repeats=5\n",
    "n_folds=10\n",
    "lasso_grid = expand.grid(alpha=1,lambda=lambda_seq)\n",
    "Control=trainControl(method = \"repeatedcv\",\n",
    "                           number = n_folds,\n",
    "                           repeats = n_repeats)                         \n",
    "lassolr_fit = train(Final_note~ .,data=train_set1,\n",
    "                family = \"gaussian\",\n",
    "                 method = \"glmnet\", \n",
    "                 tuneGrid = lasso_grid,\n",
    "                 trControl = Control) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Length Class      Mode     \n",
       "a0            75   -none-     numeric  \n",
       "beta        2925   dgCMatrix  S4       \n",
       "df            75   -none-     numeric  \n",
       "dim            2   -none-     numeric  \n",
       "lambda        75   -none-     numeric  \n",
       "dev.ratio     75   -none-     numeric  \n",
       "nulldev        1   -none-     numeric  \n",
       "npasses        1   -none-     numeric  \n",
       "jerr           1   -none-     numeric  \n",
       "offset         1   -none-     logical  \n",
       "call           5   -none-     call     \n",
       "nobs           1   -none-     numeric  \n",
       "lambdaOpt      1   -none-     numeric  \n",
       "xNames        39   -none-     character\n",
       "problemType    1   -none-     character\n",
       "tuneValue      2   data.frame list     \n",
       "obsLevels      1   -none-     logical  \n",
       "param          1   -none-     list     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "glmnet \n",
       "\n",
       "276 samples\n",
       " 30 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 249, 250, 248, 248, 248, 248, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  lambda    RMSE      Rsquared   MAE     \n",
       "  0.000010  4.322159  0.1850155  3.372441\n",
       "  0.000208  4.322159  0.1850155  3.372441\n",
       "  0.000406  4.322159  0.1850155  3.372441\n",
       "  0.000604  4.322159  0.1850155  3.372441\n",
       "  0.000802  4.322159  0.1850155  3.372441\n",
       "  0.001000  4.322159  0.1850155  3.372441\n",
       "\n",
       "Tuning parameter 'alpha' was held constant at a value of 1\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were alpha = 1 and lambda = 0.001."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lassolr_fit)\n",
    "lassolr_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse of lasso model at alpha = 1 and lambda = 0.001\n",
    "model_lasso_rmse = 4.322159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction with lasso\n",
    "predict_lasso = predict(lassolr_fit, test_set1 )\n",
    "#RMSE calculation between prediction and test data\n",
    "model_predict_comp_lasso=sqrt(mean((test_set1$Final_note - predict_lasso)^2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_lasso = c()\n",
    "comp_lasso[1] = as.numeric(model_lasso_rmse)\n",
    "comp_lasso[2]= as.numeric(model_predict_comp_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2- Decision Tree\n",
    "set.seed(1)\n",
    "n_repeats=5\n",
    "n_folds=10\n",
    "Control=trainControl(method = \"repeatedcv\",\n",
    "                           number = n_folds,\n",
    "                           repeats = n_repeats)\n",
    "#complexity parameter is selected as 0.01, 0.02, 0.03\n",
    "grid_tree = expand.grid(cp=c(0.01, 0.02, 0.03))\n",
    "#Three different model is trained with different minbucket values\n",
    "tree_fit_minbucket7 = train(Final_note~ .,data=train_set1,\n",
    "                 method = \"rpart\", \n",
    "                 trControl = Control,\n",
    "                control = rpart.control(minbucket=7),\n",
    "                tuneGrid = grid_tree)\n",
    "tree_fit_minbucket10 = train(Final_note~ .,data=train_set1,\n",
    "                 method = \"rpart\", \n",
    "                 trControl = Control,\n",
    "                control = rpart.control(minbucket=10),\n",
    "                            tuneGrid = grid_tree)\n",
    "tree_fit_minbucket5 = train(Final_note~ .,data=train_set1,\n",
    "                 method = \"rpart\", \n",
    "                 trControl = Control,\n",
    "                control = rpart.control(minbucket=5),\n",
    "                tuneGrid = grid_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results @ minbucket=7"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "276 samples\n",
       " 30 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 249, 250, 248, 248, 248, 248, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp    RMSE      Rsquared   MAE     \n",
       "  0.01  4.373848  0.1919859  3.322877\n",
       "  0.02  4.229556  0.2072084  3.195830\n",
       "  0.03  4.274138  0.1760222  3.231596\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 0.02."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results @ minbucket=5"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "276 samples\n",
       " 30 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 250, 247, 247, 250, 249, 248, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp    RMSE      Rsquared   MAE     \n",
       "  0.01  4.333945  0.1932356  3.267346\n",
       "  0.02  4.234260  0.1985996  3.206042\n",
       "  0.03  4.246514  0.1825829  3.238410\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 0.02."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results @ minbucket=10"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "276 samples\n",
       " 30 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 247, 250, 248, 246, 248, 248, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp    RMSE      Rsquared   MAE     \n",
       "  0.01  4.362598  0.1869901  3.400193\n",
       "  0.02  4.345717  0.1753893  3.368365\n",
       "  0.03  4.351829  0.1655460  3.367102\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 0.02."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat(\"Decision Tree Results @ minbucket=7\")\n",
    "tree_fit_minbucket7\n",
    "cat(\"Decision Tree Results @ minbucket=5\")\n",
    "tree_fit_minbucket5\n",
    "cat(\"Decision Tree Results @ minbucket=10\")\n",
    "tree_fit_minbucket10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE of decision tree at cp = 0.02 and minbucket=5\n",
    "model_tree_rmse = 4.234260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC2VBMVEUAAAAgNEEoOUIrR1cw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\nCCBBUAUCSBBUgQASBFUggARBFej/A/KEiPqu/nx+AAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpart.plot(tree_fit_minbucket5$finalModel, box.palette=\"RdBu\", shadow.col=\"gray\", nn=TRUE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with decision tree \n",
    "#RMSE is lowest when minbucket is equal to 5 \n",
    "predict_tree = predict(tree_fit_minbucket5, test_set1 )\n",
    "#RMSE calculation between prediction and test data\n",
    "model_predict_comp_tree=sqrt(mean((test_set1$Final_note - predict_tree)^2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_tree = c()\n",
    "comp_tree[1] = as.numeric(model_tree_rmse)\n",
    "comp_tree[2]= as.numeric(model_predict_comp_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Random Forest\n",
    "set.seed(1)\n",
    "n_folds=10\n",
    "Control=trainControl(method = \"cv\",\n",
    "                           number = n_folds)  \n",
    "#the minimal number of observations per tree leaf is determined with different values.\n",
    "#Normally, it is set to 5\n",
    "grid_random_forest <- expand.grid(mtry = c(1,5,9,11,15)) \n",
    "\n",
    "rf_fit = train(Final_note~ .,data=train_set1,\n",
    "                 method = \"rf\", \n",
    "                 ntree=500,\n",
    "                 nodesize=5,\n",
    "                 trControl = Control,\n",
    "                 tuneGrid = grid_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest \n",
       "\n",
       "276 samples\n",
       " 30 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 249, 250, 248, 248, 248, 248, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  mtry  RMSE      Rsquared   MAE     \n",
       "   1    4.247122  0.2641487  3.259941\n",
       "   5    3.936576  0.2913484  3.072648\n",
       "   9    3.890046  0.2962361  3.035218\n",
       "  11    3.865458  0.3026115  3.009106\n",
       "  15    3.843573  0.3046491  2.985793\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was mtry = 15."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAgP9NTU1oaGh8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\nSICQgAQICUiAkIAECAlIgJCABAgJSOB/fJgc9JHDHrYAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_fit\n",
    "plot(rf_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE of random forest at mtry=15\n",
    "model_forest_rmse = 3.843573"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction by using random forests method\n",
    "predict_forest = predict(rf_fit, test_set1 )\n",
    "#RMSE calculation between prediction and test data\n",
    "model_predict_comp_forest=sqrt(mean((test_set1$Final_note - predict_forest)^2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_forest = c()\n",
    "comp_forest[1] = as.numeric(model_forest_rmse)\n",
    "comp_forest[2]= as.numeric(model_predict_comp_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.9538             nan     0.0010    0.0055\n",
      "     2       21.9474             nan     0.0010    0.0060\n",
      "     3       21.9393             nan     0.0010    0.0059\n",
      "     4       21.9328             nan     0.0010    0.0068\n",
      "     5       21.9266             nan     0.0010    0.0057\n",
      "     6       21.9195             nan     0.0010    0.0044\n",
      "     7       21.9109             nan     0.0010    0.0057\n",
      "     8       21.9054             nan     0.0010    0.0065\n",
      "     9       21.8999             nan     0.0010    0.0057\n",
      "    10       21.8916             nan     0.0010    0.0049\n",
      "    20       21.8271             nan     0.0010    0.0060\n",
      "    40       21.6952             nan     0.0010   -0.0001\n",
      "    60       21.5750             nan     0.0010    0.0035\n",
      "    80       21.4550             nan     0.0010    0.0051\n",
      "   100       21.3521             nan     0.0010    0.0011\n",
      "   120       21.2442             nan     0.0010    0.0034\n",
      "   140       21.1341             nan     0.0010    0.0041\n",
      "   160       21.0261             nan     0.0010    0.0051\n",
      "   180       20.9140             nan     0.0010    0.0044\n",
      "   200       20.8222             nan     0.0010    0.0047\n",
      "   220       20.7322             nan     0.0010    0.0028\n",
      "   240       20.6405             nan     0.0010    0.0053\n",
      "   260       20.5446             nan     0.0010    0.0016\n",
      "   280       20.4493             nan     0.0010    0.0034\n",
      "   300       20.3653             nan     0.0010    0.0033\n",
      "   320       20.2746             nan     0.0010    0.0033\n",
      "   340       20.1888             nan     0.0010    0.0029\n",
      "   360       20.1121             nan     0.0010    0.0025\n",
      "   380       20.0286             nan     0.0010    0.0025\n",
      "   400       19.9567             nan     0.0010    0.0038\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.9507             nan     0.0010    0.0071\n",
      "     2       21.9385             nan     0.0010    0.0076\n",
      "     3       21.9296             nan     0.0010    0.0068\n",
      "     4       21.9189             nan     0.0010    0.0083\n",
      "     5       21.9039             nan     0.0010    0.0088\n",
      "     6       21.8950             nan     0.0010    0.0047\n",
      "     7       21.8854             nan     0.0010    0.0080\n",
      "     8       21.8756             nan     0.0010    0.0090\n",
      "     9       21.8654             nan     0.0010    0.0055\n",
      "    10       21.8513             nan     0.0010    0.0059\n",
      "    20       21.7485             nan     0.0010    0.0099\n",
      "    40       21.5462             nan     0.0010    0.0099\n",
      "    60       21.3426             nan     0.0010    0.0074\n",
      "    80       21.1652             nan     0.0010    0.0050\n",
      "   100       21.0015             nan     0.0010    0.0055\n",
      "   120       20.8262             nan     0.0010    0.0082\n",
      "   140       20.6519             nan     0.0010    0.0072\n",
      "   160       20.4745             nan     0.0010    0.0014\n",
      "   180       20.3115             nan     0.0010    0.0050\n",
      "   200       20.1415             nan     0.0010    0.0075\n",
      "   220       19.9800             nan     0.0010    0.0039\n",
      "   240       19.8234             nan     0.0010    0.0066\n",
      "   260       19.6790             nan     0.0010    0.0002\n",
      "   280       19.5357             nan     0.0010    0.0043\n",
      "   300       19.3981             nan     0.0010    0.0029\n",
      "   320       19.2439             nan     0.0010    0.0065\n",
      "   340       19.1122             nan     0.0010    0.0050\n",
      "   360       18.9804             nan     0.0010    0.0021\n",
      "   380       18.8406             nan     0.0010    0.0045\n",
      "   400       18.7041             nan     0.0010    0.0054\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.9496             nan     0.0010    0.0073\n",
      "     2       21.9376             nan     0.0010    0.0094\n",
      "     3       21.9244             nan     0.0010    0.0064\n",
      "     4       21.9143             nan     0.0010    0.0086\n",
      "     5       21.9018             nan     0.0010    0.0093\n",
      "     6       21.8888             nan     0.0010    0.0084\n",
      "     7       21.8757             nan     0.0010    0.0085\n",
      "     8       21.8624             nan     0.0010    0.0073\n",
      "     9       21.8498             nan     0.0010    0.0108\n",
      "    10       21.8383             nan     0.0010    0.0057\n",
      "    20       21.7062             nan     0.0010    0.0091\n",
      "    40       21.4683             nan     0.0010    0.0037\n",
      "    60       21.2313             nan     0.0010    0.0054\n",
      "    80       20.9914             nan     0.0010    0.0082\n",
      "   100       20.7674             nan     0.0010    0.0059\n",
      "   120       20.5613             nan     0.0010    0.0080\n",
      "   140       20.3313             nan     0.0010    0.0085\n",
      "   160       20.1347             nan     0.0010    0.0072\n",
      "   180       19.9366             nan     0.0010    0.0048\n",
      "   200       19.7407             nan     0.0010    0.0057\n",
      "   220       19.5653             nan     0.0010    0.0047\n",
      "   240       19.3832             nan     0.0010    0.0064\n",
      "   260       19.2046             nan     0.0010    0.0049\n",
      "   280       19.0290             nan     0.0010    0.0036\n",
      "   300       18.8586             nan     0.0010    0.0053\n",
      "   320       18.6850             nan     0.0010    0.0070\n",
      "   340       18.5205             nan     0.0010    0.0051\n",
      "   360       18.3467             nan     0.0010    0.0046\n",
      "   380       18.1923             nan     0.0010    0.0055\n",
      "   400       18.0366             nan     0.0010    0.0049\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.8744             nan     0.0100    0.0811\n",
      "     2       21.7955             nan     0.0100    0.0543\n",
      "     3       21.7262             nan     0.0100    0.0546\n",
      "     4       21.6440             nan     0.0100    0.0517\n",
      "     5       21.6284             nan     0.0100    0.0019\n",
      "     6       21.5663             nan     0.0100    0.0542\n",
      "     7       21.5156             nan     0.0100    0.0552\n",
      "     8       21.4566             nan     0.0100    0.0221\n",
      "     9       21.4129             nan     0.0100    0.0544\n",
      "    10       21.3552             nan     0.0100    0.0385\n",
      "    20       20.8834             nan     0.0100    0.0495\n",
      "    40       19.9736             nan     0.0100    0.0317\n",
      "    60       19.2762             nan     0.0100    0.0239\n",
      "    80       18.7389             nan     0.0100    0.0027\n",
      "   100       18.2569             nan     0.0100    0.0151\n",
      "   120       17.8004             nan     0.0100    0.0140\n",
      "   140       17.4441             nan     0.0100    0.0093\n",
      "   160       17.1327             nan     0.0100   -0.0076\n",
      "   180       16.8209             nan     0.0100   -0.0150\n",
      "   200       16.5548             nan     0.0100    0.0032\n",
      "   220       16.3147             nan     0.0100    0.0024\n",
      "   240       16.0915             nan     0.0100   -0.0012\n",
      "   260       15.8806             nan     0.0100   -0.0023\n",
      "   280       15.7050             nan     0.0100    0.0003\n",
      "   300       15.5294             nan     0.0100    0.0001\n",
      "   320       15.3701             nan     0.0100   -0.0058\n",
      "   340       15.2181             nan     0.0100   -0.0074\n",
      "   360       15.0633             nan     0.0100   -0.0016\n",
      "   380       14.9262             nan     0.0100   -0.0054\n",
      "   400       14.8129             nan     0.0100   -0.0074\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.8661             nan     0.0100    0.0863\n",
      "     2       21.7786             nan     0.0100    0.0580\n",
      "     3       21.6865             nan     0.0100    0.0684\n",
      "     4       21.5965             nan     0.0100    0.0718\n",
      "     5       21.4954             nan     0.0100    0.1047\n",
      "     6       21.3892             nan     0.0100    0.0797\n",
      "     7       21.3006             nan     0.0100    0.0631\n",
      "     8       21.1943             nan     0.0100    0.0892\n",
      "     9       21.0949             nan     0.0100    0.0727\n",
      "    10       20.9992             nan     0.0100    0.0119\n",
      "    20       20.2001             nan     0.0100    0.0392\n",
      "    40       18.7332             nan     0.0100    0.0521\n",
      "    60       17.4783             nan     0.0100    0.0203\n",
      "    80       16.4838             nan     0.0100    0.0027\n",
      "   100       15.6219             nan     0.0100    0.0494\n",
      "   120       14.9329             nan     0.0100    0.0201\n",
      "   140       14.3021             nan     0.0100    0.0215\n",
      "   160       13.7801             nan     0.0100   -0.0036\n",
      "   180       13.3072             nan     0.0100   -0.0011\n",
      "   200       12.8943             nan     0.0100   -0.0027\n",
      "   220       12.5354             nan     0.0100    0.0025\n",
      "   240       12.1964             nan     0.0100   -0.0068\n",
      "   260       11.8993             nan     0.0100   -0.0014\n",
      "   280       11.6135             nan     0.0100   -0.0139\n",
      "   300       11.3440             nan     0.0100    0.0032\n",
      "   320       11.1234             nan     0.0100   -0.0046\n",
      "   340       10.9080             nan     0.0100   -0.0027\n",
      "   360       10.7163             nan     0.0100   -0.0093\n",
      "   380       10.5019             nan     0.0100   -0.0060\n",
      "   400       10.3365             nan     0.0100   -0.0093\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.8516             nan     0.0100    0.0585\n",
      "     2       21.7320             nan     0.0100    0.0586\n",
      "     3       21.6248             nan     0.0100    0.0523\n",
      "     4       21.5000             nan     0.0100    0.0970\n",
      "     5       21.3938             nan     0.0100    0.0556\n",
      "     6       21.2769             nan     0.0100    0.0785\n",
      "     7       21.1697             nan     0.0100    0.0844\n",
      "     8       21.0347             nan     0.0100    0.0921\n",
      "     9       20.9015             nan     0.0100    0.0674\n",
      "    10       20.7907             nan     0.0100    0.0733\n",
      "    20       19.7856             nan     0.0100    0.0866\n",
      "    40       18.0975             nan     0.0100    0.0454\n",
      "    60       16.6493             nan     0.0100    0.0337\n",
      "    80       15.4430             nan     0.0100    0.0225\n",
      "   100       14.4722             nan     0.0100    0.0025\n",
      "   120       13.6055             nan     0.0100   -0.0171\n",
      "   140       12.8943             nan     0.0100    0.0133\n",
      "   160       12.2593             nan     0.0100    0.0107\n",
      "   180       11.7066             nan     0.0100    0.0011\n",
      "   200       11.2283             nan     0.0100   -0.0083\n",
      "   220       10.7858             nan     0.0100   -0.0223\n",
      "   240       10.4063             nan     0.0100   -0.0132\n",
      "   260       10.0745             nan     0.0100   -0.0078\n",
      "   280        9.7834             nan     0.0100    0.0035\n",
      "   300        9.5133             nan     0.0100   -0.0018\n",
      "   320        9.2615             nan     0.0100   -0.0009\n",
      "   340        9.0375             nan     0.0100   -0.0003\n",
      "   360        8.8037             nan     0.0100   -0.0068\n",
      "   380        8.5958             nan     0.0100    0.0000\n",
      "   400        8.3871             nan     0.0100   -0.0037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.2971             nan     0.1000    0.6486\n",
      "     2       20.8204             nan     0.1000    0.3223\n",
      "     3       20.6866             nan     0.1000   -0.0051\n",
      "     4       20.0739             nan     0.1000    0.5295\n",
      "     5       19.6369             nan     0.1000    0.4038\n",
      "     6       19.3019             nan     0.1000    0.1559\n",
      "     7       18.8984             nan     0.1000    0.2404\n",
      "     8       18.5189             nan     0.1000    0.2207\n",
      "     9       18.2997             nan     0.1000    0.1111\n",
      "    10       18.0433             nan     0.1000    0.0595\n",
      "    20       16.4854             nan     0.1000    0.0464\n",
      "    40       14.8571             nan     0.1000   -0.0538\n",
      "    60       13.8533             nan     0.1000    0.0363\n",
      "    80       13.1979             nan     0.1000   -0.1147\n",
      "   100       12.7383             nan     0.1000   -0.0718\n",
      "   120       12.4250             nan     0.1000   -0.0885\n",
      "   140       12.1823             nan     0.1000   -0.0994\n",
      "   160       11.9361             nan     0.1000   -0.0529\n",
      "   180       11.7669             nan     0.1000   -0.0045\n",
      "   200       11.6167             nan     0.1000   -0.0861\n",
      "   220       11.4849             nan     0.1000   -0.0760\n",
      "   240       11.4136             nan     0.1000   -0.0724\n",
      "   260       11.3674             nan     0.1000   -0.1096\n",
      "   280       11.2782             nan     0.1000   -0.0675\n",
      "   300       11.2199             nan     0.1000   -0.0684\n",
      "   320       11.1621             nan     0.1000   -0.1002\n",
      "   340       11.1110             nan     0.1000   -0.0846\n",
      "   360       11.0601             nan     0.1000   -0.0704\n",
      "   380       10.9731             nan     0.1000   -0.0330\n",
      "   400       10.9149             nan     0.1000   -0.0401\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.0678             nan     0.1000    0.7288\n",
      "     2       20.0685             nan     0.1000    0.6577\n",
      "     3       19.4260             nan     0.1000    0.3181\n",
      "     4       18.5511             nan     0.1000    0.5923\n",
      "     5       17.9762             nan     0.1000    0.5493\n",
      "     6       17.5547             nan     0.1000    0.2684\n",
      "     7       17.1741             nan     0.1000    0.1638\n",
      "     8       16.7016             nan     0.1000    0.3848\n",
      "     9       16.2724             nan     0.1000    0.1023\n",
      "    10       15.5769             nan     0.1000    0.2658\n",
      "    20       12.8382             nan     0.1000   -0.0892\n",
      "    40       10.3522             nan     0.1000   -0.1189\n",
      "    60        9.1629             nan     0.1000   -0.0457\n",
      "    80        8.2447             nan     0.1000   -0.0789\n",
      "   100        7.6208             nan     0.1000   -0.1211\n",
      "   120        6.9396             nan     0.1000   -0.0654\n",
      "   140        6.3327             nan     0.1000   -0.0129\n",
      "   160        5.9291             nan     0.1000   -0.0890\n",
      "   180        5.5192             nan     0.1000   -0.0811\n",
      "   200        5.2898             nan     0.1000   -0.0556\n",
      "   220        4.9564             nan     0.1000   -0.0269\n",
      "   240        4.6789             nan     0.1000   -0.0751\n",
      "   260        4.4545             nan     0.1000   -0.0666\n",
      "   280        4.1669             nan     0.1000   -0.0516\n",
      "   300        3.9989             nan     0.1000   -0.0449\n",
      "   320        3.7790             nan     0.1000   -0.0693\n",
      "   340        3.5495             nan     0.1000   -0.0327\n",
      "   360        3.3344             nan     0.1000   -0.0384\n",
      "   380        3.1570             nan     0.1000   -0.0148\n",
      "   400        3.0164             nan     0.1000   -0.0292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.2986             nan     0.1000    0.1836\n",
      "     2       20.6672             nan     0.1000    0.0531\n",
      "     3       19.6058             nan     0.1000    0.8750\n",
      "     4       18.3988             nan     0.1000    0.9680\n",
      "     5       17.6564             nan     0.1000    0.6654\n",
      "     6       17.0512             nan     0.1000   -0.0625\n",
      "     7       16.3072             nan     0.1000    0.5918\n",
      "     8       15.7094             nan     0.1000    0.3230\n",
      "     9       15.2064             nan     0.1000    0.1981\n",
      "    10       14.7863             nan     0.1000    0.1645\n",
      "    20       11.6119             nan     0.1000    0.1224\n",
      "    40        8.6092             nan     0.1000   -0.0267\n",
      "    60        7.1119             nan     0.1000   -0.1094\n",
      "    80        6.1708             nan     0.1000   -0.0866\n",
      "   100        5.2739             nan     0.1000   -0.0863\n",
      "   120        4.6099             nan     0.1000   -0.0875\n",
      "   140        4.0251             nan     0.1000   -0.0555\n",
      "   160        3.5706             nan     0.1000   -0.0206\n",
      "   180        3.1246             nan     0.1000   -0.0385\n",
      "   200        2.7763             nan     0.1000   -0.0268\n",
      "   220        2.4714             nan     0.1000   -0.0584\n",
      "   240        2.2396             nan     0.1000   -0.0353\n",
      "   260        2.0578             nan     0.1000   -0.0413\n",
      "   280        1.8776             nan     0.1000   -0.0255\n",
      "   300        1.6854             nan     0.1000   -0.0346\n",
      "   320        1.5367             nan     0.1000   -0.0103\n",
      "   340        1.4275             nan     0.1000   -0.0170\n",
      "   360        1.3342             nan     0.1000   -0.0254\n",
      "   380        1.2121             nan     0.1000   -0.0184\n",
      "   400        1.1005             nan     0.1000   -0.0185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.2048             nan     0.0010    0.0090\n",
      "     2       20.1967             nan     0.0010    0.0090\n",
      "     3       20.1896             nan     0.0010    0.0076\n",
      "     4       20.1818             nan     0.0010    0.0067\n",
      "     5       20.1744             nan     0.0010    0.0063\n",
      "     6       20.1653             nan     0.0010    0.0091\n",
      "     7       20.1583             nan     0.0010    0.0072\n",
      "     8       20.1501             nan     0.0010    0.0069\n",
      "     9       20.1424             nan     0.0010    0.0047\n",
      "    10       20.1405             nan     0.0010    0.0009\n",
      "    20       20.0717             nan     0.0010    0.0054\n",
      "    40       19.9326             nan     0.0010    0.0032\n",
      "    60       19.7998             nan     0.0010    0.0070\n",
      "    80       19.6822             nan     0.0010    0.0056\n",
      "   100       19.5709             nan     0.0010    0.0053\n",
      "   120       19.4483             nan     0.0010    0.0052\n",
      "   140       19.3341             nan     0.0010    0.0040\n",
      "   160       19.2217             nan     0.0010    0.0046\n",
      "   180       19.1248             nan     0.0010    0.0041\n",
      "   200       19.0317             nan     0.0010    0.0042\n",
      "   220       18.9366             nan     0.0010    0.0041\n",
      "   240       18.8430             nan     0.0010    0.0048\n",
      "   260       18.7542             nan     0.0010    0.0035\n",
      "   280       18.6658             nan     0.0010    0.0021\n",
      "   300       18.5803             nan     0.0010    0.0014\n",
      "   320       18.5044             nan     0.0010    0.0016\n",
      "   340       18.4283             nan     0.0010    0.0032\n",
      "   360       18.3454             nan     0.0010    0.0039\n",
      "   380       18.2718             nan     0.0010    0.0035\n",
      "   400       18.2034             nan     0.0010    0.0035\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.2072             nan     0.0010    0.0040\n",
      "     2       20.1967             nan     0.0010    0.0064\n",
      "     3       20.1853             nan     0.0010    0.0062\n",
      "     4       20.1763             nan     0.0010    0.0094\n",
      "     5       20.1671             nan     0.0010    0.0097\n",
      "     6       20.1588             nan     0.0010    0.0065\n",
      "     7       20.1508             nan     0.0010    0.0058\n",
      "     8       20.1422             nan     0.0010    0.0085\n",
      "     9       20.1323             nan     0.0010    0.0075\n",
      "    10       20.1213             nan     0.0010    0.0073\n",
      "    20       20.0294             nan     0.0010    0.0076\n",
      "    40       19.8415             nan     0.0010    0.0070\n",
      "    60       19.6585             nan     0.0010    0.0068\n",
      "    80       19.4785             nan     0.0010    0.0065\n",
      "   100       19.3154             nan     0.0010    0.0072\n",
      "   120       19.1534             nan     0.0010    0.0051\n",
      "   140       18.9987             nan     0.0010    0.0064\n",
      "   160       18.8385             nan     0.0010    0.0053\n",
      "   180       18.6837             nan     0.0010    0.0044\n",
      "   200       18.5417             nan     0.0010    0.0033\n",
      "   220       18.3901             nan     0.0010    0.0042\n",
      "   240       18.2368             nan     0.0010    0.0003\n",
      "   260       18.0937             nan     0.0010    0.0059\n",
      "   280       17.9520             nan     0.0010    0.0052\n",
      "   300       17.8241             nan     0.0010    0.0041\n",
      "   320       17.7070             nan     0.0010    0.0039\n",
      "   340       17.5865             nan     0.0010    0.0030\n",
      "   360       17.4639             nan     0.0010    0.0045\n",
      "   380       17.3497             nan     0.0010    0.0051\n",
      "   400       17.2392             nan     0.0010    0.0020\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.2035             nan     0.0010    0.0079\n",
      "     2       20.1934             nan     0.0010    0.0092\n",
      "     3       20.1827             nan     0.0010    0.0081\n",
      "     4       20.1724             nan     0.0010    0.0075\n",
      "     5       20.1591             nan     0.0010    0.0112\n",
      "     6       20.1481             nan     0.0010    0.0072\n",
      "     7       20.1395             nan     0.0010    0.0052\n",
      "     8       20.1272             nan     0.0010    0.0103\n",
      "     9       20.1172             nan     0.0010    0.0108\n",
      "    10       20.1074             nan     0.0010    0.0085\n",
      "    20       19.9953             nan     0.0010    0.0083\n",
      "    40       19.7695             nan     0.0010    0.0089\n",
      "    60       19.5561             nan     0.0010    0.0086\n",
      "    80       19.3543             nan     0.0010    0.0087\n",
      "   100       19.1433             nan     0.0010    0.0096\n",
      "   120       18.9501             nan     0.0010    0.0060\n",
      "   140       18.7655             nan     0.0010    0.0041\n",
      "   160       18.5753             nan     0.0010    0.0043\n",
      "   180       18.3872             nan     0.0010    0.0060\n",
      "   200       18.2084             nan     0.0010    0.0049\n",
      "   220       18.0328             nan     0.0010    0.0027\n",
      "   240       17.8714             nan     0.0010    0.0052\n",
      "   260       17.7111             nan     0.0010    0.0063\n",
      "   280       17.5567             nan     0.0010    0.0049\n",
      "   300       17.4035             nan     0.0010    0.0056\n",
      "   320       17.2544             nan     0.0010    0.0024\n",
      "   340       17.1047             nan     0.0010    0.0049\n",
      "   360       16.9637             nan     0.0010    0.0043\n",
      "   380       16.8195             nan     0.0010    0.0044\n",
      "   400       16.6794             nan     0.0010    0.0063\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.1274             nan     0.0100    0.0682\n",
      "     2       20.0524             nan     0.0100    0.0811\n",
      "     3       19.9644             nan     0.0100    0.0715\n",
      "     4       19.8923             nan     0.0100    0.0566\n",
      "     5       19.8219             nan     0.0100    0.0708\n",
      "     6       19.7713             nan     0.0100    0.0519\n",
      "     7       19.7001             nan     0.0100    0.0515\n",
      "     8       19.6483             nan     0.0100    0.0634\n",
      "     9       19.5851             nan     0.0100    0.0602\n",
      "    10       19.5251             nan     0.0100    0.0580\n",
      "    20       19.0358             nan     0.0100    0.0493\n",
      "    40       18.1872             nan     0.0100    0.0049\n",
      "    60       17.5865             nan     0.0100    0.0046\n",
      "    80       17.1415             nan     0.0100    0.0083\n",
      "   100       16.7044             nan     0.0100    0.0064\n",
      "   120       16.3725             nan     0.0100   -0.0067\n",
      "   140       16.0645             nan     0.0100    0.0094\n",
      "   160       15.7973             nan     0.0100    0.0066\n",
      "   180       15.5525             nan     0.0100   -0.0072\n",
      "   200       15.3181             nan     0.0100    0.0091\n",
      "   220       15.0804             nan     0.0100    0.0026\n",
      "   240       14.8935             nan     0.0100    0.0014\n",
      "   260       14.7250             nan     0.0100   -0.0069\n",
      "   280       14.5588             nan     0.0100    0.0014\n",
      "   300       14.4013             nan     0.0100   -0.0110\n",
      "   320       14.2315             nan     0.0100    0.0023\n",
      "   340       14.0780             nan     0.0100   -0.0023\n",
      "   360       13.9535             nan     0.0100   -0.0008\n",
      "   380       13.8360             nan     0.0100    0.0023\n",
      "   400       13.6914             nan     0.0100   -0.0018\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.1002             nan     0.0100    0.0640\n",
      "     2       20.0036             nan     0.0100    0.0997\n",
      "     3       19.9010             nan     0.0100    0.0832\n",
      "     4       19.7904             nan     0.0100    0.0743\n",
      "     5       19.7113             nan     0.0100    0.0795\n",
      "     6       19.6320             nan     0.0100    0.0786\n",
      "     7       19.5651             nan     0.0100    0.0561\n",
      "     8       19.4743             nan     0.0100    0.0680\n",
      "     9       19.3763             nan     0.0100    0.0317\n",
      "    10       19.2882             nan     0.0100    0.0486\n",
      "    20       18.4827             nan     0.0100    0.0483\n",
      "    40       17.2418             nan     0.0100    0.0564\n",
      "    60       16.2760             nan     0.0100    0.0260\n",
      "    80       15.4314             nan     0.0100    0.0040\n",
      "   100       14.7363             nan     0.0100   -0.0020\n",
      "   120       14.0763             nan     0.0100   -0.0026\n",
      "   140       13.5083             nan     0.0100    0.0128\n",
      "   160       13.0339             nan     0.0100    0.0012\n",
      "   180       12.6254             nan     0.0100    0.0094\n",
      "   200       12.2469             nan     0.0100   -0.0013\n",
      "   220       11.9046             nan     0.0100   -0.0124\n",
      "   240       11.5962             nan     0.0100   -0.0035\n",
      "   260       11.2919             nan     0.0100   -0.0115\n",
      "   280       11.0402             nan     0.0100   -0.0069\n",
      "   300       10.7963             nan     0.0100   -0.0162\n",
      "   320       10.5691             nan     0.0100   -0.0078\n",
      "   340       10.3665             nan     0.0100   -0.0088\n",
      "   360       10.1619             nan     0.0100   -0.0062\n",
      "   380        9.9947             nan     0.0100   -0.0101\n",
      "   400        9.8316             nan     0.0100   -0.0094\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.1116             nan     0.0100    0.0709\n",
      "     2       20.0060             nan     0.0100    0.0958\n",
      "     3       19.8888             nan     0.0100    0.0763\n",
      "     4       19.7565             nan     0.0100    0.0924\n",
      "     5       19.6239             nan     0.0100    0.0677\n",
      "     6       19.5376             nan     0.0100    0.0696\n",
      "     7       19.4256             nan     0.0100    0.0578\n",
      "     8       19.3293             nan     0.0100    0.0832\n",
      "     9       19.2482             nan     0.0100    0.0689\n",
      "    10       19.1611             nan     0.0100    0.0788\n",
      "    20       18.2744             nan     0.0100    0.0561\n",
      "    40       16.7110             nan     0.0100    0.0559\n",
      "    60       15.4296             nan     0.0100    0.0186\n",
      "    80       14.3658             nan     0.0100    0.0199\n",
      "   100       13.4924             nan     0.0100    0.0125\n",
      "   120       12.7482             nan     0.0100    0.0137\n",
      "   140       12.0229             nan     0.0100    0.0085\n",
      "   160       11.4711             nan     0.0100    0.0020\n",
      "   180       10.9670             nan     0.0100    0.0025\n",
      "   200       10.5660             nan     0.0100   -0.0029\n",
      "   220       10.1757             nan     0.0100   -0.0049\n",
      "   240        9.8347             nan     0.0100   -0.0011\n",
      "   260        9.5266             nan     0.0100    0.0031\n",
      "   280        9.2241             nan     0.0100   -0.0105\n",
      "   300        8.9709             nan     0.0100   -0.0083\n",
      "   320        8.7075             nan     0.0100   -0.0165\n",
      "   340        8.4625             nan     0.0100   -0.0118\n",
      "   360        8.2509             nan     0.0100   -0.0045\n",
      "   380        8.0389             nan     0.0100   -0.0041\n",
      "   400        7.8449             nan     0.0100   -0.0062\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.4976             nan     0.1000    0.5811\n",
      "     2       18.8591             nan     0.1000    0.6173\n",
      "     3       18.3949             nan     0.1000    0.4450\n",
      "     4       18.0331             nan     0.1000    0.2263\n",
      "     5       17.7918             nan     0.1000    0.0320\n",
      "     6       17.5783             nan     0.1000    0.1382\n",
      "     7       17.3619             nan     0.1000    0.1674\n",
      "     8       17.1018             nan     0.1000    0.2132\n",
      "     9       16.9461             nan     0.1000    0.0078\n",
      "    10       16.6444             nan     0.1000    0.1003\n",
      "    20       15.3472             nan     0.1000   -0.0102\n",
      "    40       13.6915             nan     0.1000   -0.0216\n",
      "    60       12.7795             nan     0.1000   -0.0396\n",
      "    80       12.0593             nan     0.1000   -0.0406\n",
      "   100       11.5133             nan     0.1000   -0.0330\n",
      "   120       11.2073             nan     0.1000   -0.0455\n",
      "   140       10.8618             nan     0.1000   -0.0202\n",
      "   160       10.7048             nan     0.1000   -0.0068\n",
      "   180       10.5912             nan     0.1000   -0.0575\n",
      "   200       10.5059             nan     0.1000   -0.0290\n",
      "   220       10.3747             nan     0.1000   -0.0268\n",
      "   240       10.3504             nan     0.1000   -0.0434\n",
      "   260       10.2759             nan     0.1000   -0.0419\n",
      "   280       10.2119             nan     0.1000   -0.0657\n",
      "   300       10.1407             nan     0.1000   -0.0639\n",
      "   320       10.0851             nan     0.1000   -0.0670\n",
      "   340       10.0805             nan     0.1000   -0.0539\n",
      "   360       10.0697             nan     0.1000   -0.0613\n",
      "   380       10.0725             nan     0.1000   -0.0991\n",
      "   400       10.0050             nan     0.1000   -0.1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.3170             nan     0.1000    0.5855\n",
      "     2       18.4589             nan     0.1000    0.5941\n",
      "     3       17.8526             nan     0.1000    0.5668\n",
      "     4       17.3956             nan     0.1000    0.2800\n",
      "     5       16.7988             nan     0.1000    0.1234\n",
      "     6       16.3952             nan     0.1000   -0.0525\n",
      "     7       15.8015             nan     0.1000    0.3696\n",
      "     8       15.5916             nan     0.1000   -0.0531\n",
      "     9       15.0865             nan     0.1000    0.2538\n",
      "    10       14.7360             nan     0.1000    0.1866\n",
      "    20       12.2446             nan     0.1000   -0.0811\n",
      "    40        9.7816             nan     0.1000   -0.0417\n",
      "    60        8.4314             nan     0.1000   -0.0287\n",
      "    80        7.6019             nan     0.1000   -0.0650\n",
      "   100        7.1143             nan     0.1000   -0.1032\n",
      "   120        6.5168             nan     0.1000   -0.0883\n",
      "   140        5.9656             nan     0.1000   -0.0445\n",
      "   160        5.6499             nan     0.1000   -0.1066\n",
      "   180        5.3183             nan     0.1000   -0.0449\n",
      "   200        5.0021             nan     0.1000   -0.0543\n",
      "   220        4.6964             nan     0.1000   -0.0714\n",
      "   240        4.4658             nan     0.1000   -0.0549\n",
      "   260        4.1647             nan     0.1000   -0.0691\n",
      "   280        3.8771             nan     0.1000   -0.0348\n",
      "   300        3.7135             nan     0.1000   -0.0411\n",
      "   320        3.5229             nan     0.1000   -0.0445\n",
      "   340        3.3065             nan     0.1000   -0.0465\n",
      "   360        3.1031             nan     0.1000   -0.0232\n",
      "   380        2.9885             nan     0.1000   -0.0254\n",
      "   400        2.8515             nan     0.1000   -0.0325\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.0538             nan     0.1000    1.0191\n",
      "     2       18.1026             nan     0.1000    0.6052\n",
      "     3       17.3105             nan     0.1000    0.5973\n",
      "     4       16.6378             nan     0.1000    0.4619\n",
      "     5       16.0049             nan     0.1000    0.4043\n",
      "     6       15.3014             nan     0.1000    0.3353\n",
      "     7       14.7554             nan     0.1000    0.1806\n",
      "     8       14.2650             nan     0.1000    0.1091\n",
      "     9       13.8279             nan     0.1000    0.0589\n",
      "    10       13.4909             nan     0.1000    0.1249\n",
      "    20       10.8658             nan     0.1000   -0.0203\n",
      "    40        8.1216             nan     0.1000   -0.1370\n",
      "    60        6.6203             nan     0.1000   -0.0145\n",
      "    80        5.7433             nan     0.1000   -0.1326\n",
      "   100        4.9982             nan     0.1000   -0.1217\n",
      "   120        4.3771             nan     0.1000   -0.1016\n",
      "   140        3.8773             nan     0.1000   -0.0387\n",
      "   160        3.4444             nan     0.1000   -0.0483\n",
      "   180        3.0577             nan     0.1000   -0.0429\n",
      "   200        2.7295             nan     0.1000   -0.0616\n",
      "   220        2.4070             nan     0.1000   -0.0513\n",
      "   240        2.1696             nan     0.1000   -0.0566\n",
      "   260        1.9641             nan     0.1000   -0.0417\n",
      "   280        1.7600             nan     0.1000   -0.0337\n",
      "   300        1.6012             nan     0.1000   -0.0266\n",
      "   320        1.4516             nan     0.1000   -0.0290\n",
      "   340        1.3154             nan     0.1000   -0.0233\n",
      "   360        1.1889             nan     0.1000   -0.0358\n",
      "   380        1.0851             nan     0.1000   -0.0169\n",
      "   400        0.9620             nan     0.1000   -0.0201\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.9921             nan     0.0010    0.0044\n",
      "     2       20.9847             nan     0.0010    0.0052\n",
      "     3       20.9770             nan     0.0010    0.0074\n",
      "     4       20.9706             nan     0.0010    0.0057\n",
      "     5       20.9639             nan     0.0010    0.0043\n",
      "     6       20.9557             nan     0.0010    0.0043\n",
      "     7       20.9500             nan     0.0010    0.0061\n",
      "     8       20.9440             nan     0.0010    0.0057\n",
      "     9       20.9369             nan     0.0010    0.0060\n",
      "    10       20.9309             nan     0.0010    0.0045\n",
      "    20       20.8739             nan     0.0010    0.0048\n",
      "    40       20.7568             nan     0.0010    0.0059\n",
      "    60       20.6373             nan     0.0010    0.0010\n",
      "    80       20.5198             nan     0.0010    0.0043\n",
      "   100       20.4155             nan     0.0010    0.0047\n",
      "   120       20.3086             nan     0.0010    0.0039\n",
      "   140       20.2024             nan     0.0010    0.0042\n",
      "   160       20.0894             nan     0.0010    0.0046\n",
      "   180       19.9915             nan     0.0010    0.0051\n",
      "   200       19.8972             nan     0.0010    0.0045\n",
      "   220       19.8128             nan     0.0010    0.0040\n",
      "   240       19.7231             nan     0.0010    0.0030\n",
      "   260       19.6299             nan     0.0010    0.0038\n",
      "   280       19.5440             nan     0.0010    0.0017\n",
      "   300       19.4616             nan     0.0010    0.0038\n",
      "   320       19.3846             nan     0.0010    0.0002\n",
      "   340       19.3050             nan     0.0010    0.0032\n",
      "   360       19.2271             nan     0.0010    0.0033\n",
      "   380       19.1500             nan     0.0010    0.0021\n",
      "   400       19.0758             nan     0.0010    0.0026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.9916             nan     0.0010    0.0048\n",
      "     2       20.9860             nan     0.0010    0.0031\n",
      "     3       20.9768             nan     0.0010    0.0086\n",
      "     4       20.9674             nan     0.0010    0.0079\n",
      "     5       20.9603             nan     0.0010    0.0030\n",
      "     6       20.9491             nan     0.0010    0.0032\n",
      "     7       20.9413             nan     0.0010    0.0065\n",
      "     8       20.9320             nan     0.0010    0.0069\n",
      "     9       20.9230             nan     0.0010    0.0077\n",
      "    10       20.9150             nan     0.0010    0.0063\n",
      "    20       20.8150             nan     0.0010    0.0080\n",
      "    40       20.6279             nan     0.0010    0.0094\n",
      "    60       20.4470             nan     0.0010    0.0059\n",
      "    80       20.2787             nan     0.0010    0.0056\n",
      "   100       20.1028             nan     0.0010    0.0076\n",
      "   120       19.9331             nan     0.0010    0.0096\n",
      "   140       19.7728             nan     0.0010    0.0061\n",
      "   160       19.6141             nan     0.0010    0.0029\n",
      "   180       19.4478             nan     0.0010    0.0065\n",
      "   200       19.2949             nan     0.0010    0.0075\n",
      "   220       19.1344             nan     0.0010    0.0064\n",
      "   240       18.9850             nan     0.0010    0.0021\n",
      "   260       18.8392             nan     0.0010    0.0046\n",
      "   280       18.7012             nan     0.0010    0.0018\n",
      "   300       18.5655             nan     0.0010    0.0031\n",
      "   320       18.4335             nan     0.0010    0.0048\n",
      "   340       18.3035             nan     0.0010    0.0037\n",
      "   360       18.1749             nan     0.0010   -0.0005\n",
      "   380       18.0452             nan     0.0010    0.0043\n",
      "   400       17.9333             nan     0.0010    0.0036\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.9891             nan     0.0010    0.0083\n",
      "     2       20.9784             nan     0.0010    0.0084\n",
      "     3       20.9639             nan     0.0010    0.0103\n",
      "     4       20.9507             nan     0.0010    0.0107\n",
      "     5       20.9364             nan     0.0010    0.0071\n",
      "     6       20.9254             nan     0.0010    0.0105\n",
      "     7       20.9126             nan     0.0010    0.0076\n",
      "     8       20.8995             nan     0.0010    0.0068\n",
      "     9       20.8876             nan     0.0010    0.0085\n",
      "    10       20.8773             nan     0.0010    0.0089\n",
      "    20       20.7581             nan     0.0010    0.0078\n",
      "    40       20.5288             nan     0.0010    0.0055\n",
      "    60       20.3073             nan     0.0010    0.0066\n",
      "    80       20.0844             nan     0.0010    0.0038\n",
      "   100       19.8827             nan     0.0010    0.0083\n",
      "   120       19.6874             nan     0.0010    0.0068\n",
      "   140       19.4772             nan     0.0010    0.0065\n",
      "   160       19.3061             nan     0.0010    0.0084\n",
      "   180       19.1087             nan     0.0010    0.0052\n",
      "   200       18.9319             nan     0.0010    0.0041\n",
      "   220       18.7574             nan     0.0010    0.0048\n",
      "   240       18.5795             nan     0.0010    0.0062\n",
      "   260       18.4100             nan     0.0010    0.0049\n",
      "   280       18.2425             nan     0.0010    0.0068\n",
      "   300       18.0784             nan     0.0010    0.0050\n",
      "   320       17.9321             nan     0.0010    0.0065\n",
      "   340       17.7797             nan     0.0010    0.0043\n",
      "   360       17.6180             nan     0.0010    0.0048\n",
      "   380       17.4700             nan     0.0010    0.0019\n",
      "   400       17.3227             nan     0.0010    0.0036\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.9295             nan     0.0100    0.0625\n",
      "     2       20.8654             nan     0.0100    0.0588\n",
      "     3       20.8137             nan     0.0100    0.0623\n",
      "     4       20.7535             nan     0.0100    0.0586\n",
      "     5       20.6893             nan     0.0100    0.0629\n",
      "     6       20.6249             nan     0.0100    0.0509\n",
      "     7       20.5863             nan     0.0100    0.0087\n",
      "     8       20.5257             nan     0.0100    0.0381\n",
      "     9       20.4745             nan     0.0100    0.0577\n",
      "    10       20.4286             nan     0.0100    0.0307\n",
      "    20       19.9066             nan     0.0100    0.0379\n",
      "    40       19.1178             nan     0.0100    0.0176\n",
      "    60       18.4453             nan     0.0100    0.0072\n",
      "    80       17.8982             nan     0.0100    0.0207\n",
      "   100       17.4581             nan     0.0100    0.0191\n",
      "   120       17.0328             nan     0.0100   -0.0040\n",
      "   140       16.6731             nan     0.0100    0.0096\n",
      "   160       16.4061             nan     0.0100   -0.0113\n",
      "   180       16.1368             nan     0.0100   -0.0041\n",
      "   200       15.9211             nan     0.0100   -0.0011\n",
      "   220       15.6951             nan     0.0100    0.0071\n",
      "   240       15.4619             nan     0.0100   -0.0021\n",
      "   260       15.2359             nan     0.0100    0.0049\n",
      "   280       15.0325             nan     0.0100   -0.0136\n",
      "   300       14.8652             nan     0.0100   -0.0013\n",
      "   320       14.6730             nan     0.0100   -0.0060\n",
      "   340       14.5244             nan     0.0100   -0.0052\n",
      "   360       14.3926             nan     0.0100   -0.0074\n",
      "   380       14.2469             nan     0.0100    0.0020\n",
      "   400       14.1183             nan     0.0100   -0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.9329             nan     0.0100    0.0621\n",
      "     2       20.8498             nan     0.0100    0.0721\n",
      "     3       20.7384             nan     0.0100    0.0743\n",
      "     4       20.6798             nan     0.0100    0.0328\n",
      "     5       20.6011             nan     0.0100    0.0624\n",
      "     6       20.5159             nan     0.0100    0.0629\n",
      "     7       20.4570             nan     0.0100    0.0200\n",
      "     8       20.3556             nan     0.0100    0.0624\n",
      "     9       20.2486             nan     0.0100    0.0686\n",
      "    10       20.1705             nan     0.0100    0.0708\n",
      "    20       19.3667             nan     0.0100    0.0508\n",
      "    40       17.9770             nan     0.0100    0.0488\n",
      "    60       16.8952             nan     0.0100    0.0100\n",
      "    80       15.9348             nan     0.0100    0.0084\n",
      "   100       15.2180             nan     0.0100    0.0051\n",
      "   120       14.5481             nan     0.0100    0.0184\n",
      "   140       13.9588             nan     0.0100    0.0114\n",
      "   160       13.4981             nan     0.0100   -0.0085\n",
      "   180       13.0448             nan     0.0100   -0.0038\n",
      "   200       12.6569             nan     0.0100   -0.0058\n",
      "   220       12.3101             nan     0.0100    0.0029\n",
      "   240       11.9888             nan     0.0100   -0.0038\n",
      "   260       11.6859             nan     0.0100    0.0017\n",
      "   280       11.3935             nan     0.0100    0.0006\n",
      "   300       11.1363             nan     0.0100   -0.0049\n",
      "   320       10.8774             nan     0.0100   -0.0098\n",
      "   340       10.6473             nan     0.0100   -0.0005\n",
      "   360       10.4497             nan     0.0100   -0.0076\n",
      "   380       10.2508             nan     0.0100   -0.0096\n",
      "   400       10.0586             nan     0.0100   -0.0160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.9046             nan     0.0100    0.0790\n",
      "     2       20.8036             nan     0.0100    0.1028\n",
      "     3       20.6822             nan     0.0100    0.0739\n",
      "     4       20.5715             nan     0.0100    0.0681\n",
      "     5       20.4713             nan     0.0100    0.0842\n",
      "     6       20.3642             nan     0.0100    0.0859\n",
      "     7       20.2418             nan     0.0100    0.0731\n",
      "     8       20.1324             nan     0.0100    0.0876\n",
      "     9       20.0452             nan     0.0100    0.0542\n",
      "    10       19.9332             nan     0.0100    0.0873\n",
      "    20       19.0087             nan     0.0100    0.0403\n",
      "    40       17.2698             nan     0.0100    0.0523\n",
      "    60       15.9770             nan     0.0100    0.0239\n",
      "    80       14.9259             nan     0.0100    0.0064\n",
      "   100       13.9812             nan     0.0100    0.0104\n",
      "   120       13.2209             nan     0.0100    0.0219\n",
      "   140       12.5641             nan     0.0100    0.0132\n",
      "   160       11.9238             nan     0.0100    0.0172\n",
      "   180       11.4536             nan     0.0100   -0.0134\n",
      "   200       10.9733             nan     0.0100   -0.0130\n",
      "   220       10.5625             nan     0.0100    0.0002\n",
      "   240       10.1933             nan     0.0100   -0.0057\n",
      "   260        9.8360             nan     0.0100    0.0042\n",
      "   280        9.5181             nan     0.0100    0.0018\n",
      "   300        9.2052             nan     0.0100   -0.0039\n",
      "   320        8.9255             nan     0.0100    0.0054\n",
      "   340        8.6625             nan     0.0100    0.0023\n",
      "   360        8.3985             nan     0.0100   -0.0018\n",
      "   380        8.1860             nan     0.0100   -0.0095\n",
      "   400        7.9836             nan     0.0100   -0.0034\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.3959             nan     0.1000    0.6630\n",
      "     2       19.8373             nan     0.1000    0.4894\n",
      "     3       19.5888             nan     0.1000    0.2873\n",
      "     4       19.1846             nan     0.1000    0.1682\n",
      "     5       18.8293             nan     0.1000    0.0391\n",
      "     6       18.2690             nan     0.1000    0.1717\n",
      "     7       17.9203             nan     0.1000    0.2781\n",
      "     8       17.5951             nan     0.1000    0.2279\n",
      "     9       17.4672             nan     0.1000   -0.0009\n",
      "    10       17.2326             nan     0.1000    0.0447\n",
      "    20       15.9004             nan     0.1000    0.0001\n",
      "    40       14.2223             nan     0.1000    0.0146\n",
      "    60       13.1586             nan     0.1000   -0.0339\n",
      "    80       12.5469             nan     0.1000   -0.1056\n",
      "   100       12.1510             nan     0.1000   -0.1044\n",
      "   120       11.7570             nan     0.1000   -0.0327\n",
      "   140       11.4894             nan     0.1000   -0.0617\n",
      "   160       11.2805             nan     0.1000   -0.0473\n",
      "   180       11.0586             nan     0.1000   -0.0229\n",
      "   200       10.9279             nan     0.1000   -0.0398\n",
      "   220       10.7999             nan     0.1000   -0.0313\n",
      "   240       10.7256             nan     0.1000   -0.0439\n",
      "   260       10.6143             nan     0.1000   -0.0218\n",
      "   280       10.5327             nan     0.1000   -0.0995\n",
      "   300       10.4403             nan     0.1000   -0.0604\n",
      "   320       10.3770             nan     0.1000   -0.1004\n",
      "   340       10.3395             nan     0.1000   -0.0277\n",
      "   360       10.3216             nan     0.1000   -0.0509\n",
      "   380       10.2892             nan     0.1000   -0.0969\n",
      "   400       10.2533             nan     0.1000   -0.0422\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.9923             nan     0.1000    0.8824\n",
      "     2       19.5160             nan     0.1000    0.1808\n",
      "     3       18.5571             nan     0.1000    0.6196\n",
      "     4       17.7952             nan     0.1000    0.5027\n",
      "     5       16.9737             nan     0.1000    0.4081\n",
      "     6       16.4267             nan     0.1000    0.3265\n",
      "     7       15.9992             nan     0.1000    0.2681\n",
      "     8       15.5579             nan     0.1000    0.1190\n",
      "     9       15.0252             nan     0.1000    0.0844\n",
      "    10       14.6616             nan     0.1000    0.0810\n",
      "    20       12.6033             nan     0.1000   -0.0902\n",
      "    40       10.0533             nan     0.1000   -0.0288\n",
      "    60        8.5759             nan     0.1000   -0.0718\n",
      "    80        7.6020             nan     0.1000   -0.0586\n",
      "   100        6.9236             nan     0.1000   -0.0851\n",
      "   120        6.3716             nan     0.1000   -0.1326\n",
      "   140        5.7611             nan     0.1000   -0.0330\n",
      "   160        5.3486             nan     0.1000   -0.0002\n",
      "   180        4.9617             nan     0.1000   -0.0717\n",
      "   200        4.6215             nan     0.1000   -0.1049\n",
      "   220        4.2658             nan     0.1000   -0.0379\n",
      "   240        4.0596             nan     0.1000   -0.0359\n",
      "   260        3.7884             nan     0.1000   -0.0760\n",
      "   280        3.5905             nan     0.1000   -0.0317\n",
      "   300        3.3916             nan     0.1000   -0.0412\n",
      "   320        3.1902             nan     0.1000   -0.0179\n",
      "   340        3.0239             nan     0.1000   -0.0392\n",
      "   360        2.8722             nan     0.1000   -0.0541\n",
      "   380        2.7122             nan     0.1000   -0.0245\n",
      "   400        2.5617             nan     0.1000   -0.0238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.8934             nan     0.1000    0.9034\n",
      "     2       18.6780             nan     0.1000    0.4993\n",
      "     3       17.7619             nan     0.1000    0.5210\n",
      "     4       16.9260             nan     0.1000    0.3170\n",
      "     5       16.3988             nan     0.1000    0.5156\n",
      "     6       15.7121             nan     0.1000    0.3114\n",
      "     7       15.2919             nan     0.1000   -0.0040\n",
      "     8       14.7530             nan     0.1000    0.1040\n",
      "     9       14.2990             nan     0.1000    0.1611\n",
      "    10       13.9379             nan     0.1000   -0.0387\n",
      "    20       10.7397             nan     0.1000    0.0469\n",
      "    40        7.9580             nan     0.1000   -0.0284\n",
      "    60        6.4909             nan     0.1000   -0.1498\n",
      "    80        5.4628             nan     0.1000   -0.1015\n",
      "   100        4.6458             nan     0.1000   -0.0805\n",
      "   120        4.0263             nan     0.1000   -0.0770\n",
      "   140        3.5028             nan     0.1000   -0.0635\n",
      "   160        3.0652             nan     0.1000   -0.0445\n",
      "   180        2.6573             nan     0.1000   -0.0257\n",
      "   200        2.3612             nan     0.1000   -0.0272\n",
      "   220        2.1065             nan     0.1000   -0.0272\n",
      "   240        1.8862             nan     0.1000   -0.0361\n",
      "   260        1.6976             nan     0.1000   -0.0379\n",
      "   280        1.5153             nan     0.1000   -0.0174\n",
      "   300        1.4029             nan     0.1000   -0.0198\n",
      "   320        1.2693             nan     0.1000   -0.0252\n",
      "   340        1.1511             nan     0.1000   -0.0214\n",
      "   360        1.0413             nan     0.1000   -0.0174\n",
      "   380        0.9209             nan     0.1000   -0.0309\n",
      "   400        0.8574             nan     0.1000   -0.0174\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.0863             nan     0.0010    0.0010\n",
      "     2       21.0792             nan     0.0010    0.0056\n",
      "     3       21.0706             nan     0.0010    0.0056\n",
      "     4       21.0645             nan     0.0010    0.0072\n",
      "     5       21.0589             nan     0.0010    0.0055\n",
      "     6       21.0531             nan     0.0010    0.0063\n",
      "     7       21.0471             nan     0.0010    0.0054\n",
      "     8       21.0398             nan     0.0010    0.0049\n",
      "     9       21.0328             nan     0.0010    0.0063\n",
      "    10       21.0254             nan     0.0010    0.0059\n",
      "    20       20.9569             nan     0.0010    0.0071\n",
      "    40       20.8263             nan     0.0010    0.0064\n",
      "    60       20.7203             nan     0.0010    0.0023\n",
      "    80       20.5935             nan     0.0010    0.0057\n",
      "   100       20.4743             nan     0.0010    0.0059\n",
      "   120       20.3618             nan     0.0010    0.0053\n",
      "   140       20.2578             nan     0.0010    0.0048\n",
      "   160       20.1663             nan     0.0010    0.0039\n",
      "   180       20.0713             nan     0.0010    0.0048\n",
      "   200       19.9777             nan     0.0010    0.0010\n",
      "   220       19.8813             nan     0.0010    0.0047\n",
      "   240       19.7907             nan     0.0010    0.0043\n",
      "   260       19.6932             nan     0.0010    0.0037\n",
      "   280       19.6030             nan     0.0010    0.0032\n",
      "   300       19.5164             nan     0.0010    0.0026\n",
      "   320       19.4327             nan     0.0010    0.0013\n",
      "   340       19.3622             nan     0.0010    0.0036\n",
      "   360       19.2898             nan     0.0010    0.0006\n",
      "   380       19.2140             nan     0.0010    0.0034\n",
      "   400       19.1426             nan     0.0010    0.0016\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.0767             nan     0.0010    0.0065\n",
      "     2       21.0669             nan     0.0010    0.0085\n",
      "     3       21.0561             nan     0.0010    0.0097\n",
      "     4       21.0440             nan     0.0010    0.0092\n",
      "     5       21.0336             nan     0.0010    0.0086\n",
      "     6       21.0240             nan     0.0010    0.0094\n",
      "     7       21.0187             nan     0.0010    0.0019\n",
      "     8       21.0071             nan     0.0010    0.0074\n",
      "     9       20.9966             nan     0.0010    0.0076\n",
      "    10       20.9853             nan     0.0010    0.0070\n",
      "    20       20.8834             nan     0.0010    0.0076\n",
      "    40       20.6786             nan     0.0010    0.0063\n",
      "    60       20.5010             nan     0.0010    0.0051\n",
      "    80       20.3295             nan     0.0010    0.0081\n",
      "   100       20.1566             nan     0.0010    0.0058\n",
      "   120       19.9931             nan     0.0010    0.0076\n",
      "   140       19.8218             nan     0.0010    0.0070\n",
      "   160       19.6731             nan     0.0010    0.0035\n",
      "   180       19.5073             nan     0.0010    0.0076\n",
      "   200       19.3418             nan     0.0010    0.0044\n",
      "   220       19.1859             nan     0.0010    0.0046\n",
      "   240       19.0425             nan     0.0010    0.0058\n",
      "   260       18.8981             nan     0.0010    0.0073\n",
      "   280       18.7632             nan     0.0010    0.0036\n",
      "   300       18.6323             nan     0.0010    0.0032\n",
      "   320       18.4949             nan     0.0010    0.0049\n",
      "   340       18.3645             nan     0.0010    0.0051\n",
      "   360       18.2408             nan     0.0010    0.0037\n",
      "   380       18.1143             nan     0.0010    0.0052\n",
      "   400       18.0001             nan     0.0010    0.0009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.0789             nan     0.0010    0.0065\n",
      "     2       21.0719             nan     0.0010    0.0043\n",
      "     3       21.0609             nan     0.0010    0.0077\n",
      "     4       21.0512             nan     0.0010    0.0072\n",
      "     5       21.0383             nan     0.0010    0.0088\n",
      "     6       21.0246             nan     0.0010    0.0106\n",
      "     7       21.0132             nan     0.0010    0.0086\n",
      "     8       21.0002             nan     0.0010    0.0073\n",
      "     9       20.9890             nan     0.0010    0.0083\n",
      "    10       20.9759             nan     0.0010    0.0080\n",
      "    20       20.8548             nan     0.0010    0.0072\n",
      "    40       20.6357             nan     0.0010    0.0080\n",
      "    60       20.4203             nan     0.0010    0.0075\n",
      "    80       20.2016             nan     0.0010    0.0067\n",
      "   100       19.9828             nan     0.0010    0.0065\n",
      "   120       19.7773             nan     0.0010    0.0067\n",
      "   140       19.5764             nan     0.0010    0.0075\n",
      "   160       19.3871             nan     0.0010    0.0079\n",
      "   180       19.2024             nan     0.0010    0.0061\n",
      "   200       19.0163             nan     0.0010    0.0077\n",
      "   220       18.8367             nan     0.0010    0.0057\n",
      "   240       18.6580             nan     0.0010    0.0078\n",
      "   260       18.4946             nan     0.0010    0.0065\n",
      "   280       18.3188             nan     0.0010    0.0059\n",
      "   300       18.1583             nan     0.0010    0.0062\n",
      "   320       18.0044             nan     0.0010    0.0036\n",
      "   340       17.8401             nan     0.0010    0.0036\n",
      "   360       17.6981             nan     0.0010    0.0038\n",
      "   380       17.5438             nan     0.0010    0.0058\n",
      "   400       17.3880             nan     0.0010    0.0037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.0071             nan     0.0100    0.0750\n",
      "     2       20.9370             nan     0.0100    0.0663\n",
      "     3       20.8780             nan     0.0100    0.0412\n",
      "     4       20.8158             nan     0.0100    0.0606\n",
      "     5       20.7696             nan     0.0100    0.0578\n",
      "     6       20.7022             nan     0.0100    0.0655\n",
      "     7       20.6242             nan     0.0100    0.0440\n",
      "     8       20.5536             nan     0.0100    0.0416\n",
      "     9       20.4843             nan     0.0100    0.0386\n",
      "    10       20.4188             nan     0.0100    0.0516\n",
      "    20       19.9780             nan     0.0100    0.0474\n",
      "    40       19.1398             nan     0.0100    0.0364\n",
      "    60       18.4864             nan     0.0100    0.0109\n",
      "    80       17.9453             nan     0.0100    0.0135\n",
      "   100       17.5061             nan     0.0100    0.0178\n",
      "   120       17.1476             nan     0.0100    0.0030\n",
      "   140       16.7982             nan     0.0100    0.0070\n",
      "   160       16.5014             nan     0.0100    0.0086\n",
      "   180       16.2292             nan     0.0100    0.0083\n",
      "   200       15.9879             nan     0.0100    0.0047\n",
      "   220       15.7414             nan     0.0100   -0.0028\n",
      "   240       15.5254             nan     0.0100    0.0081\n",
      "   260       15.3435             nan     0.0100    0.0023\n",
      "   280       15.1549             nan     0.0100    0.0034\n",
      "   300       14.9800             nan     0.0100   -0.0076\n",
      "   320       14.8087             nan     0.0100   -0.0025\n",
      "   340       14.6462             nan     0.0100    0.0018\n",
      "   360       14.5078             nan     0.0100    0.0016\n",
      "   380       14.3627             nan     0.0100    0.0002\n",
      "   400       14.2264             nan     0.0100   -0.0095\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.9849             nan     0.0100    0.0911\n",
      "     2       20.9011             nan     0.0100    0.0419\n",
      "     3       20.7702             nan     0.0100    0.0837\n",
      "     4       20.6738             nan     0.0100    0.0906\n",
      "     5       20.5761             nan     0.0100    0.0940\n",
      "     6       20.4935             nan     0.0100    0.0735\n",
      "     7       20.4443             nan     0.0100    0.0060\n",
      "     8       20.3472             nan     0.0100    0.0891\n",
      "     9       20.2229             nan     0.0100    0.0836\n",
      "    10       20.1213             nan     0.0100    0.0704\n",
      "    20       19.3257             nan     0.0100    0.0554\n",
      "    40       18.0748             nan     0.0100    0.0479\n",
      "    60       16.9505             nan     0.0100    0.0246\n",
      "    80       16.0376             nan     0.0100    0.0173\n",
      "   100       15.2257             nan     0.0100    0.0116\n",
      "   120       14.5477             nan     0.0100    0.0092\n",
      "   140       13.9829             nan     0.0100   -0.0009\n",
      "   160       13.4782             nan     0.0100   -0.0017\n",
      "   180       13.0526             nan     0.0100   -0.0060\n",
      "   200       12.6205             nan     0.0100    0.0041\n",
      "   220       12.2939             nan     0.0100   -0.0179\n",
      "   240       11.9695             nan     0.0100   -0.0096\n",
      "   260       11.6892             nan     0.0100   -0.0075\n",
      "   280       11.4420             nan     0.0100   -0.0128\n",
      "   300       11.1933             nan     0.0100   -0.0032\n",
      "   320       10.9353             nan     0.0100   -0.0003\n",
      "   340       10.7458             nan     0.0100    0.0011\n",
      "   360       10.5527             nan     0.0100   -0.0169\n",
      "   380       10.3804             nan     0.0100   -0.0052\n",
      "   400       10.1915             nan     0.0100   -0.0074\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.9795             nan     0.0100    0.1124\n",
      "     2       20.8728             nan     0.0100    0.0635\n",
      "     3       20.7798             nan     0.0100    0.0731\n",
      "     4       20.6362             nan     0.0100    0.0723\n",
      "     5       20.5267             nan     0.0100    0.0719\n",
      "     6       20.4255             nan     0.0100    0.0910\n",
      "     7       20.3313             nan     0.0100    0.0751\n",
      "     8       20.2208             nan     0.0100    0.1079\n",
      "     9       20.1229             nan     0.0100    0.0735\n",
      "    10       20.0441             nan     0.0100    0.0434\n",
      "    20       19.0369             nan     0.0100    0.0904\n",
      "    40       17.3192             nan     0.0100    0.0632\n",
      "    60       15.9448             nan     0.0100    0.0081\n",
      "    80       14.9310             nan     0.0100    0.0468\n",
      "   100       14.0562             nan     0.0100    0.0014\n",
      "   120       13.3457             nan     0.0100   -0.0078\n",
      "   140       12.6714             nan     0.0100    0.0023\n",
      "   160       12.1348             nan     0.0100   -0.0061\n",
      "   180       11.6389             nan     0.0100   -0.0059\n",
      "   200       11.2055             nan     0.0100    0.0082\n",
      "   220       10.7953             nan     0.0100   -0.0041\n",
      "   240       10.3906             nan     0.0100   -0.0060\n",
      "   260       10.0624             nan     0.0100   -0.0107\n",
      "   280        9.7189             nan     0.0100   -0.0070\n",
      "   300        9.4234             nan     0.0100   -0.0003\n",
      "   320        9.1709             nan     0.0100   -0.0079\n",
      "   340        8.9164             nan     0.0100   -0.0109\n",
      "   360        8.6977             nan     0.0100   -0.0048\n",
      "   380        8.4697             nan     0.0100   -0.0015\n",
      "   400        8.2759             nan     0.0100   -0.0008\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.5694             nan     0.1000    0.6495\n",
      "     2       19.9751             nan     0.1000    0.5347\n",
      "     3       19.4602             nan     0.1000    0.3771\n",
      "     4       19.0587             nan     0.1000    0.3160\n",
      "     5       18.9156             nan     0.1000    0.0221\n",
      "     6       18.5189             nan     0.1000    0.3475\n",
      "     7       18.2827             nan     0.1000    0.1978\n",
      "     8       17.9821             nan     0.1000    0.0784\n",
      "     9       17.7076             nan     0.1000    0.2112\n",
      "    10       17.4884             nan     0.1000    0.1211\n",
      "    20       16.0186             nan     0.1000    0.0576\n",
      "    40       14.3699             nan     0.1000   -0.0107\n",
      "    60       13.3193             nan     0.1000   -0.0410\n",
      "    80       12.6273             nan     0.1000   -0.0262\n",
      "   100       12.1773             nan     0.1000   -0.0313\n",
      "   120       11.7757             nan     0.1000   -0.0611\n",
      "   140       11.5388             nan     0.1000   -0.1432\n",
      "   160       11.3119             nan     0.1000   -0.0575\n",
      "   180       11.1396             nan     0.1000   -0.0483\n",
      "   200       11.0165             nan     0.1000   -0.0789\n",
      "   220       10.9221             nan     0.1000   -0.1224\n",
      "   240       10.7814             nan     0.1000   -0.0284\n",
      "   260       10.6848             nan     0.1000   -0.0429\n",
      "   280       10.6023             nan     0.1000   -0.0306\n",
      "   300       10.5777             nan     0.1000   -0.0570\n",
      "   320       10.5327             nan     0.1000   -0.0428\n",
      "   340       10.5032             nan     0.1000   -0.0265\n",
      "   360       10.5037             nan     0.1000   -0.0401\n",
      "   380       10.4560             nan     0.1000   -0.0282\n",
      "   400       10.4358             nan     0.1000   -0.0411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.2561             nan     0.1000    0.3626\n",
      "     2       19.3228             nan     0.1000    0.8596\n",
      "     3       18.4044             nan     0.1000    0.8774\n",
      "     4       17.9440             nan     0.1000    0.2205\n",
      "     5       17.3515             nan     0.1000    0.3951\n",
      "     6       16.9275             nan     0.1000    0.1233\n",
      "     7       16.3937             nan     0.1000    0.1537\n",
      "     8       16.0172             nan     0.1000    0.1528\n",
      "     9       15.6614             nan     0.1000    0.2203\n",
      "    10       15.1992             nan     0.1000    0.2566\n",
      "    20       12.5866             nan     0.1000   -0.0384\n",
      "    40       10.3830             nan     0.1000    0.0200\n",
      "    60        8.9830             nan     0.1000   -0.1223\n",
      "    80        8.2709             nan     0.1000   -0.1132\n",
      "   100        7.5139             nan     0.1000   -0.1280\n",
      "   120        6.9875             nan     0.1000   -0.0713\n",
      "   140        6.4508             nan     0.1000   -0.0633\n",
      "   160        5.9889             nan     0.1000   -0.0648\n",
      "   180        5.5299             nan     0.1000   -0.0584\n",
      "   200        5.2388             nan     0.1000   -0.0841\n",
      "   220        4.8728             nan     0.1000   -0.0457\n",
      "   240        4.5961             nan     0.1000   -0.0559\n",
      "   260        4.3980             nan     0.1000   -0.0548\n",
      "   280        4.1291             nan     0.1000   -0.0356\n",
      "   300        3.9068             nan     0.1000   -0.0536\n",
      "   320        3.6945             nan     0.1000   -0.0604\n",
      "   340        3.5445             nan     0.1000   -0.0216\n",
      "   360        3.4077             nan     0.1000   -0.0477\n",
      "   380        3.2530             nan     0.1000   -0.0362\n",
      "   400        3.1506             nan     0.1000   -0.0376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.9240             nan     0.1000    0.8540\n",
      "     2       19.1717             nan     0.1000    0.4628\n",
      "     3       18.2429             nan     0.1000    0.6021\n",
      "     4       17.4825             nan     0.1000    0.4884\n",
      "     5       16.7600             nan     0.1000    0.1646\n",
      "     6       15.9901             nan     0.1000    0.2035\n",
      "     7       15.6037             nan     0.1000    0.0630\n",
      "     8       15.2053             nan     0.1000    0.2086\n",
      "     9       14.7627             nan     0.1000    0.2857\n",
      "    10       14.4196             nan     0.1000   -0.0588\n",
      "    20       11.0249             nan     0.1000   -0.0204\n",
      "    40        8.3477             nan     0.1000   -0.0618\n",
      "    60        6.7436             nan     0.1000   -0.0902\n",
      "    80        5.7322             nan     0.1000   -0.0891\n",
      "   100        4.8882             nan     0.1000   -0.0859\n",
      "   120        4.1899             nan     0.1000   -0.0989\n",
      "   140        3.7323             nan     0.1000   -0.0615\n",
      "   160        3.3118             nan     0.1000   -0.0357\n",
      "   180        2.9426             nan     0.1000   -0.0627\n",
      "   200        2.6582             nan     0.1000   -0.0628\n",
      "   220        2.3703             nan     0.1000   -0.0363\n",
      "   240        2.1458             nan     0.1000   -0.0069\n",
      "   260        1.9142             nan     0.1000   -0.0453\n",
      "   280        1.7533             nan     0.1000   -0.0321\n",
      "   300        1.6043             nan     0.1000   -0.0155\n",
      "   320        1.4555             nan     0.1000   -0.0219\n",
      "   340        1.3175             nan     0.1000   -0.0309\n",
      "   360        1.2018             nan     0.1000   -0.0241\n",
      "   380        1.1103             nan     0.1000   -0.0230\n",
      "   400        1.0080             nan     0.1000   -0.0145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.5856             nan     0.0010    0.0057\n",
      "     2       21.5797             nan     0.0010    0.0055\n",
      "     3       21.5743             nan     0.0010    0.0033\n",
      "     4       21.5674             nan     0.0010    0.0044\n",
      "     5       21.5618             nan     0.0010    0.0061\n",
      "     6       21.5555             nan     0.0010    0.0054\n",
      "     7       21.5496             nan     0.0010    0.0064\n",
      "     8       21.5434             nan     0.0010    0.0052\n",
      "     9       21.5379             nan     0.0010    0.0031\n",
      "    10       21.5308             nan     0.0010    0.0071\n",
      "    20       21.4709             nan     0.0010    0.0015\n",
      "    40       21.3563             nan     0.0010    0.0013\n",
      "    60       21.2412             nan     0.0010    0.0031\n",
      "    80       21.1327             nan     0.0010    0.0053\n",
      "   100       21.0250             nan     0.0010    0.0010\n",
      "   120       20.9262             nan     0.0010    0.0041\n",
      "   140       20.8365             nan     0.0010   -0.0012\n",
      "   160       20.7348             nan     0.0010    0.0036\n",
      "   180       20.6421             nan     0.0010    0.0039\n",
      "   200       20.5596             nan     0.0010    0.0034\n",
      "   220       20.4614             nan     0.0010    0.0035\n",
      "   240       20.3771             nan     0.0010    0.0027\n",
      "   260       20.2934             nan     0.0010    0.0031\n",
      "   280       20.2197             nan     0.0010    0.0044\n",
      "   300       20.1378             nan     0.0010    0.0031\n",
      "   320       20.0604             nan     0.0010    0.0032\n",
      "   340       19.9833             nan     0.0010    0.0023\n",
      "   360       19.9142             nan     0.0010    0.0030\n",
      "   380       19.8477             nan     0.0010    0.0020\n",
      "   400       19.7763             nan     0.0010    0.0029\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.5837             nan     0.0010    0.0081\n",
      "     2       21.5746             nan     0.0010    0.0068\n",
      "     3       21.5649             nan     0.0010    0.0065\n",
      "     4       21.5560             nan     0.0010    0.0083\n",
      "     5       21.5436             nan     0.0010    0.0084\n",
      "     6       21.5336             nan     0.0010    0.0035\n",
      "     7       21.5261             nan     0.0010    0.0018\n",
      "     8       21.5149             nan     0.0010    0.0085\n",
      "     9       21.5064             nan     0.0010    0.0090\n",
      "    10       21.4968             nan     0.0010    0.0079\n",
      "    20       21.4020             nan     0.0010    0.0080\n",
      "    40       21.2162             nan     0.0010    0.0080\n",
      "    60       21.0316             nan     0.0010    0.0061\n",
      "    80       20.8541             nan     0.0010    0.0061\n",
      "   100       20.6823             nan     0.0010    0.0079\n",
      "   120       20.5114             nan     0.0010    0.0068\n",
      "   140       20.3460             nan     0.0010    0.0071\n",
      "   160       20.1762             nan     0.0010    0.0061\n",
      "   180       20.0127             nan     0.0010    0.0069\n",
      "   200       19.8678             nan     0.0010    0.0061\n",
      "   220       19.7211             nan     0.0010    0.0034\n",
      "   240       19.5768             nan     0.0010    0.0068\n",
      "   260       19.4229             nan     0.0010    0.0043\n",
      "   280       19.2817             nan     0.0010    0.0051\n",
      "   300       19.1425             nan     0.0010    0.0052\n",
      "   320       19.0147             nan     0.0010    0.0052\n",
      "   340       18.8835             nan     0.0010    0.0067\n",
      "   360       18.7417             nan     0.0010    0.0035\n",
      "   380       18.6109             nan     0.0010    0.0033\n",
      "   400       18.4899             nan     0.0010   -0.0008\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.5837             nan     0.0010    0.0081\n",
      "     2       21.5703             nan     0.0010    0.0100\n",
      "     3       21.5591             nan     0.0010    0.0052\n",
      "     4       21.5466             nan     0.0010    0.0068\n",
      "     5       21.5344             nan     0.0010    0.0091\n",
      "     6       21.5225             nan     0.0010    0.0056\n",
      "     7       21.5099             nan     0.0010    0.0086\n",
      "     8       21.4974             nan     0.0010    0.0086\n",
      "     9       21.4836             nan     0.0010    0.0086\n",
      "    10       21.4728             nan     0.0010    0.0116\n",
      "    20       21.3608             nan     0.0010    0.0033\n",
      "    40       21.1465             nan     0.0010    0.0091\n",
      "    60       20.9270             nan     0.0010    0.0061\n",
      "    80       20.7093             nan     0.0010    0.0080\n",
      "   100       20.4936             nan     0.0010    0.0095\n",
      "   120       20.2867             nan     0.0010    0.0031\n",
      "   140       20.0864             nan     0.0010    0.0050\n",
      "   160       19.8788             nan     0.0010    0.0067\n",
      "   180       19.6822             nan     0.0010    0.0079\n",
      "   200       19.4828             nan     0.0010    0.0082\n",
      "   220       19.2990             nan     0.0010    0.0099\n",
      "   240       19.1116             nan     0.0010    0.0038\n",
      "   260       18.9295             nan     0.0010    0.0077\n",
      "   280       18.7473             nan     0.0010    0.0069\n",
      "   300       18.5728             nan     0.0010    0.0025\n",
      "   320       18.3990             nan     0.0010    0.0034\n",
      "   340       18.2353             nan     0.0010    0.0045\n",
      "   360       18.0762             nan     0.0010    0.0059\n",
      "   380       17.9203             nan     0.0010    0.0046\n",
      "   400       17.7773             nan     0.0010    0.0030\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.5415             nan     0.0100    0.0591\n",
      "     2       21.4676             nan     0.0100    0.0478\n",
      "     3       21.4209             nan     0.0100    0.0533\n",
      "     4       21.3857             nan     0.0100    0.0249\n",
      "     5       21.3157             nan     0.0100    0.0380\n",
      "     6       21.2599             nan     0.0100    0.0495\n",
      "     7       21.1969             nan     0.0100    0.0385\n",
      "     8       21.1357             nan     0.0100    0.0499\n",
      "     9       21.1194             nan     0.0100    0.0016\n",
      "    10       21.0632             nan     0.0100    0.0314\n",
      "    20       20.6020             nan     0.0100    0.0532\n",
      "    40       19.7690             nan     0.0100    0.0338\n",
      "    60       19.1197             nan     0.0100    0.0148\n",
      "    80       18.5668             nan     0.0100   -0.0015\n",
      "   100       18.0864             nan     0.0100    0.0040\n",
      "   120       17.6878             nan     0.0100    0.0022\n",
      "   140       17.3982             nan     0.0100    0.0122\n",
      "   160       17.0924             nan     0.0100    0.0091\n",
      "   180       16.8088             nan     0.0100    0.0127\n",
      "   200       16.5172             nan     0.0100    0.0054\n",
      "   220       16.2827             nan     0.0100   -0.0059\n",
      "   240       16.0443             nan     0.0100    0.0011\n",
      "   260       15.8327             nan     0.0100    0.0037\n",
      "   280       15.6504             nan     0.0100   -0.0122\n",
      "   300       15.4641             nan     0.0100    0.0013\n",
      "   320       15.3043             nan     0.0100    0.0066\n",
      "   340       15.1287             nan     0.0100   -0.0063\n",
      "   360       14.9673             nan     0.0100   -0.0066\n",
      "   380       14.8105             nan     0.0100   -0.0020\n",
      "   400       14.6757             nan     0.0100   -0.0014\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.4917             nan     0.0100    0.0691\n",
      "     2       21.4005             nan     0.0100    0.0648\n",
      "     3       21.2747             nan     0.0100    0.0526\n",
      "     4       21.1937             nan     0.0100    0.0779\n",
      "     5       21.1147             nan     0.0100    0.0785\n",
      "     6       21.0192             nan     0.0100    0.0574\n",
      "     7       20.9735             nan     0.0100    0.0289\n",
      "     8       20.8710             nan     0.0100    0.0746\n",
      "     9       20.7545             nan     0.0100    0.0806\n",
      "    10       20.6675             nan     0.0100    0.0530\n",
      "    20       19.8030             nan     0.0100    0.0365\n",
      "    40       18.4629             nan     0.0100    0.0570\n",
      "    60       17.4177             nan     0.0100    0.0227\n",
      "    80       16.4965             nan     0.0100    0.0148\n",
      "   100       15.7014             nan     0.0100    0.0270\n",
      "   120       14.9440             nan     0.0100   -0.0040\n",
      "   140       14.3353             nan     0.0100   -0.0024\n",
      "   160       13.8381             nan     0.0100   -0.0074\n",
      "   180       13.3432             nan     0.0100   -0.0084\n",
      "   200       12.9442             nan     0.0100   -0.0004\n",
      "   220       12.5882             nan     0.0100    0.0080\n",
      "   240       12.2489             nan     0.0100   -0.0000\n",
      "   260       11.9525             nan     0.0100   -0.0061\n",
      "   280       11.6798             nan     0.0100   -0.0134\n",
      "   300       11.3983             nan     0.0100   -0.0032\n",
      "   320       11.1566             nan     0.0100   -0.0033\n",
      "   340       10.9184             nan     0.0100   -0.0063\n",
      "   360       10.7160             nan     0.0100   -0.0069\n",
      "   380       10.5219             nan     0.0100   -0.0117\n",
      "   400       10.3285             nan     0.0100   -0.0073\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.4730             nan     0.0100    0.0693\n",
      "     2       21.3258             nan     0.0100    0.0792\n",
      "     3       21.1991             nan     0.0100    0.0932\n",
      "     4       21.0904             nan     0.0100    0.0415\n",
      "     5       20.9939             nan     0.0100    0.0790\n",
      "     6       20.8938             nan     0.0100    0.0296\n",
      "     7       20.8011             nan     0.0100    0.0486\n",
      "     8       20.6940             nan     0.0100    0.0903\n",
      "     9       20.5565             nan     0.0100    0.0310\n",
      "    10       20.4939             nan     0.0100    0.0436\n",
      "    20       19.4839             nan     0.0100    0.0525\n",
      "    40       17.7352             nan     0.0100    0.0208\n",
      "    60       16.2416             nan     0.0100    0.0362\n",
      "    80       15.2307             nan     0.0100    0.0272\n",
      "   100       14.3597             nan     0.0100    0.0161\n",
      "   120       13.5000             nan     0.0100    0.0196\n",
      "   140       12.7398             nan     0.0100    0.0025\n",
      "   160       12.1147             nan     0.0100   -0.0052\n",
      "   180       11.6118             nan     0.0100   -0.0029\n",
      "   200       11.1810             nan     0.0100    0.0058\n",
      "   220       10.7620             nan     0.0100   -0.0057\n",
      "   240       10.3985             nan     0.0100   -0.0007\n",
      "   260       10.0384             nan     0.0100   -0.0051\n",
      "   280        9.7180             nan     0.0100   -0.0137\n",
      "   300        9.4242             nan     0.0100   -0.0160\n",
      "   320        9.1671             nan     0.0100   -0.0120\n",
      "   340        8.9386             nan     0.0100   -0.0117\n",
      "   360        8.7186             nan     0.0100   -0.0303\n",
      "   380        8.4782             nan     0.0100   -0.0012\n",
      "   400        8.2612             nan     0.0100   -0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.0800             nan     0.1000    0.3675\n",
      "     2       20.7738             nan     0.1000    0.0022\n",
      "     3       20.4264             nan     0.1000    0.2749\n",
      "     4       19.7693             nan     0.1000    0.5534\n",
      "     5       19.3740             nan     0.1000    0.3475\n",
      "     6       19.2706             nan     0.1000    0.0037\n",
      "     7       18.8494             nan     0.1000    0.2326\n",
      "     8       18.6906             nan     0.1000    0.0945\n",
      "     9       18.4254             nan     0.1000    0.1555\n",
      "    10       18.2362             nan     0.1000    0.0651\n",
      "    20       16.4103             nan     0.1000   -0.1560\n",
      "    40       14.7100             nan     0.1000   -0.1527\n",
      "    60       13.6128             nan     0.1000   -0.0705\n",
      "    80       13.0015             nan     0.1000   -0.1504\n",
      "   100       12.4152             nan     0.1000   -0.0720\n",
      "   120       11.9893             nan     0.1000   -0.0565\n",
      "   140       11.6581             nan     0.1000   -0.0357\n",
      "   160       11.4872             nan     0.1000   -0.0284\n",
      "   180       11.2707             nan     0.1000   -0.0701\n",
      "   200       11.1413             nan     0.1000   -0.0861\n",
      "   220       11.0389             nan     0.1000   -0.1278\n",
      "   240       11.0267             nan     0.1000   -0.0777\n",
      "   260       10.9306             nan     0.1000   -0.0579\n",
      "   280       10.8918             nan     0.1000   -0.0679\n",
      "   300       10.8445             nan     0.1000   -0.0647\n",
      "   320       10.8296             nan     0.1000   -0.0502\n",
      "   340       10.7576             nan     0.1000   -0.0443\n",
      "   360       10.7398             nan     0.1000   -0.0945\n",
      "   380       10.7240             nan     0.1000   -0.0766\n",
      "   400       10.6617             nan     0.1000   -0.0501\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.4549             nan     0.1000    0.8100\n",
      "     2       19.9947             nan     0.1000    0.1955\n",
      "     3       19.2864             nan     0.1000    0.6010\n",
      "     4       18.4819             nan     0.1000    0.2810\n",
      "     5       17.6475             nan     0.1000    0.4230\n",
      "     6       17.1138             nan     0.1000    0.2570\n",
      "     7       16.7645             nan     0.1000    0.2252\n",
      "     8       16.5038             nan     0.1000    0.0762\n",
      "     9       16.0064             nan     0.1000    0.0852\n",
      "    10       15.6769             nan     0.1000    0.0113\n",
      "    20       13.2516             nan     0.1000    0.0713\n",
      "    40       10.5624             nan     0.1000    0.0079\n",
      "    60        9.1344             nan     0.1000   -0.0339\n",
      "    80        8.3659             nan     0.1000   -0.0931\n",
      "   100        7.6520             nan     0.1000   -0.1475\n",
      "   120        7.0510             nan     0.1000   -0.0980\n",
      "   140        6.6110             nan     0.1000   -0.0834\n",
      "   160        6.1592             nan     0.1000   -0.0307\n",
      "   180        5.7345             nan     0.1000   -0.0874\n",
      "   200        5.4093             nan     0.1000   -0.0760\n",
      "   220        5.0208             nan     0.1000   -0.0291\n",
      "   240        4.7567             nan     0.1000   -0.0558\n",
      "   260        4.5238             nan     0.1000   -0.0434\n",
      "   280        4.2568             nan     0.1000   -0.0413\n",
      "   300        3.9301             nan     0.1000   -0.0447\n",
      "   320        3.7421             nan     0.1000   -0.0394\n",
      "   340        3.5971             nan     0.1000   -0.0518\n",
      "   360        3.4602             nan     0.1000   -0.0449\n",
      "   380        3.3124             nan     0.1000   -0.0470\n",
      "   400        3.1886             nan     0.1000   -0.0528\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.4445             nan     0.1000    0.9064\n",
      "     2       19.2781             nan     0.1000    0.6599\n",
      "     3       18.4859             nan     0.1000    0.4710\n",
      "     4       17.7052             nan     0.1000    0.4672\n",
      "     5       16.9610             nan     0.1000    0.3489\n",
      "     6       16.2733             nan     0.1000    0.2601\n",
      "     7       15.6907             nan     0.1000    0.1950\n",
      "     8       15.3526             nan     0.1000   -0.0040\n",
      "     9       14.8147             nan     0.1000    0.1569\n",
      "    10       14.3680             nan     0.1000    0.1948\n",
      "    20       11.7441             nan     0.1000   -0.2684\n",
      "    40        8.8441             nan     0.1000   -0.0450\n",
      "    60        6.9296             nan     0.1000   -0.1569\n",
      "    80        5.8900             nan     0.1000   -0.0689\n",
      "   100        5.1451             nan     0.1000   -0.0795\n",
      "   120        4.4264             nan     0.1000   -0.0415\n",
      "   140        3.9287             nan     0.1000   -0.0360\n",
      "   160        3.5683             nan     0.1000   -0.0514\n",
      "   180        3.2005             nan     0.1000   -0.0772\n",
      "   200        2.8909             nan     0.1000   -0.0617\n",
      "   220        2.5904             nan     0.1000   -0.0555\n",
      "   240        2.3317             nan     0.1000   -0.0440\n",
      "   260        2.1250             nan     0.1000   -0.0500\n",
      "   280        1.9178             nan     0.1000   -0.0273\n",
      "   300        1.7518             nan     0.1000   -0.0241\n",
      "   320        1.6187             nan     0.1000   -0.0254\n",
      "   340        1.4902             nan     0.1000   -0.0175\n",
      "   360        1.3594             nan     0.1000   -0.0161\n",
      "   380        1.2497             nan     0.1000   -0.0180\n",
      "   400        1.1444             nan     0.1000   -0.0298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.2814             nan     0.0010    0.0064\n",
      "     2       20.2741             nan     0.0010    0.0059\n",
      "     3       20.2665             nan     0.0010    0.0053\n",
      "     4       20.2607             nan     0.0010    0.0072\n",
      "     5       20.2553             nan     0.0010    0.0001\n",
      "     6       20.2486             nan     0.0010    0.0070\n",
      "     7       20.2420             nan     0.0010    0.0069\n",
      "     8       20.2356             nan     0.0010    0.0071\n",
      "     9       20.2287             nan     0.0010    0.0069\n",
      "    10       20.2232             nan     0.0010    0.0069\n",
      "    20       20.1587             nan     0.0010    0.0027\n",
      "    40       20.0295             nan     0.0010    0.0024\n",
      "    60       19.9045             nan     0.0010    0.0053\n",
      "    80       19.7896             nan     0.0010    0.0057\n",
      "   100       19.6679             nan     0.0010    0.0025\n",
      "   120       19.5532             nan     0.0010    0.0061\n",
      "   140       19.4447             nan     0.0010    0.0047\n",
      "   160       19.3424             nan     0.0010    0.0047\n",
      "   180       19.2407             nan     0.0010    0.0015\n",
      "   200       19.1428             nan     0.0010    0.0023\n",
      "   220       19.0408             nan     0.0010    0.0015\n",
      "   240       18.9463             nan     0.0010    0.0016\n",
      "   260       18.8546             nan     0.0010    0.0022\n",
      "   280       18.7682             nan     0.0010    0.0034\n",
      "   300       18.6854             nan     0.0010    0.0034\n",
      "   320       18.5999             nan     0.0010    0.0049\n",
      "   340       18.5240             nan     0.0010    0.0042\n",
      "   360       18.4460             nan     0.0010    0.0021\n",
      "   380       18.3726             nan     0.0010    0.0031\n",
      "   400       18.2976             nan     0.0010    0.0033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.2819             nan     0.0010    0.0060\n",
      "     2       20.2714             nan     0.0010    0.0100\n",
      "     3       20.2607             nan     0.0010    0.0053\n",
      "     4       20.2524             nan     0.0010    0.0085\n",
      "     5       20.2460             nan     0.0010    0.0044\n",
      "     6       20.2361             nan     0.0010    0.0084\n",
      "     7       20.2246             nan     0.0010    0.0073\n",
      "     8       20.2129             nan     0.0010    0.0069\n",
      "     9       20.2041             nan     0.0010    0.0063\n",
      "    10       20.1969             nan     0.0010    0.0017\n",
      "    20       20.1046             nan     0.0010    0.0050\n",
      "    40       19.9191             nan     0.0010    0.0088\n",
      "    60       19.7214             nan     0.0010    0.0083\n",
      "    80       19.5340             nan     0.0010    0.0088\n",
      "   100       19.3579             nan     0.0010    0.0074\n",
      "   120       19.1936             nan     0.0010    0.0062\n",
      "   140       19.0280             nan     0.0010    0.0086\n",
      "   160       18.8546             nan     0.0010    0.0047\n",
      "   180       18.6928             nan     0.0010    0.0063\n",
      "   200       18.5397             nan     0.0010    0.0010\n",
      "   220       18.3945             nan     0.0010    0.0053\n",
      "   240       18.2500             nan     0.0010    0.0069\n",
      "   260       18.1097             nan     0.0010    0.0037\n",
      "   280       17.9693             nan     0.0010    0.0041\n",
      "   300       17.8313             nan     0.0010    0.0041\n",
      "   320       17.6979             nan     0.0010    0.0048\n",
      "   340       17.5594             nan     0.0010    0.0044\n",
      "   360       17.4333             nan     0.0010    0.0058\n",
      "   380       17.3113             nan     0.0010    0.0027\n",
      "   400       17.1869             nan     0.0010    0.0037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.2760             nan     0.0010    0.0110\n",
      "     2       20.2621             nan     0.0010    0.0096\n",
      "     3       20.2501             nan     0.0010    0.0103\n",
      "     4       20.2369             nan     0.0010    0.0108\n",
      "     5       20.2254             nan     0.0010    0.0098\n",
      "     6       20.2151             nan     0.0010    0.0056\n",
      "     7       20.2038             nan     0.0010    0.0063\n",
      "     8       20.1892             nan     0.0010    0.0103\n",
      "     9       20.1779             nan     0.0010    0.0077\n",
      "    10       20.1657             nan     0.0010    0.0081\n",
      "    20       20.0515             nan     0.0010    0.0082\n",
      "    40       19.8147             nan     0.0010    0.0082\n",
      "    60       19.5957             nan     0.0010    0.0116\n",
      "    80       19.3696             nan     0.0010    0.0085\n",
      "   100       19.1459             nan     0.0010    0.0083\n",
      "   120       18.9427             nan     0.0010    0.0082\n",
      "   140       18.7437             nan     0.0010    0.0090\n",
      "   160       18.5519             nan     0.0010    0.0048\n",
      "   180       18.3799             nan     0.0010    0.0086\n",
      "   200       18.1841             nan     0.0010    0.0060\n",
      "   220       17.9964             nan     0.0010    0.0055\n",
      "   240       17.8153             nan     0.0010    0.0062\n",
      "   260       17.6426             nan     0.0010    0.0075\n",
      "   280       17.4803             nan     0.0010    0.0060\n",
      "   300       17.3259             nan     0.0010    0.0059\n",
      "   320       17.1585             nan     0.0010    0.0067\n",
      "   340       17.0096             nan     0.0010    0.0052\n",
      "   360       16.8490             nan     0.0010    0.0041\n",
      "   380       16.6993             nan     0.0010    0.0041\n",
      "   400       16.5541             nan     0.0010    0.0032\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.2411             nan     0.0100    0.0628\n",
      "     2       20.1780             nan     0.0100    0.0647\n",
      "     3       20.1162             nan     0.0100    0.0681\n",
      "     4       20.0448             nan     0.0100    0.0488\n",
      "     5       19.9890             nan     0.0100    0.0733\n",
      "     6       19.9414             nan     0.0100    0.0536\n",
      "     7       19.8749             nan     0.0100    0.0474\n",
      "     8       19.8020             nan     0.0100    0.0548\n",
      "     9       19.7343             nan     0.0100    0.0524\n",
      "    10       19.6870             nan     0.0100    0.0570\n",
      "    20       19.1941             nan     0.0100    0.0444\n",
      "    40       18.3123             nan     0.0100    0.0134\n",
      "    60       17.6473             nan     0.0100    0.0273\n",
      "    80       17.1014             nan     0.0100    0.0154\n",
      "   100       16.6643             nan     0.0100    0.0171\n",
      "   120       16.3726             nan     0.0100    0.0033\n",
      "   140       16.0764             nan     0.0100   -0.0003\n",
      "   160       15.7870             nan     0.0100   -0.0042\n",
      "   180       15.5242             nan     0.0100    0.0018\n",
      "   200       15.2751             nan     0.0100   -0.0020\n",
      "   220       15.0363             nan     0.0100    0.0036\n",
      "   240       14.8334             nan     0.0100   -0.0014\n",
      "   260       14.6509             nan     0.0100   -0.0028\n",
      "   280       14.4607             nan     0.0100   -0.0009\n",
      "   300       14.2921             nan     0.0100   -0.0009\n",
      "   320       14.1272             nan     0.0100   -0.0022\n",
      "   340       13.9794             nan     0.0100   -0.0057\n",
      "   360       13.8471             nan     0.0100    0.0034\n",
      "   380       13.7026             nan     0.0100    0.0004\n",
      "   400       13.5796             nan     0.0100    0.0009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.1914             nan     0.0100    0.0647\n",
      "     2       20.1081             nan     0.0100    0.0396\n",
      "     3       20.0013             nan     0.0100    0.0788\n",
      "     4       19.8992             nan     0.0100    0.0803\n",
      "     5       19.7771             nan     0.0100    0.0654\n",
      "     6       19.6681             nan     0.0100    0.0924\n",
      "     7       19.5897             nan     0.0100    0.0196\n",
      "     8       19.4952             nan     0.0100    0.0451\n",
      "     9       19.4215             nan     0.0100    0.0577\n",
      "    10       19.3280             nan     0.0100    0.0588\n",
      "    20       18.5355             nan     0.0100    0.0639\n",
      "    40       17.2380             nan     0.0100    0.0436\n",
      "    60       16.2222             nan     0.0100    0.0066\n",
      "    80       15.2480             nan     0.0100    0.0169\n",
      "   100       14.4796             nan     0.0100    0.0184\n",
      "   120       13.8867             nan     0.0100   -0.0045\n",
      "   140       13.3171             nan     0.0100   -0.0005\n",
      "   160       12.8633             nan     0.0100    0.0006\n",
      "   180       12.4256             nan     0.0100    0.0061\n",
      "   200       12.0603             nan     0.0100    0.0142\n",
      "   220       11.7061             nan     0.0100   -0.0042\n",
      "   240       11.3936             nan     0.0100    0.0052\n",
      "   260       11.0794             nan     0.0100   -0.0063\n",
      "   280       10.8025             nan     0.0100   -0.0081\n",
      "   300       10.5592             nan     0.0100    0.0011\n",
      "   320       10.3287             nan     0.0100    0.0022\n",
      "   340       10.1330             nan     0.0100   -0.0178\n",
      "   360        9.9427             nan     0.0100   -0.0011\n",
      "   380        9.7491             nan     0.0100   -0.0135\n",
      "   400        9.5697             nan     0.0100   -0.0045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.1369             nan     0.0100    0.0949\n",
      "     2       20.0214             nan     0.0100    0.0634\n",
      "     3       19.9259             nan     0.0100    0.0780\n",
      "     4       19.7954             nan     0.0100    0.1017\n",
      "     5       19.6801             nan     0.0100    0.0847\n",
      "     6       19.5953             nan     0.0100    0.0852\n",
      "     7       19.4999             nan     0.0100    0.0675\n",
      "     8       19.4044             nan     0.0100    0.0461\n",
      "     9       19.3007             nan     0.0100    0.0905\n",
      "    10       19.1973             nan     0.0100    0.0787\n",
      "    20       18.2737             nan     0.0100    0.0381\n",
      "    40       16.6908             nan     0.0100    0.0194\n",
      "    60       15.3585             nan     0.0100    0.0367\n",
      "    80       14.2911             nan     0.0100    0.0231\n",
      "   100       13.3780             nan     0.0100    0.0120\n",
      "   120       12.6541             nan     0.0100   -0.0034\n",
      "   140       12.0048             nan     0.0100    0.0087\n",
      "   160       11.4553             nan     0.0100    0.0008\n",
      "   180       10.9638             nan     0.0100   -0.0048\n",
      "   200       10.5156             nan     0.0100   -0.0129\n",
      "   220       10.1205             nan     0.0100   -0.0015\n",
      "   240        9.7299             nan     0.0100   -0.0019\n",
      "   260        9.4169             nan     0.0100   -0.0049\n",
      "   280        9.1065             nan     0.0100   -0.0065\n",
      "   300        8.8392             nan     0.0100   -0.0020\n",
      "   320        8.5990             nan     0.0100   -0.0038\n",
      "   340        8.3713             nan     0.0100   -0.0014\n",
      "   360        8.1318             nan     0.0100   -0.0064\n",
      "   380        7.9305             nan     0.0100   -0.0043\n",
      "   400        7.7369             nan     0.0100   -0.0130\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.5910             nan     0.1000    0.7010\n",
      "     2       19.1384             nan     0.1000    0.4733\n",
      "     3       18.7377             nan     0.1000    0.3750\n",
      "     4       18.4134             nan     0.1000    0.1640\n",
      "     5       17.9303             nan     0.1000    0.3213\n",
      "     6       17.6958             nan     0.1000    0.0346\n",
      "     7       17.3886             nan     0.1000    0.2679\n",
      "     8       17.1448             nan     0.1000    0.2754\n",
      "     9       16.9061             nan     0.1000    0.2559\n",
      "    10       16.6031             nan     0.1000    0.1390\n",
      "    20       15.2660             nan     0.1000    0.0648\n",
      "    40       13.9113             nan     0.1000   -0.0508\n",
      "    60       12.7577             nan     0.1000   -0.0195\n",
      "    80       12.0673             nan     0.1000   -0.0091\n",
      "   100       11.5632             nan     0.1000   -0.0163\n",
      "   120       11.2621             nan     0.1000   -0.0193\n",
      "   140       11.0614             nan     0.1000   -0.1029\n",
      "   160       10.9089             nan     0.1000   -0.1131\n",
      "   180       10.7111             nan     0.1000   -0.0463\n",
      "   200       10.6044             nan     0.1000   -0.0565\n",
      "   220       10.4896             nan     0.1000   -0.0232\n",
      "   240       10.3841             nan     0.1000   -0.1409\n",
      "   260       10.3392             nan     0.1000   -0.0920\n",
      "   280       10.2637             nan     0.1000   -0.0345\n",
      "   300       10.2118             nan     0.1000   -0.0463\n",
      "   320       10.1636             nan     0.1000   -0.0617\n",
      "   340       10.1343             nan     0.1000   -0.0766\n",
      "   360       10.0866             nan     0.1000   -0.1214\n",
      "   380       10.0330             nan     0.1000   -0.0673\n",
      "   400        9.9762             nan     0.1000   -0.1099\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.6050             nan     0.1000    0.3418\n",
      "     2       18.9639             nan     0.1000    0.5074\n",
      "     3       17.8965             nan     0.1000    0.4404\n",
      "     4       17.1360             nan     0.1000    0.4572\n",
      "     5       16.5834             nan     0.1000    0.2598\n",
      "     6       16.0250             nan     0.1000   -0.0420\n",
      "     7       15.5675             nan     0.1000    0.2155\n",
      "     8       15.2039             nan     0.1000    0.1641\n",
      "     9       14.8723             nan     0.1000    0.2398\n",
      "    10       14.5502             nan     0.1000    0.0932\n",
      "    20       12.2267             nan     0.1000    0.0531\n",
      "    40       10.0777             nan     0.1000   -0.0409\n",
      "    60        8.7455             nan     0.1000    0.0012\n",
      "    80        7.8535             nan     0.1000   -0.0553\n",
      "   100        7.1706             nan     0.1000   -0.0812\n",
      "   120        6.6932             nan     0.1000   -0.0315\n",
      "   140        6.2214             nan     0.1000   -0.1618\n",
      "   160        5.7487             nan     0.1000   -0.0596\n",
      "   180        5.4291             nan     0.1000   -0.0662\n",
      "   200        5.1338             nan     0.1000   -0.0488\n",
      "   220        4.8422             nan     0.1000   -0.0940\n",
      "   240        4.5664             nan     0.1000   -0.0360\n",
      "   260        4.3038             nan     0.1000   -0.0174\n",
      "   280        4.0578             nan     0.1000   -0.0330\n",
      "   300        3.8470             nan     0.1000   -0.0312\n",
      "   320        3.6551             nan     0.1000   -0.0735\n",
      "   340        3.4415             nan     0.1000   -0.0674\n",
      "   360        3.2876             nan     0.1000   -0.0384\n",
      "   380        3.0652             nan     0.1000   -0.0620\n",
      "   400        2.9024             nan     0.1000   -0.0253\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.3027             nan     0.1000    0.4704\n",
      "     2       18.2551             nan     0.1000    0.6576\n",
      "     3       17.1449             nan     0.1000    0.8407\n",
      "     4       16.2130             nan     0.1000    0.5952\n",
      "     5       15.3862             nan     0.1000    0.4682\n",
      "     6       14.8961             nan     0.1000    0.2236\n",
      "     7       14.5673             nan     0.1000    0.0577\n",
      "     8       14.1260             nan     0.1000    0.0774\n",
      "     9       13.7622             nan     0.1000    0.1093\n",
      "    10       13.1854             nan     0.1000    0.2255\n",
      "    20       10.5226             nan     0.1000   -0.1079\n",
      "    40        7.9321             nan     0.1000   -0.0128\n",
      "    60        6.6506             nan     0.1000   -0.0837\n",
      "    80        5.5337             nan     0.1000   -0.0366\n",
      "   100        4.7002             nan     0.1000   -0.0648\n",
      "   120        4.1490             nan     0.1000   -0.0412\n",
      "   140        3.7118             nan     0.1000   -0.0331\n",
      "   160        3.3555             nan     0.1000   -0.0540\n",
      "   180        2.9833             nan     0.1000   -0.0331\n",
      "   200        2.6637             nan     0.1000   -0.0395\n",
      "   220        2.3786             nan     0.1000   -0.0606\n",
      "   240        2.1375             nan     0.1000   -0.0204\n",
      "   260        1.9157             nan     0.1000   -0.0450\n",
      "   280        1.7522             nan     0.1000   -0.0399\n",
      "   300        1.5808             nan     0.1000   -0.0292\n",
      "   320        1.4492             nan     0.1000   -0.0337\n",
      "   340        1.2935             nan     0.1000   -0.0376\n",
      "   360        1.1813             nan     0.1000   -0.0253\n",
      "   380        1.0700             nan     0.1000   -0.0201\n",
      "   400        0.9859             nan     0.1000   -0.0159\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.0865             nan     0.0010    0.0053\n",
      "     2       21.0795             nan     0.0010    0.0063\n",
      "     3       21.0732             nan     0.0010    0.0070\n",
      "     4       21.0675             nan     0.0010    0.0061\n",
      "     5       21.0607             nan     0.0010    0.0052\n",
      "     6       21.0572             nan     0.0010    0.0037\n",
      "     7       21.0537             nan     0.0010    0.0020\n",
      "     8       21.0468             nan     0.0010    0.0073\n",
      "     9       21.0397             nan     0.0010    0.0064\n",
      "    10       21.0324             nan     0.0010    0.0047\n",
      "    20       20.9726             nan     0.0010    0.0008\n",
      "    40       20.8502             nan     0.0010    0.0053\n",
      "    60       20.7273             nan     0.0010    0.0065\n",
      "    80       20.6169             nan     0.0010    0.0068\n",
      "   100       20.5049             nan     0.0010    0.0049\n",
      "   120       20.3905             nan     0.0010    0.0040\n",
      "   140       20.2887             nan     0.0010    0.0049\n",
      "   160       20.1791             nan     0.0010    0.0022\n",
      "   180       20.0790             nan     0.0010    0.0018\n",
      "   200       19.9849             nan     0.0010    0.0048\n",
      "   220       19.8924             nan     0.0010    0.0021\n",
      "   240       19.8040             nan     0.0010    0.0040\n",
      "   260       19.7036             nan     0.0010    0.0044\n",
      "   280       19.6120             nan     0.0010    0.0041\n",
      "   300       19.5323             nan     0.0010    0.0036\n",
      "   320       19.4553             nan     0.0010    0.0036\n",
      "   340       19.3787             nan     0.0010    0.0037\n",
      "   360       19.3008             nan     0.0010    0.0039\n",
      "   380       19.2250             nan     0.0010    0.0032\n",
      "   400       19.1516             nan     0.0010    0.0037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.0803             nan     0.0010    0.0095\n",
      "     2       21.0705             nan     0.0010    0.0080\n",
      "     3       21.0599             nan     0.0010    0.0063\n",
      "     4       21.0494             nan     0.0010    0.0065\n",
      "     5       21.0388             nan     0.0010    0.0089\n",
      "     6       21.0289             nan     0.0010    0.0088\n",
      "     7       21.0177             nan     0.0010    0.0095\n",
      "     8       21.0082             nan     0.0010    0.0076\n",
      "     9       20.9973             nan     0.0010    0.0090\n",
      "    10       20.9874             nan     0.0010    0.0077\n",
      "    20       20.8882             nan     0.0010    0.0053\n",
      "    40       20.6914             nan     0.0010    0.0040\n",
      "    60       20.4876             nan     0.0010    0.0090\n",
      "    80       20.2933             nan     0.0010    0.0083\n",
      "   100       20.1135             nan     0.0010    0.0078\n",
      "   120       19.9208             nan     0.0010    0.0080\n",
      "   140       19.7469             nan     0.0010    0.0039\n",
      "   160       19.5739             nan     0.0010    0.0090\n",
      "   180       19.4118             nan     0.0010    0.0053\n",
      "   200       19.2498             nan     0.0010    0.0071\n",
      "   220       19.0992             nan     0.0010    0.0058\n",
      "   240       18.9421             nan     0.0010    0.0067\n",
      "   260       18.7876             nan     0.0010    0.0065\n",
      "   280       18.6486             nan     0.0010    0.0021\n",
      "   300       18.4951             nan     0.0010    0.0056\n",
      "   320       18.3616             nan     0.0010    0.0040\n",
      "   340       18.2125             nan     0.0010    0.0064\n",
      "   360       18.0893             nan     0.0010    0.0050\n",
      "   380       17.9648             nan     0.0010    0.0018\n",
      "   400       17.8368             nan     0.0010    0.0049\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.0814             nan     0.0010    0.0075\n",
      "     2       21.0689             nan     0.0010    0.0086\n",
      "     3       21.0576             nan     0.0010    0.0063\n",
      "     4       21.0440             nan     0.0010    0.0115\n",
      "     5       21.0342             nan     0.0010    0.0063\n",
      "     6       21.0256             nan     0.0010    0.0056\n",
      "     7       21.0116             nan     0.0010    0.0093\n",
      "     8       21.0012             nan     0.0010    0.0090\n",
      "     9       20.9906             nan     0.0010    0.0071\n",
      "    10       20.9771             nan     0.0010    0.0089\n",
      "    20       20.8590             nan     0.0010    0.0095\n",
      "    40       20.6314             nan     0.0010    0.0097\n",
      "    60       20.4032             nan     0.0010    0.0099\n",
      "    80       20.1777             nan     0.0010    0.0097\n",
      "   100       19.9434             nan     0.0010    0.0097\n",
      "   120       19.7404             nan     0.0010    0.0068\n",
      "   140       19.5322             nan     0.0010    0.0069\n",
      "   160       19.3352             nan     0.0010    0.0081\n",
      "   180       19.1310             nan     0.0010    0.0090\n",
      "   200       18.9454             nan     0.0010    0.0062\n",
      "   220       18.7468             nan     0.0010    0.0080\n",
      "   240       18.5654             nan     0.0010    0.0055\n",
      "   260       18.3804             nan     0.0010    0.0066\n",
      "   280       18.2110             nan     0.0010    0.0010\n",
      "   300       18.0416             nan     0.0010    0.0052\n",
      "   320       17.8770             nan     0.0010    0.0045\n",
      "   340       17.7055             nan     0.0010    0.0062\n",
      "   360       17.5519             nan     0.0010    0.0057\n",
      "   380       17.3976             nan     0.0010    0.0036\n",
      "   400       17.2421             nan     0.0010    0.0040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       21.0331             nan     0.0100    0.0298\n",
      "     2       20.9729             nan     0.0100    0.0650\n",
      "     3       20.9083             nan     0.0100    0.0529\n",
      "     4       20.8497             nan     0.0100    0.0623\n",
      "     5       20.7847             nan     0.0100    0.0627\n",
      "     6       20.7158             nan     0.0100    0.0463\n",
      "     7       20.6526             nan     0.0100    0.0443\n",
      "     8       20.6023             nan     0.0100    0.0576\n",
      "     9       20.5431             nan     0.0100    0.0505\n",
      "    10       20.4885             nan     0.0100    0.0606\n",
      "    20       19.9893             nan     0.0100    0.0426\n",
      "    40       19.1821             nan     0.0100    0.0236\n",
      "    60       18.4829             nan     0.0100    0.0187\n",
      "    80       17.9418             nan     0.0100    0.0215\n",
      "   100       17.4564             nan     0.0100    0.0024\n",
      "   120       17.0400             nan     0.0100    0.0074\n",
      "   140       16.6956             nan     0.0100    0.0073\n",
      "   160       16.4093             nan     0.0100   -0.0026\n",
      "   180       16.1230             nan     0.0100    0.0094\n",
      "   200       15.8503             nan     0.0100    0.0002\n",
      "   220       15.6034             nan     0.0100    0.0043\n",
      "   240       15.3643             nan     0.0100    0.0032\n",
      "   260       15.1516             nan     0.0100   -0.0006\n",
      "   280       14.9613             nan     0.0100    0.0023\n",
      "   300       14.7871             nan     0.0100   -0.0107\n",
      "   320       14.6493             nan     0.0100    0.0019\n",
      "   340       14.4849             nan     0.0100   -0.0032\n",
      "   360       14.3347             nan     0.0100   -0.0048\n",
      "   380       14.1860             nan     0.0100   -0.0010\n",
      "   400       14.0373             nan     0.0100   -0.0002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.9648             nan     0.0100    0.0865\n",
      "     2       20.8468             nan     0.0100    0.0765\n",
      "     3       20.7482             nan     0.0100    0.0558\n",
      "     4       20.6465             nan     0.0100    0.0988\n",
      "     5       20.5384             nan     0.0100    0.0755\n",
      "     6       20.4421             nan     0.0100    0.0801\n",
      "     7       20.3852             nan     0.0100    0.0329\n",
      "     8       20.2935             nan     0.0100    0.0662\n",
      "     9       20.1650             nan     0.0100    0.0733\n",
      "    10       20.0801             nan     0.0100    0.0692\n",
      "    20       19.2643             nan     0.0100    0.0611\n",
      "    40       17.7822             nan     0.0100    0.0378\n",
      "    60       16.6617             nan     0.0100    0.0398\n",
      "    80       15.7509             nan     0.0100    0.0217\n",
      "   100       15.0274             nan     0.0100   -0.0038\n",
      "   120       14.3552             nan     0.0100    0.0015\n",
      "   140       13.8170             nan     0.0100    0.0024\n",
      "   160       13.3412             nan     0.0100    0.0027\n",
      "   180       12.8533             nan     0.0100   -0.0072\n",
      "   200       12.4277             nan     0.0100   -0.0032\n",
      "   220       12.0580             nan     0.0100   -0.0073\n",
      "   240       11.7013             nan     0.0100   -0.0032\n",
      "   260       11.3904             nan     0.0100   -0.0134\n",
      "   280       11.0845             nan     0.0100   -0.0087\n",
      "   300       10.8194             nan     0.0100    0.0034\n",
      "   320       10.5738             nan     0.0100   -0.0062\n",
      "   340       10.3239             nan     0.0100   -0.0012\n",
      "   360       10.1322             nan     0.0100   -0.0059\n",
      "   380        9.9258             nan     0.0100    0.0006\n",
      "   400        9.7517             nan     0.0100   -0.0006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.9645             nan     0.0100    0.0917\n",
      "     2       20.8239             nan     0.0100    0.1181\n",
      "     3       20.7049             nan     0.0100    0.0608\n",
      "     4       20.5959             nan     0.0100    0.0606\n",
      "     5       20.4700             nan     0.0100    0.0847\n",
      "     6       20.3697             nan     0.0100    0.0794\n",
      "     7       20.2859             nan     0.0100    0.0519\n",
      "     8       20.2200             nan     0.0100    0.0295\n",
      "     9       20.1179             nan     0.0100    0.0902\n",
      "    10       20.0131             nan     0.0100    0.0893\n",
      "    20       18.9531             nan     0.0100    0.0615\n",
      "    40       17.2410             nan     0.0100    0.0535\n",
      "    60       15.8947             nan     0.0100    0.0417\n",
      "    80       14.7248             nan     0.0100    0.0473\n",
      "   100       13.7882             nan     0.0100    0.0257\n",
      "   120       12.9273             nan     0.0100    0.0208\n",
      "   140       12.2679             nan     0.0100    0.0096\n",
      "   160       11.6687             nan     0.0100   -0.0022\n",
      "   180       11.1673             nan     0.0100   -0.0013\n",
      "   200       10.7017             nan     0.0100    0.0031\n",
      "   220       10.2934             nan     0.0100   -0.0102\n",
      "   240        9.9018             nan     0.0100   -0.0137\n",
      "   260        9.6010             nan     0.0100   -0.0088\n",
      "   280        9.2883             nan     0.0100   -0.0083\n",
      "   300        8.9709             nan     0.0100   -0.0008\n",
      "   320        8.7103             nan     0.0100   -0.0130\n",
      "   340        8.4608             nan     0.0100   -0.0066\n",
      "   360        8.2543             nan     0.0100   -0.0100\n",
      "   380        8.0566             nan     0.0100   -0.0163\n",
      "   400        7.8802             nan     0.0100   -0.0119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.4261             nan     0.1000    0.4064\n",
      "     2       19.9519             nan     0.1000    0.4475\n",
      "     3       19.5525             nan     0.1000    0.2732\n",
      "     4       18.9931             nan     0.1000    0.3918\n",
      "     5       18.7173             nan     0.1000    0.2467\n",
      "     6       18.3806             nan     0.1000    0.2697\n",
      "     7       18.0361             nan     0.1000    0.2079\n",
      "     8       17.7933             nan     0.1000    0.1725\n",
      "     9       17.5119             nan     0.1000    0.0377\n",
      "    10       17.2955             nan     0.1000    0.0968\n",
      "    20       15.6980             nan     0.1000   -0.0082\n",
      "    40       14.0955             nan     0.1000   -0.2152\n",
      "    60       13.0786             nan     0.1000   -0.1508\n",
      "    80       12.4764             nan     0.1000   -0.0947\n",
      "   100       11.9927             nan     0.1000   -0.0352\n",
      "   120       11.6132             nan     0.1000   -0.0371\n",
      "   140       11.3986             nan     0.1000   -0.0393\n",
      "   160       11.1612             nan     0.1000   -0.0337\n",
      "   180       11.0223             nan     0.1000   -0.0942\n",
      "   200       10.9460             nan     0.1000   -0.0652\n",
      "   220       10.8322             nan     0.1000   -0.0911\n",
      "   240       10.7356             nan     0.1000   -0.0709\n",
      "   260       10.6890             nan     0.1000   -0.0823\n",
      "   280       10.6740             nan     0.1000   -0.0365\n",
      "   300       10.6072             nan     0.1000   -0.0628\n",
      "   320       10.5608             nan     0.1000   -0.0488\n",
      "   340       10.5132             nan     0.1000   -0.1144\n",
      "   360       10.5104             nan     0.1000   -0.0522\n",
      "   380       10.4696             nan     0.1000   -0.1108\n",
      "   400       10.4262             nan     0.1000   -0.0498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.1058             nan     0.1000    0.7794\n",
      "     2       19.3775             nan     0.1000    0.5579\n",
      "     3       18.6525             nan     0.1000    0.6427\n",
      "     4       17.8486             nan     0.1000    0.5270\n",
      "     5       17.1811             nan     0.1000    0.2284\n",
      "     6       16.6554             nan     0.1000    0.3887\n",
      "     7       16.2215             nan     0.1000    0.1871\n",
      "     8       15.7394             nan     0.1000    0.2712\n",
      "     9       15.2957             nan     0.1000    0.3408\n",
      "    10       14.8512             nan     0.1000    0.0094\n",
      "    20       12.5861             nan     0.1000   -0.0400\n",
      "    40       10.0948             nan     0.1000   -0.0653\n",
      "    60        8.7349             nan     0.1000   -0.0951\n",
      "    80        7.7887             nan     0.1000   -0.0269\n",
      "   100        7.0492             nan     0.1000   -0.0752\n",
      "   120        6.3713             nan     0.1000   -0.0868\n",
      "   140        5.9312             nan     0.1000   -0.0865\n",
      "   160        5.4767             nan     0.1000   -0.0754\n",
      "   180        5.0997             nan     0.1000   -0.0593\n",
      "   200        4.7777             nan     0.1000   -0.0571\n",
      "   220        4.4699             nan     0.1000   -0.0707\n",
      "   240        4.2407             nan     0.1000   -0.0396\n",
      "   260        3.9709             nan     0.1000   -0.0667\n",
      "   280        3.7024             nan     0.1000   -0.0515\n",
      "   300        3.5202             nan     0.1000   -0.0602\n",
      "   320        3.3418             nan     0.1000   -0.0347\n",
      "   340        3.1582             nan     0.1000   -0.0333\n",
      "   360        2.9692             nan     0.1000   -0.0251\n",
      "   380        2.8281             nan     0.1000   -0.0477\n",
      "   400        2.6584             nan     0.1000   -0.0246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.6541             nan     0.1000    0.9657\n",
      "     2       18.5186             nan     0.1000    0.6643\n",
      "     3       17.6048             nan     0.1000    0.5208\n",
      "     4       16.9045             nan     0.1000    0.2432\n",
      "     5       16.3327             nan     0.1000    0.2220\n",
      "     6       15.6939             nan     0.1000    0.2530\n",
      "     7       15.1438             nan     0.1000    0.3562\n",
      "     8       14.5911             nan     0.1000    0.3843\n",
      "     9       14.1628             nan     0.1000    0.2822\n",
      "    10       13.5298             nan     0.1000    0.1282\n",
      "    20       10.5094             nan     0.1000   -0.0492\n",
      "    40        8.1376             nan     0.1000   -0.0653\n",
      "    60        6.6876             nan     0.1000   -0.0939\n",
      "    80        5.7089             nan     0.1000   -0.0663\n",
      "   100        4.9025             nan     0.1000   -0.0582\n",
      "   120        4.3250             nan     0.1000   -0.0601\n",
      "   140        3.8251             nan     0.1000   -0.0653\n",
      "   160        3.3678             nan     0.1000   -0.0778\n",
      "   180        2.9660             nan     0.1000   -0.0346\n",
      "   200        2.6867             nan     0.1000   -0.0488\n",
      "   220        2.3828             nan     0.1000   -0.0226\n",
      "   240        2.1325             nan     0.1000   -0.0531\n",
      "   260        1.8869             nan     0.1000   -0.0312\n",
      "   280        1.6945             nan     0.1000   -0.0277\n",
      "   300        1.5325             nan     0.1000   -0.0456\n",
      "   320        1.3706             nan     0.1000   -0.0310\n",
      "   340        1.2595             nan     0.1000   -0.0200\n",
      "   360        1.1312             nan     0.1000   -0.0299\n",
      "   380        1.0383             nan     0.1000   -0.0132\n",
      "   400        0.9404             nan     0.1000   -0.0147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.8421             nan     0.0010    0.0058\n",
      "     2       20.8365             nan     0.0010    0.0058\n",
      "     3       20.8310             nan     0.0010    0.0058\n",
      "     4       20.8263             nan     0.0010    0.0059\n",
      "     5       20.8207             nan     0.0010    0.0057\n",
      "     6       20.8170             nan     0.0010    0.0026\n",
      "     7       20.8108             nan     0.0010    0.0065\n",
      "     8       20.8041             nan     0.0010    0.0058\n",
      "     9       20.7973             nan     0.0010    0.0049\n",
      "    10       20.7921             nan     0.0010    0.0054\n",
      "    20       20.7304             nan     0.0010    0.0022\n",
      "    40       20.6070             nan     0.0010    0.0051\n",
      "    60       20.4946             nan     0.0010    0.0005\n",
      "    80       20.3891             nan     0.0010    0.0023\n",
      "   100       20.2851             nan     0.0010    0.0023\n",
      "   120       20.1868             nan     0.0010    0.0049\n",
      "   140       20.0795             nan     0.0010    0.0041\n",
      "   160       19.9743             nan     0.0010    0.0038\n",
      "   180       19.8812             nan     0.0010    0.0041\n",
      "   200       19.7881             nan     0.0010    0.0043\n",
      "   220       19.7040             nan     0.0010   -0.0014\n",
      "   240       19.6180             nan     0.0010    0.0038\n",
      "   260       19.5422             nan     0.0010    0.0041\n",
      "   280       19.4563             nan     0.0010    0.0040\n",
      "   300       19.3688             nan     0.0010    0.0033\n",
      "   320       19.2889             nan     0.0010    0.0039\n",
      "   340       19.2148             nan     0.0010    0.0021\n",
      "   360       19.1393             nan     0.0010    0.0037\n",
      "   380       19.0654             nan     0.0010    0.0018\n",
      "   400       18.9932             nan     0.0010   -0.0008\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.8377             nan     0.0010    0.0079\n",
      "     2       20.8280             nan     0.0010    0.0082\n",
      "     3       20.8182             nan     0.0010    0.0041\n",
      "     4       20.8104             nan     0.0010    0.0073\n",
      "     5       20.8011             nan     0.0010    0.0087\n",
      "     6       20.7931             nan     0.0010    0.0045\n",
      "     7       20.7806             nan     0.0010    0.0045\n",
      "     8       20.7703             nan     0.0010    0.0092\n",
      "     9       20.7611             nan     0.0010    0.0067\n",
      "    10       20.7516             nan     0.0010    0.0082\n",
      "    20       20.6524             nan     0.0010    0.0053\n",
      "    40       20.4753             nan     0.0010    0.0085\n",
      "    60       20.2886             nan     0.0010    0.0069\n",
      "    80       20.1125             nan     0.0010    0.0051\n",
      "   100       19.9386             nan     0.0010    0.0046\n",
      "   120       19.7702             nan     0.0010    0.0036\n",
      "   140       19.6175             nan     0.0010    0.0057\n",
      "   160       19.4479             nan     0.0010    0.0066\n",
      "   180       19.2882             nan     0.0010    0.0081\n",
      "   200       19.1299             nan     0.0010    0.0059\n",
      "   220       18.9790             nan     0.0010    0.0057\n",
      "   240       18.8270             nan     0.0010    0.0053\n",
      "   260       18.6892             nan     0.0010    0.0041\n",
      "   280       18.5644             nan     0.0010    0.0038\n",
      "   300       18.4265             nan     0.0010    0.0040\n",
      "   320       18.2957             nan     0.0010    0.0011\n",
      "   340       18.1686             nan     0.0010    0.0057\n",
      "   360       18.0388             nan     0.0010    0.0059\n",
      "   380       17.9111             nan     0.0010    0.0043\n",
      "   400       17.7862             nan     0.0010    0.0032\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.8332             nan     0.0010    0.0098\n",
      "     2       20.8229             nan     0.0010    0.0055\n",
      "     3       20.8091             nan     0.0010    0.0103\n",
      "     4       20.7963             nan     0.0010    0.0077\n",
      "     5       20.7868             nan     0.0010    0.0065\n",
      "     6       20.7749             nan     0.0010    0.0056\n",
      "     7       20.7635             nan     0.0010    0.0086\n",
      "     8       20.7519             nan     0.0010    0.0093\n",
      "     9       20.7394             nan     0.0010    0.0085\n",
      "    10       20.7285             nan     0.0010    0.0084\n",
      "    20       20.6091             nan     0.0010    0.0059\n",
      "    40       20.3813             nan     0.0010    0.0093\n",
      "    60       20.1637             nan     0.0010    0.0091\n",
      "    80       19.9481             nan     0.0010    0.0048\n",
      "   100       19.7436             nan     0.0010    0.0063\n",
      "   120       19.5488             nan     0.0010    0.0045\n",
      "   140       19.3515             nan     0.0010    0.0081\n",
      "   160       19.1644             nan     0.0010    0.0082\n",
      "   180       18.9728             nan     0.0010    0.0065\n",
      "   200       18.7770             nan     0.0010    0.0057\n",
      "   220       18.6037             nan     0.0010    0.0024\n",
      "   240       18.4317             nan     0.0010    0.0064\n",
      "   260       18.2645             nan     0.0010    0.0033\n",
      "   280       18.0934             nan     0.0010    0.0092\n",
      "   300       17.9245             nan     0.0010    0.0070\n",
      "   320       17.7693             nan     0.0010    0.0060\n",
      "   340       17.6154             nan     0.0010    0.0012\n",
      "   360       17.4631             nan     0.0010    0.0066\n",
      "   380       17.3105             nan     0.0010    0.0055\n",
      "   400       17.1631             nan     0.0010    0.0023\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.7658             nan     0.0100    0.0654\n",
      "     2       20.7222             nan     0.0100    0.0130\n",
      "     3       20.6631             nan     0.0100    0.0521\n",
      "     4       20.5933             nan     0.0100    0.0588\n",
      "     5       20.5295             nan     0.0100    0.0635\n",
      "     6       20.4636             nan     0.0100    0.0679\n",
      "     7       20.4125             nan     0.0100    0.0496\n",
      "     8       20.3544             nan     0.0100    0.0591\n",
      "     9       20.3319             nan     0.0100   -0.0036\n",
      "    10       20.2897             nan     0.0100    0.0529\n",
      "    20       19.7672             nan     0.0100    0.0604\n",
      "    40       19.0179             nan     0.0100    0.0312\n",
      "    60       18.3429             nan     0.0100    0.0242\n",
      "    80       17.8086             nan     0.0100    0.0168\n",
      "   100       17.3856             nan     0.0100   -0.0006\n",
      "   120       17.0685             nan     0.0100    0.0056\n",
      "   140       16.7700             nan     0.0100   -0.0020\n",
      "   160       16.4466             nan     0.0100    0.0095\n",
      "   180       16.1621             nan     0.0100    0.0089\n",
      "   200       15.9313             nan     0.0100   -0.0074\n",
      "   220       15.7226             nan     0.0100    0.0003\n",
      "   240       15.5100             nan     0.0100    0.0023\n",
      "   260       15.2995             nan     0.0100   -0.0090\n",
      "   280       15.1481             nan     0.0100   -0.0089\n",
      "   300       14.9719             nan     0.0100    0.0025\n",
      "   320       14.8074             nan     0.0100   -0.0025\n",
      "   340       14.6506             nan     0.0100    0.0022\n",
      "   360       14.4989             nan     0.0100    0.0002\n",
      "   380       14.3714             nan     0.0100    0.0025\n",
      "   400       14.2381             nan     0.0100   -0.0049\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.7301             nan     0.0100    0.0649\n",
      "     2       20.6214             nan     0.0100    0.0564\n",
      "     3       20.5165             nan     0.0100    0.0514\n",
      "     4       20.4169             nan     0.0100    0.0439\n",
      "     5       20.3536             nan     0.0100    0.0325\n",
      "     6       20.2928             nan     0.0100    0.0448\n",
      "     7       20.2221             nan     0.0100    0.0435\n",
      "     8       20.1229             nan     0.0100    0.0749\n",
      "     9       20.0244             nan     0.0100    0.0704\n",
      "    10       19.9306             nan     0.0100    0.0779\n",
      "    20       19.1399             nan     0.0100    0.0472\n",
      "    40       17.7810             nan     0.0100    0.0296\n",
      "    60       16.6583             nan     0.0100    0.0077\n",
      "    80       15.8397             nan     0.0100    0.0218\n",
      "   100       15.0813             nan     0.0100    0.0184\n",
      "   120       14.4470             nan     0.0100    0.0133\n",
      "   140       13.9004             nan     0.0100    0.0161\n",
      "   160       13.4572             nan     0.0100   -0.0005\n",
      "   180       13.0077             nan     0.0100    0.0104\n",
      "   200       12.5935             nan     0.0100   -0.0009\n",
      "   220       12.2415             nan     0.0100    0.0072\n",
      "   240       11.9083             nan     0.0100    0.0124\n",
      "   260       11.6066             nan     0.0100    0.0016\n",
      "   280       11.3452             nan     0.0100   -0.0049\n",
      "   300       11.0772             nan     0.0100   -0.0033\n",
      "   320       10.8456             nan     0.0100   -0.0091\n",
      "   340       10.6371             nan     0.0100   -0.0042\n",
      "   360       10.4666             nan     0.0100   -0.0181\n",
      "   380       10.2688             nan     0.0100   -0.0072\n",
      "   400       10.0923             nan     0.0100   -0.0052\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.7362             nan     0.0100    0.0721\n",
      "     2       20.6150             nan     0.0100    0.0956\n",
      "     3       20.4817             nan     0.0100    0.1057\n",
      "     4       20.4024             nan     0.0100    0.0360\n",
      "     5       20.2893             nan     0.0100    0.0924\n",
      "     6       20.1869             nan     0.0100    0.0647\n",
      "     7       20.1045             nan     0.0100    0.0446\n",
      "     8       19.9714             nan     0.0100    0.0859\n",
      "     9       19.8724             nan     0.0100    0.0806\n",
      "    10       19.7883             nan     0.0100    0.0692\n",
      "    20       18.8434             nan     0.0100    0.0363\n",
      "    40       17.2599             nan     0.0100    0.0387\n",
      "    60       15.9909             nan     0.0100    0.0214\n",
      "    80       14.8579             nan     0.0100    0.0067\n",
      "   100       13.9753             nan     0.0100    0.0158\n",
      "   120       13.2129             nan     0.0100    0.0035\n",
      "   140       12.5704             nan     0.0100   -0.0068\n",
      "   160       11.9747             nan     0.0100    0.0161\n",
      "   180       11.4559             nan     0.0100   -0.0026\n",
      "   200       10.9672             nan     0.0100    0.0036\n",
      "   220       10.5643             nan     0.0100   -0.0150\n",
      "   240       10.2050             nan     0.0100   -0.0023\n",
      "   260        9.8513             nan     0.0100    0.0002\n",
      "   280        9.5451             nan     0.0100   -0.0047\n",
      "   300        9.2438             nan     0.0100   -0.0013\n",
      "   320        9.0027             nan     0.0100   -0.0086\n",
      "   340        8.7484             nan     0.0100   -0.0061\n",
      "   360        8.5490             nan     0.0100   -0.0092\n",
      "   380        8.3253             nan     0.0100   -0.0145\n",
      "   400        8.1240             nan     0.0100   -0.0097\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.1876             nan     0.1000    0.2870\n",
      "     2       19.6688             nan     0.1000    0.3812\n",
      "     3       19.2841             nan     0.1000    0.4044\n",
      "     4       18.9030             nan     0.1000    0.3589\n",
      "     5       18.5607             nan     0.1000    0.2195\n",
      "     6       18.2795             nan     0.1000    0.1595\n",
      "     7       17.9672             nan     0.1000    0.0237\n",
      "     8       17.7739             nan     0.1000    0.1567\n",
      "     9       17.5984             nan     0.1000    0.1220\n",
      "    10       17.4165             nan     0.1000    0.1710\n",
      "    20       16.0376             nan     0.1000    0.0388\n",
      "    40       14.3849             nan     0.1000   -0.0456\n",
      "    60       13.4465             nan     0.1000   -0.0405\n",
      "    80       12.6928             nan     0.1000   -0.0657\n",
      "   100       12.1862             nan     0.1000   -0.0811\n",
      "   120       11.8316             nan     0.1000   -0.0467\n",
      "   140       11.6196             nan     0.1000   -0.0609\n",
      "   160       11.4042             nan     0.1000   -0.0857\n",
      "   180       11.2342             nan     0.1000   -0.1137\n",
      "   200       11.1004             nan     0.1000   -0.0723\n",
      "   220       11.0152             nan     0.1000   -0.0802\n",
      "   240       10.9690             nan     0.1000   -0.0998\n",
      "   260       10.8859             nan     0.1000   -0.0717\n",
      "   280       10.8144             nan     0.1000   -0.0806\n",
      "   300       10.7337             nan     0.1000   -0.0550\n",
      "   320       10.6907             nan     0.1000   -0.0456\n",
      "   340       10.6784             nan     0.1000   -0.0582\n",
      "   360       10.6434             nan     0.1000   -0.0793\n",
      "   380       10.6225             nan     0.1000   -0.1016\n",
      "   400       10.5705             nan     0.1000   -0.0508\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.0463             nan     0.1000    0.4909\n",
      "     2       19.0287             nan     0.1000    0.6305\n",
      "     3       18.2459             nan     0.1000    0.5354\n",
      "     4       17.6777             nan     0.1000    0.4762\n",
      "     5       17.0872             nan     0.1000    0.3296\n",
      "     6       16.5884             nan     0.1000    0.3687\n",
      "     7       16.1275             nan     0.1000    0.3140\n",
      "     8       15.7273             nan     0.1000    0.2352\n",
      "     9       15.2167             nan     0.1000    0.1968\n",
      "    10       14.8680             nan     0.1000    0.2424\n",
      "    20       12.6703             nan     0.1000    0.0670\n",
      "    40       10.3546             nan     0.1000   -0.0447\n",
      "    60        9.1427             nan     0.1000   -0.0180\n",
      "    80        8.1496             nan     0.1000    0.0145\n",
      "   100        7.3601             nan     0.1000   -0.1135\n",
      "   120        6.7666             nan     0.1000   -0.0800\n",
      "   140        6.2319             nan     0.1000   -0.0207\n",
      "   160        5.7521             nan     0.1000   -0.0992\n",
      "   180        5.3313             nan     0.1000   -0.0597\n",
      "   200        4.9412             nan     0.1000   -0.0620\n",
      "   220        4.6587             nan     0.1000   -0.0597\n",
      "   240        4.3404             nan     0.1000   -0.0480\n",
      "   260        4.1239             nan     0.1000   -0.0322\n",
      "   280        3.8427             nan     0.1000   -0.0121\n",
      "   300        3.6381             nan     0.1000   -0.0614\n",
      "   320        3.4370             nan     0.1000   -0.0380\n",
      "   340        3.2557             nan     0.1000   -0.0283\n",
      "   360        3.0692             nan     0.1000   -0.0529\n",
      "   380        2.9102             nan     0.1000   -0.0230\n",
      "   400        2.7454             nan     0.1000   -0.0319\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.8412             nan     0.1000    0.9078\n",
      "     2       19.0234             nan     0.1000    0.3015\n",
      "     3       18.0487             nan     0.1000    0.8036\n",
      "     4       17.2917             nan     0.1000    0.5113\n",
      "     5       16.5860             nan     0.1000    0.2930\n",
      "     6       15.9241             nan     0.1000    0.1745\n",
      "     7       15.5539             nan     0.1000   -0.0699\n",
      "     8       14.9925             nan     0.1000    0.1995\n",
      "     9       14.5735             nan     0.1000    0.1916\n",
      "    10       14.2491             nan     0.1000    0.0801\n",
      "    20       11.1089             nan     0.1000   -0.0895\n",
      "    40        8.2222             nan     0.1000   -0.0369\n",
      "    60        6.8824             nan     0.1000   -0.0546\n",
      "    80        5.7874             nan     0.1000   -0.1250\n",
      "   100        4.7836             nan     0.1000   -0.0531\n",
      "   120        4.1904             nan     0.1000   -0.0492\n",
      "   140        3.7223             nan     0.1000   -0.0703\n",
      "   160        3.2313             nan     0.1000   -0.0527\n",
      "   180        2.8330             nan     0.1000   -0.0421\n",
      "   200        2.5284             nan     0.1000   -0.0310\n",
      "   220        2.2584             nan     0.1000   -0.0488\n",
      "   240        2.0072             nan     0.1000   -0.0157\n",
      "   260        1.7703             nan     0.1000   -0.0278\n",
      "   280        1.5828             nan     0.1000   -0.0340\n",
      "   300        1.4388             nan     0.1000   -0.0169\n",
      "   320        1.2940             nan     0.1000   -0.0156\n",
      "   340        1.1453             nan     0.1000   -0.0157\n",
      "   360        1.0210             nan     0.1000   -0.0130\n",
      "   380        0.9308             nan     0.1000   -0.0194\n",
      "   400        0.8505             nan     0.1000   -0.0184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.8204             nan     0.0010    0.0063\n",
      "     2       19.8137             nan     0.0010    0.0043\n",
      "     3       19.8081             nan     0.0010    0.0047\n",
      "     4       19.8049             nan     0.0010    0.0043\n",
      "     5       19.7995             nan     0.0010    0.0049\n",
      "     6       19.7947             nan     0.0010    0.0059\n",
      "     7       19.7887             nan     0.0010    0.0058\n",
      "     8       19.7817             nan     0.0010    0.0049\n",
      "     9       19.7762             nan     0.0010    0.0057\n",
      "    10       19.7714             nan     0.0010    0.0045\n",
      "    20       19.7128             nan     0.0010    0.0056\n",
      "    40       19.5979             nan     0.0010    0.0054\n",
      "    60       19.4897             nan     0.0010    0.0054\n",
      "    80       19.3929             nan     0.0010    0.0041\n",
      "   100       19.2954             nan     0.0010    0.0050\n",
      "   120       19.1997             nan     0.0010    0.0037\n",
      "   140       19.1101             nan     0.0010    0.0048\n",
      "   160       19.0187             nan     0.0010    0.0043\n",
      "   180       18.9328             nan     0.0010   -0.0004\n",
      "   200       18.8556             nan     0.0010    0.0037\n",
      "   220       18.7756             nan     0.0010    0.0043\n",
      "   240       18.7049             nan     0.0010    0.0016\n",
      "   260       18.6301             nan     0.0010    0.0043\n",
      "   280       18.5574             nan     0.0010    0.0014\n",
      "   300       18.4874             nan     0.0010    0.0033\n",
      "   320       18.4164             nan     0.0010    0.0029\n",
      "   340       18.3448             nan     0.0010    0.0028\n",
      "   360       18.2795             nan     0.0010    0.0031\n",
      "   380       18.2148             nan     0.0010    0.0032\n",
      "   400       18.1524             nan     0.0010    0.0024\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.8183             nan     0.0010    0.0061\n",
      "     2       19.8124             nan     0.0010    0.0058\n",
      "     3       19.8057             nan     0.0010    0.0066\n",
      "     4       19.7979             nan     0.0010    0.0069\n",
      "     5       19.7877             nan     0.0010    0.0066\n",
      "     6       19.7805             nan     0.0010    0.0045\n",
      "     7       19.7723             nan     0.0010    0.0052\n",
      "     8       19.7682             nan     0.0010    0.0013\n",
      "     9       19.7616             nan     0.0010    0.0063\n",
      "    10       19.7531             nan     0.0010    0.0072\n",
      "    20       19.6681             nan     0.0010    0.0067\n",
      "    40       19.5187             nan     0.0010    0.0028\n",
      "    60       19.3597             nan     0.0010    0.0044\n",
      "    80       19.2126             nan     0.0010    0.0054\n",
      "   100       19.0697             nan     0.0010    0.0048\n",
      "   120       18.9358             nan     0.0010    0.0047\n",
      "   140       18.7915             nan     0.0010    0.0037\n",
      "   160       18.6437             nan     0.0010    0.0044\n",
      "   180       18.5130             nan     0.0010    0.0033\n",
      "   200       18.3831             nan     0.0010    0.0028\n",
      "   220       18.2515             nan     0.0010    0.0058\n",
      "   240       18.1217             nan     0.0010    0.0054\n",
      "   260       18.0074             nan     0.0010    0.0057\n",
      "   280       17.8969             nan     0.0010    0.0021\n",
      "   300       17.7857             nan     0.0010    0.0004\n",
      "   320       17.6788             nan     0.0010    0.0029\n",
      "   340       17.5699             nan     0.0010    0.0028\n",
      "   360       17.4646             nan     0.0010    0.0006\n",
      "   380       17.3499             nan     0.0010    0.0026\n",
      "   400       17.2447             nan     0.0010    0.0029\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.8161             nan     0.0010    0.0087\n",
      "     2       19.8046             nan     0.0010    0.0089\n",
      "     3       19.7924             nan     0.0010    0.0069\n",
      "     4       19.7807             nan     0.0010    0.0083\n",
      "     5       19.7732             nan     0.0010    0.0055\n",
      "     6       19.7654             nan     0.0010    0.0052\n",
      "     7       19.7531             nan     0.0010    0.0091\n",
      "     8       19.7443             nan     0.0010    0.0070\n",
      "     9       19.7342             nan     0.0010    0.0068\n",
      "    10       19.7237             nan     0.0010    0.0046\n",
      "    20       19.6255             nan     0.0010    0.0045\n",
      "    40       19.4432             nan     0.0010    0.0053\n",
      "    60       19.2650             nan     0.0010    0.0078\n",
      "    80       19.0840             nan     0.0010    0.0060\n",
      "   100       18.8930             nan     0.0010    0.0057\n",
      "   120       18.7076             nan     0.0010    0.0083\n",
      "   140       18.5297             nan     0.0010    0.0064\n",
      "   160       18.3701             nan     0.0010    0.0063\n",
      "   180       18.1979             nan     0.0010    0.0038\n",
      "   200       18.0325             nan     0.0010    0.0056\n",
      "   220       17.8793             nan     0.0010    0.0016\n",
      "   240       17.7287             nan     0.0010    0.0046\n",
      "   260       17.5745             nan     0.0010    0.0033\n",
      "   280       17.4367             nan     0.0010    0.0030\n",
      "   300       17.2878             nan     0.0010    0.0026\n",
      "   320       17.1434             nan     0.0010    0.0040\n",
      "   340       17.0149             nan     0.0010    0.0030\n",
      "   360       16.8819             nan     0.0010    0.0042\n",
      "   380       16.7501             nan     0.0010    0.0030\n",
      "   400       16.6224             nan     0.0010    0.0040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.7360             nan     0.0100    0.0575\n",
      "     2       19.6798             nan     0.0100    0.0512\n",
      "     3       19.6218             nan     0.0100    0.0508\n",
      "     4       19.5631             nan     0.0100    0.0371\n",
      "     5       19.5474             nan     0.0100    0.0007\n",
      "     6       19.4930             nan     0.0100    0.0525\n",
      "     7       19.4260             nan     0.0100    0.0544\n",
      "     8       19.3805             nan     0.0100    0.0451\n",
      "     9       19.3383             nan     0.0100    0.0448\n",
      "    10       19.2746             nan     0.0100    0.0418\n",
      "    20       18.8887             nan     0.0100    0.0396\n",
      "    40       18.1890             nan     0.0100    0.0325\n",
      "    60       17.6066             nan     0.0100    0.0174\n",
      "    80       17.1656             nan     0.0100    0.0183\n",
      "   100       16.7652             nan     0.0100    0.0042\n",
      "   120       16.4734             nan     0.0100   -0.0121\n",
      "   140       16.1936             nan     0.0100    0.0107\n",
      "   160       15.9342             nan     0.0100    0.0014\n",
      "   180       15.7030             nan     0.0100   -0.0006\n",
      "   200       15.4967             nan     0.0100   -0.0062\n",
      "   220       15.3017             nan     0.0100    0.0001\n",
      "   240       15.1054             nan     0.0100   -0.0027\n",
      "   260       14.9396             nan     0.0100    0.0004\n",
      "   280       14.7673             nan     0.0100    0.0011\n",
      "   300       14.6118             nan     0.0100   -0.0040\n",
      "   320       14.4565             nan     0.0100   -0.0041\n",
      "   340       14.3226             nan     0.0100    0.0002\n",
      "   360       14.1941             nan     0.0100    0.0002\n",
      "   380       14.0755             nan     0.0100   -0.0019\n",
      "   400       13.9470             nan     0.0100    0.0019\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.7453             nan     0.0100    0.0386\n",
      "     2       19.6924             nan     0.0100    0.0402\n",
      "     3       19.6069             nan     0.0100    0.0570\n",
      "     4       19.5111             nan     0.0100    0.0356\n",
      "     5       19.4431             nan     0.0100    0.0478\n",
      "     6       19.3631             nan     0.0100    0.0721\n",
      "     7       19.2868             nan     0.0100    0.0434\n",
      "     8       19.2239             nan     0.0100    0.0467\n",
      "     9       19.1552             nan     0.0100    0.0296\n",
      "    10       19.0778             nan     0.0100    0.0585\n",
      "    20       18.3621             nan     0.0100    0.0556\n",
      "    40       17.2357             nan     0.0100    0.0315\n",
      "    60       16.3030             nan     0.0100    0.0080\n",
      "    80       15.5645             nan     0.0100    0.0211\n",
      "   100       14.8793             nan     0.0100    0.0146\n",
      "   120       14.2731             nan     0.0100    0.0079\n",
      "   140       13.8111             nan     0.0100    0.0059\n",
      "   160       13.3323             nan     0.0100    0.0131\n",
      "   180       12.9247             nan     0.0100    0.0049\n",
      "   200       12.5590             nan     0.0100    0.0053\n",
      "   220       12.2602             nan     0.0100    0.0003\n",
      "   240       11.9302             nan     0.0100    0.0054\n",
      "   260       11.6590             nan     0.0100    0.0051\n",
      "   280       11.3916             nan     0.0100   -0.0102\n",
      "   300       11.1240             nan     0.0100   -0.0090\n",
      "   320       10.9163             nan     0.0100   -0.0139\n",
      "   340       10.7230             nan     0.0100   -0.0007\n",
      "   360       10.5104             nan     0.0100   -0.0113\n",
      "   380       10.3435             nan     0.0100   -0.0087\n",
      "   400       10.1773             nan     0.0100   -0.0032\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.7283             nan     0.0100    0.0671\n",
      "     2       19.6415             nan     0.0100    0.0392\n",
      "     3       19.5316             nan     0.0100    0.0855\n",
      "     4       19.4189             nan     0.0100    0.0700\n",
      "     5       19.3337             nan     0.0100    0.0696\n",
      "     6       19.2460             nan     0.0100    0.0503\n",
      "     7       19.1542             nan     0.0100    0.0641\n",
      "     8       19.0429             nan     0.0100    0.0848\n",
      "     9       18.9665             nan     0.0100    0.0693\n",
      "    10       18.8766             nan     0.0100    0.0409\n",
      "    20       18.1093             nan     0.0100    0.0439\n",
      "    40       16.7102             nan     0.0100    0.0117\n",
      "    60       15.5959             nan     0.0100   -0.0029\n",
      "    80       14.6350             nan     0.0100    0.0080\n",
      "   100       13.7687             nan     0.0100    0.0264\n",
      "   120       13.0399             nan     0.0100   -0.0145\n",
      "   140       12.3522             nan     0.0100   -0.0185\n",
      "   160       11.8286             nan     0.0100   -0.0019\n",
      "   180       11.3673             nan     0.0100    0.0074\n",
      "   200       10.9282             nan     0.0100    0.0017\n",
      "   220       10.5359             nan     0.0100   -0.0186\n",
      "   240       10.1581             nan     0.0100   -0.0052\n",
      "   260        9.8412             nan     0.0100   -0.0101\n",
      "   280        9.5016             nan     0.0100   -0.0148\n",
      "   300        9.2351             nan     0.0100   -0.0109\n",
      "   320        8.9613             nan     0.0100   -0.0078\n",
      "   340        8.7535             nan     0.0100   -0.0131\n",
      "   360        8.5486             nan     0.0100   -0.0156\n",
      "   380        8.3178             nan     0.0100   -0.0081\n",
      "   400        8.1248             nan     0.0100   -0.0023\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.2466             nan     0.1000    0.5113\n",
      "     2       18.7958             nan     0.1000    0.4121\n",
      "     3       18.5518             nan     0.1000    0.1997\n",
      "     4       18.1580             nan     0.1000    0.2949\n",
      "     5       17.9124             nan     0.1000    0.1142\n",
      "     6       17.6041             nan     0.1000    0.3011\n",
      "     7       17.3043             nan     0.1000    0.1826\n",
      "     8       17.0810             nan     0.1000    0.0294\n",
      "     9       16.8982             nan     0.1000   -0.0192\n",
      "    10       16.6667             nan     0.1000    0.1153\n",
      "    20       15.3527             nan     0.1000    0.0099\n",
      "    40       13.9355             nan     0.1000    0.0353\n",
      "    60       13.0201             nan     0.1000    0.0102\n",
      "    80       12.5359             nan     0.1000   -0.0834\n",
      "   100       12.2139             nan     0.1000   -0.0201\n",
      "   120       11.9067             nan     0.1000   -0.0548\n",
      "   140       11.5914             nan     0.1000   -0.0450\n",
      "   160       11.4714             nan     0.1000   -0.1206\n",
      "   180       11.2900             nan     0.1000   -0.0475\n",
      "   200       11.1992             nan     0.1000   -0.0593\n",
      "   220       11.1009             nan     0.1000   -0.0669\n",
      "   240       10.9433             nan     0.1000   -0.0524\n",
      "   260       10.8240             nan     0.1000   -0.0621\n",
      "   280       10.7581             nan     0.1000   -0.0276\n",
      "   300       10.7061             nan     0.1000   -0.0642\n",
      "   320       10.7413             nan     0.1000   -0.0476\n",
      "   340       10.6537             nan     0.1000   -0.0626\n",
      "   360       10.6228             nan     0.1000   -0.0942\n",
      "   380       10.5721             nan     0.1000   -0.0534\n",
      "   400       10.5225             nan     0.1000   -0.0742\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.2133             nan     0.1000    0.6051\n",
      "     2       18.4907             nan     0.1000    0.2007\n",
      "     3       17.7887             nan     0.1000    0.4520\n",
      "     4       17.1597             nan     0.1000    0.5376\n",
      "     5       16.5275             nan     0.1000    0.4692\n",
      "     6       16.2303             nan     0.1000    0.0770\n",
      "     7       15.9080             nan     0.1000    0.2092\n",
      "     8       15.4330             nan     0.1000    0.1900\n",
      "     9       15.2244             nan     0.1000    0.0073\n",
      "    10       14.8263             nan     0.1000    0.1063\n",
      "    20       12.5892             nan     0.1000   -0.0626\n",
      "    40       10.2817             nan     0.1000   -0.0986\n",
      "    60        9.0152             nan     0.1000   -0.0818\n",
      "    80        8.0730             nan     0.1000   -0.0259\n",
      "   100        7.3485             nan     0.1000   -0.0738\n",
      "   120        6.8428             nan     0.1000   -0.0502\n",
      "   140        6.2973             nan     0.1000   -0.0475\n",
      "   160        5.8065             nan     0.1000   -0.0657\n",
      "   180        5.4351             nan     0.1000   -0.0580\n",
      "   200        5.0333             nan     0.1000   -0.1063\n",
      "   220        4.7794             nan     0.1000   -0.0732\n",
      "   240        4.5341             nan     0.1000   -0.0535\n",
      "   260        4.2931             nan     0.1000   -0.0320\n",
      "   280        3.9827             nan     0.1000   -0.0170\n",
      "   300        3.7202             nan     0.1000   -0.0541\n",
      "   320        3.5988             nan     0.1000   -0.0623\n",
      "   340        3.4450             nan     0.1000   -0.0528\n",
      "   360        3.2398             nan     0.1000   -0.0600\n",
      "   380        3.0556             nan     0.1000   -0.0323\n",
      "   400        2.8988             nan     0.1000   -0.0293\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       18.8892             nan     0.1000    0.5199\n",
      "     2       18.0534             nan     0.1000    0.3666\n",
      "     3       17.4974             nan     0.1000    0.1792\n",
      "     4       16.8267             nan     0.1000    0.4424\n",
      "     5       16.2984             nan     0.1000    0.0355\n",
      "     6       15.7907             nan     0.1000    0.2425\n",
      "     7       15.3324             nan     0.1000    0.1815\n",
      "     8       15.0145             nan     0.1000    0.0198\n",
      "     9       14.4004             nan     0.1000    0.2332\n",
      "    10       13.9567             nan     0.1000    0.1052\n",
      "    20       11.1707             nan     0.1000   -0.0302\n",
      "    40        8.2352             nan     0.1000   -0.1302\n",
      "    60        6.6953             nan     0.1000   -0.0411\n",
      "    80        5.5654             nan     0.1000   -0.0600\n",
      "   100        4.8248             nan     0.1000   -0.0465\n",
      "   120        4.2148             nan     0.1000   -0.0698\n",
      "   140        3.6789             nan     0.1000   -0.0217\n",
      "   160        3.2822             nan     0.1000   -0.0741\n",
      "   180        2.8950             nan     0.1000   -0.0273\n",
      "   200        2.5790             nan     0.1000   -0.0194\n",
      "   220        2.3110             nan     0.1000   -0.0215\n",
      "   240        2.0569             nan     0.1000   -0.0422\n",
      "   260        1.8625             nan     0.1000   -0.0481\n",
      "   280        1.6621             nan     0.1000   -0.0165\n",
      "   300        1.4756             nan     0.1000   -0.0447\n",
      "   320        1.3504             nan     0.1000   -0.0212\n",
      "   340        1.2305             nan     0.1000   -0.0181\n",
      "   360        1.1199             nan     0.1000   -0.0283\n",
      "   380        1.0218             nan     0.1000   -0.0132\n",
      "   400        0.9429             nan     0.1000   -0.0232\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.5154             nan     0.0010    0.0055\n",
      "     2       20.5117             nan     0.0010    0.0023\n",
      "     3       20.5044             nan     0.0010    0.0038\n",
      "     4       20.4986             nan     0.0010    0.0044\n",
      "     5       20.4959             nan     0.0010    0.0008\n",
      "     6       20.4928             nan     0.0010    0.0017\n",
      "     7       20.4866             nan     0.0010    0.0046\n",
      "     8       20.4814             nan     0.0010    0.0053\n",
      "     9       20.4758             nan     0.0010    0.0056\n",
      "    10       20.4710             nan     0.0010    0.0046\n",
      "    20       20.4083             nan     0.0010    0.0047\n",
      "    40       20.3078             nan     0.0010    0.0053\n",
      "    60       20.2000             nan     0.0010    0.0041\n",
      "    80       20.0896             nan     0.0010    0.0046\n",
      "   100       19.9935             nan     0.0010    0.0051\n",
      "   120       19.8965             nan     0.0010    0.0032\n",
      "   140       19.8041             nan     0.0010    0.0053\n",
      "   160       19.7115             nan     0.0010    0.0040\n",
      "   180       19.6228             nan     0.0010    0.0022\n",
      "   200       19.5462             nan     0.0010    0.0039\n",
      "   220       19.4635             nan     0.0010    0.0034\n",
      "   240       19.3751             nan     0.0010    0.0017\n",
      "   260       19.2986             nan     0.0010    0.0020\n",
      "   280       19.2177             nan     0.0010    0.0028\n",
      "   300       19.1454             nan     0.0010    0.0027\n",
      "   320       19.0738             nan     0.0010    0.0036\n",
      "   340       18.9947             nan     0.0010    0.0030\n",
      "   360       18.9234             nan     0.0010   -0.0007\n",
      "   380       18.8569             nan     0.0010    0.0012\n",
      "   400       18.7819             nan     0.0010    0.0037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.5145             nan     0.0010    0.0053\n",
      "     2       20.5041             nan     0.0010    0.0074\n",
      "     3       20.4943             nan     0.0010    0.0083\n",
      "     4       20.4833             nan     0.0010    0.0061\n",
      "     5       20.4769             nan     0.0010    0.0008\n",
      "     6       20.4688             nan     0.0010    0.0069\n",
      "     7       20.4613             nan     0.0010    0.0063\n",
      "     8       20.4542             nan     0.0010    0.0047\n",
      "     9       20.4469             nan     0.0010    0.0055\n",
      "    10       20.4381             nan     0.0010    0.0059\n",
      "    20       20.3481             nan     0.0010    0.0069\n",
      "    40       20.1891             nan     0.0010    0.0082\n",
      "    60       20.0296             nan     0.0010    0.0064\n",
      "    80       19.8721             nan     0.0010    0.0040\n",
      "   100       19.7160             nan     0.0010    0.0038\n",
      "   120       19.5646             nan     0.0010    0.0027\n",
      "   140       19.4078             nan     0.0010    0.0043\n",
      "   160       19.2629             nan     0.0010    0.0047\n",
      "   180       19.1165             nan     0.0010    0.0039\n",
      "   200       18.9857             nan     0.0010    0.0058\n",
      "   220       18.8471             nan     0.0010    0.0032\n",
      "   240       18.7088             nan     0.0010    0.0037\n",
      "   260       18.5721             nan     0.0010    0.0034\n",
      "   280       18.4467             nan     0.0010    0.0040\n",
      "   300       18.3218             nan     0.0010    0.0050\n",
      "   320       18.1971             nan     0.0010    0.0038\n",
      "   340       18.0820             nan     0.0010    0.0019\n",
      "   360       17.9642             nan     0.0010    0.0048\n",
      "   380       17.8430             nan     0.0010    0.0033\n",
      "   400       17.7340             nan     0.0010    0.0026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.5108             nan     0.0010    0.0074\n",
      "     2       20.5014             nan     0.0010    0.0074\n",
      "     3       20.4912             nan     0.0010    0.0084\n",
      "     4       20.4807             nan     0.0010    0.0083\n",
      "     5       20.4681             nan     0.0010    0.0073\n",
      "     6       20.4584             nan     0.0010    0.0056\n",
      "     7       20.4460             nan     0.0010    0.0086\n",
      "     8       20.4355             nan     0.0010    0.0080\n",
      "     9       20.4264             nan     0.0010    0.0051\n",
      "    10       20.4158             nan     0.0010    0.0080\n",
      "    20       20.3066             nan     0.0010    0.0085\n",
      "    40       20.0977             nan     0.0010    0.0072\n",
      "    60       19.8929             nan     0.0010    0.0069\n",
      "    80       19.7009             nan     0.0010    0.0061\n",
      "   100       19.5121             nan     0.0010    0.0070\n",
      "   120       19.3255             nan     0.0010    0.0066\n",
      "   140       19.1569             nan     0.0010    0.0036\n",
      "   160       18.9753             nan     0.0010    0.0060\n",
      "   180       18.7936             nan     0.0010    0.0066\n",
      "   200       18.6292             nan     0.0010    0.0085\n",
      "   220       18.4668             nan     0.0010    0.0050\n",
      "   240       18.3195             nan     0.0010    0.0063\n",
      "   260       18.1561             nan     0.0010    0.0019\n",
      "   280       18.0077             nan     0.0010    0.0075\n",
      "   300       17.8540             nan     0.0010    0.0045\n",
      "   320       17.7137             nan     0.0010    0.0030\n",
      "   340       17.5693             nan     0.0010    0.0016\n",
      "   360       17.4265             nan     0.0010    0.0027\n",
      "   380       17.2851             nan     0.0010    0.0055\n",
      "   400       17.1527             nan     0.0010   -0.0036\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.4664             nan     0.0100    0.0567\n",
      "     2       20.4135             nan     0.0100    0.0482\n",
      "     3       20.3544             nan     0.0100    0.0591\n",
      "     4       20.3043             nan     0.0100    0.0400\n",
      "     5       20.2579             nan     0.0100    0.0473\n",
      "     6       20.2040             nan     0.0100    0.0516\n",
      "     7       20.1498             nan     0.0100    0.0419\n",
      "     8       20.1046             nan     0.0100    0.0505\n",
      "     9       20.0547             nan     0.0100    0.0529\n",
      "    10       20.0020             nan     0.0100    0.0274\n",
      "    20       19.5703             nan     0.0100    0.0504\n",
      "    40       18.8667             nan     0.0100   -0.0010\n",
      "    60       18.2717             nan     0.0100    0.0213\n",
      "    80       17.7655             nan     0.0100   -0.0019\n",
      "   100       17.2967             nan     0.0100    0.0144\n",
      "   120       16.9364             nan     0.0100    0.0055\n",
      "   140       16.5664             nan     0.0100    0.0066\n",
      "   160       16.2574             nan     0.0100   -0.0010\n",
      "   180       16.0116             nan     0.0100    0.0011\n",
      "   200       15.7767             nan     0.0100   -0.0247\n",
      "   220       15.5706             nan     0.0100    0.0030\n",
      "   240       15.4005             nan     0.0100   -0.0108\n",
      "   260       15.2365             nan     0.0100   -0.0018\n",
      "   280       15.0820             nan     0.0100    0.0024\n",
      "   300       14.9380             nan     0.0100   -0.0042\n",
      "   320       14.7850             nan     0.0100    0.0020\n",
      "   340       14.6444             nan     0.0100   -0.0018\n",
      "   360       14.5149             nan     0.0100    0.0030\n",
      "   380       14.3891             nan     0.0100   -0.0015\n",
      "   400       14.2661             nan     0.0100    0.0006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.4496             nan     0.0100    0.0477\n",
      "     2       20.3601             nan     0.0100    0.0737\n",
      "     3       20.2816             nan     0.0100    0.0602\n",
      "     4       20.1852             nan     0.0100    0.0880\n",
      "     5       20.1267             nan     0.0100    0.0530\n",
      "     6       20.0538             nan     0.0100    0.0703\n",
      "     7       19.9670             nan     0.0100    0.0363\n",
      "     8       19.8756             nan     0.0100    0.0829\n",
      "     9       19.8170             nan     0.0100    0.0281\n",
      "    10       19.7107             nan     0.0100    0.0403\n",
      "    20       18.9224             nan     0.0100    0.0550\n",
      "    40       17.7490             nan     0.0100    0.0395\n",
      "    60       16.7442             nan     0.0100    0.0153\n",
      "    80       15.9297             nan     0.0100    0.0164\n",
      "   100       15.2257             nan     0.0100   -0.0053\n",
      "   120       14.6512             nan     0.0100   -0.0015\n",
      "   140       14.1619             nan     0.0100    0.0089\n",
      "   160       13.6387             nan     0.0100   -0.0085\n",
      "   180       13.2248             nan     0.0100   -0.0077\n",
      "   200       12.8766             nan     0.0100    0.0056\n",
      "   220       12.5537             nan     0.0100   -0.0153\n",
      "   240       12.2308             nan     0.0100   -0.0037\n",
      "   260       11.9645             nan     0.0100   -0.0165\n",
      "   280       11.7070             nan     0.0100   -0.0063\n",
      "   300       11.4685             nan     0.0100   -0.0176\n",
      "   320       11.2675             nan     0.0100   -0.0041\n",
      "   340       11.0504             nan     0.0100   -0.0019\n",
      "   360       10.8457             nan     0.0100   -0.0075\n",
      "   380       10.6397             nan     0.0100   -0.0057\n",
      "   400       10.4536             nan     0.0100   -0.0089\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.4167             nan     0.0100    0.0601\n",
      "     2       20.3278             nan     0.0100    0.0689\n",
      "     3       20.2489             nan     0.0100    0.0558\n",
      "     4       20.1668             nan     0.0100    0.0567\n",
      "     5       20.0693             nan     0.0100    0.0526\n",
      "     6       19.9646             nan     0.0100    0.0624\n",
      "     7       19.8674             nan     0.0100    0.0843\n",
      "     8       19.7714             nan     0.0100    0.0577\n",
      "     9       19.6733             nan     0.0100    0.0729\n",
      "    10       19.5631             nan     0.0100    0.0591\n",
      "    20       18.7440             nan     0.0100    0.0317\n",
      "    40       17.2120             nan     0.0100    0.0403\n",
      "    60       16.0467             nan     0.0100    0.0444\n",
      "    80       15.0021             nan     0.0100    0.0210\n",
      "   100       14.1419             nan     0.0100    0.0015\n",
      "   120       13.3901             nan     0.0100   -0.0003\n",
      "   140       12.7738             nan     0.0100    0.0057\n",
      "   160       12.2279             nan     0.0100    0.0056\n",
      "   180       11.7245             nan     0.0100   -0.0195\n",
      "   200       11.2737             nan     0.0100    0.0171\n",
      "   220       10.8402             nan     0.0100   -0.0020\n",
      "   240       10.4999             nan     0.0100   -0.0197\n",
      "   260       10.1733             nan     0.0100   -0.0030\n",
      "   280        9.8576             nan     0.0100   -0.0151\n",
      "   300        9.5981             nan     0.0100   -0.0047\n",
      "   320        9.3130             nan     0.0100   -0.0209\n",
      "   340        9.0523             nan     0.0100    0.0011\n",
      "   360        8.8385             nan     0.0100   -0.0096\n",
      "   380        8.6167             nan     0.0100   -0.0051\n",
      "   400        8.4283             nan     0.0100   -0.0072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.9582             nan     0.1000    0.5136\n",
      "     2       19.3661             nan     0.1000    0.3128\n",
      "     3       18.8451             nan     0.1000    0.3171\n",
      "     4       18.5070             nan     0.1000    0.2511\n",
      "     5       18.2262             nan     0.1000    0.1921\n",
      "     6       17.8961             nan     0.1000    0.3374\n",
      "     7       17.7240             nan     0.1000    0.1367\n",
      "     8       17.5442             nan     0.1000    0.0888\n",
      "     9       17.3209             nan     0.1000    0.1120\n",
      "    10       17.1434             nan     0.1000   -0.0453\n",
      "    20       15.8579             nan     0.1000   -0.1407\n",
      "    40       14.2926             nan     0.1000   -0.0131\n",
      "    60       13.4119             nan     0.1000   -0.0175\n",
      "    80       12.7320             nan     0.1000   -0.0509\n",
      "   100       12.2757             nan     0.1000   -0.0845\n",
      "   120       12.0001             nan     0.1000   -0.0524\n",
      "   140       11.7656             nan     0.1000   -0.0239\n",
      "   160       11.5988             nan     0.1000   -0.0592\n",
      "   180       11.4322             nan     0.1000   -0.0909\n",
      "   200       11.4032             nan     0.1000   -0.0647\n",
      "   220       11.3025             nan     0.1000   -0.1477\n",
      "   240       11.2351             nan     0.1000   -0.0926\n",
      "   260       11.0879             nan     0.1000   -0.1440\n",
      "   280       10.9489             nan     0.1000   -0.0484\n",
      "   300       10.9061             nan     0.1000   -0.1080\n",
      "   320       10.8665             nan     0.1000   -0.0424\n",
      "   340       10.7941             nan     0.1000   -0.0746\n",
      "   360       10.7357             nan     0.1000   -0.0351\n",
      "   380       10.7144             nan     0.1000   -0.0837\n",
      "   400       10.7253             nan     0.1000   -0.0842\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.6053             nan     0.1000    0.8356\n",
      "     2       18.6774             nan     0.1000    0.2097\n",
      "     3       18.1959             nan     0.1000    0.3339\n",
      "     4       17.6007             nan     0.1000    0.3334\n",
      "     5       17.0716             nan     0.1000    0.4516\n",
      "     6       16.5058             nan     0.1000    0.3512\n",
      "     7       15.8800             nan     0.1000   -0.0197\n",
      "     8       15.5670             nan     0.1000    0.1529\n",
      "     9       15.1825             nan     0.1000    0.0684\n",
      "    10       14.8910             nan     0.1000    0.0500\n",
      "    20       12.8582             nan     0.1000   -0.0392\n",
      "    40       10.8308             nan     0.1000   -0.0637\n",
      "    60        9.6007             nan     0.1000   -0.0259\n",
      "    80        8.5557             nan     0.1000   -0.1555\n",
      "   100        7.8924             nan     0.1000   -0.1072\n",
      "   120        7.4217             nan     0.1000   -0.1211\n",
      "   140        6.8938             nan     0.1000   -0.0719\n",
      "   160        6.4010             nan     0.1000   -0.0692\n",
      "   180        5.9357             nan     0.1000   -0.0557\n",
      "   200        5.5923             nan     0.1000   -0.0885\n",
      "   220        5.2368             nan     0.1000   -0.0225\n",
      "   240        4.8942             nan     0.1000   -0.0585\n",
      "   260        4.5494             nan     0.1000   -0.0356\n",
      "   280        4.3254             nan     0.1000   -0.0485\n",
      "   300        4.0020             nan     0.1000   -0.0380\n",
      "   320        3.7445             nan     0.1000   -0.0393\n",
      "   340        3.5577             nan     0.1000   -0.0806\n",
      "   360        3.3688             nan     0.1000   -0.0398\n",
      "   380        3.2118             nan     0.1000   -0.0386\n",
      "   400        3.0705             nan     0.1000   -0.0506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       19.3365             nan     0.1000    0.6602\n",
      "     2       18.4274             nan     0.1000    0.3428\n",
      "     3       17.6047             nan     0.1000    0.3948\n",
      "     4       16.9766             nan     0.1000    0.0443\n",
      "     5       16.3407             nan     0.1000    0.0986\n",
      "     6       15.7572             nan     0.1000    0.2591\n",
      "     7       15.3404             nan     0.1000    0.1460\n",
      "     8       14.8946             nan     0.1000    0.1264\n",
      "     9       14.5026             nan     0.1000    0.1270\n",
      "    10       14.0342             nan     0.1000    0.0914\n",
      "    20       11.4320             nan     0.1000   -0.0869\n",
      "    40        8.6602             nan     0.1000   -0.1500\n",
      "    60        7.0241             nan     0.1000   -0.1433\n",
      "    80        5.7989             nan     0.1000   -0.0961\n",
      "   100        5.0773             nan     0.1000   -0.1008\n",
      "   120        4.3587             nan     0.1000   -0.0988\n",
      "   140        3.7575             nan     0.1000    0.0009\n",
      "   160        3.2964             nan     0.1000   -0.0373\n",
      "   180        2.8480             nan     0.1000   -0.0574\n",
      "   200        2.4713             nan     0.1000   -0.0404\n",
      "   220        2.1683             nan     0.1000   -0.0353\n",
      "   240        1.9412             nan     0.1000   -0.0122\n",
      "   260        1.7608             nan     0.1000   -0.0389\n",
      "   280        1.5697             nan     0.1000   -0.0313\n",
      "   300        1.4165             nan     0.1000   -0.0202\n",
      "   320        1.2789             nan     0.1000   -0.0123\n",
      "   340        1.1409             nan     0.1000   -0.0126\n",
      "   360        1.0337             nan     0.1000   -0.0164\n",
      "   380        0.9268             nan     0.1000   -0.0181\n",
      "   400        0.8613             nan     0.1000   -0.0122\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 1: schoolMS has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1       20.7520             nan     0.0100    0.0822\n",
      "     2       20.6472             nan     0.0100    0.0827\n",
      "     3       20.5068             nan     0.0100    0.0866\n",
      "     4       20.3709             nan     0.0100    0.0854\n",
      "     5       20.2573             nan     0.0100    0.0957\n",
      "     6       20.1561             nan     0.0100    0.0799\n",
      "     7       20.0581             nan     0.0100    0.0836\n",
      "     8       19.9209             nan     0.0100    0.0602\n",
      "     9       19.8154             nan     0.0100    0.0690\n",
      "    10       19.7472             nan     0.0100    0.0127\n",
      "    20       18.7836             nan     0.0100    0.0411\n",
      "    40       17.1382             nan     0.0100    0.0347\n",
      "    60       15.8978             nan     0.0100    0.0101\n",
      "    80       14.8649             nan     0.0100    0.0288\n",
      "   100       13.9884             nan     0.0100    0.0029\n",
      "   120       13.2246             nan     0.0100    0.0115\n",
      "   140       12.5599             nan     0.0100    0.0078\n",
      "   160       12.0125             nan     0.0100   -0.0012\n",
      "   180       11.5481             nan     0.0100   -0.0074\n",
      "   200       11.0762             nan     0.0100   -0.0126\n",
      "   220       10.6649             nan     0.0100   -0.0165\n",
      "   240       10.3150             nan     0.0100   -0.0101\n",
      "   260        9.9799             nan     0.0100   -0.0047\n",
      "   280        9.7065             nan     0.0100   -0.0150\n",
      "   300        9.4303             nan     0.0100    0.0006\n",
      "   320        9.1855             nan     0.0100    0.0001\n",
      "   340        8.9624             nan     0.0100   -0.0147\n",
      "   360        8.7748             nan     0.0100   -0.0051\n",
      "   380        8.5756             nan     0.0100   -0.0111\n",
      "   400        8.3566             nan     0.0100   -0.0102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 4: Stochastic Gradient Boosting\n",
    "set.seed(1)\n",
    "n_folds=10\n",
    "Control=trainControl(method = \"cv\",\n",
    "                           number = n_folds)  \n",
    "#Number of trees are set to 200, 300 and 400\n",
    "#Interaction depth is set to 1, 3, and 5\n",
    "#Learning rate is et to 0.001,0.01,0.1\n",
    "#minobsinnode is set to 10 to avoid underfitting\n",
    "grid_sgb <- expand.grid(n.trees = c(200,300,400), interaction.depth =c(1,3,5),shrinkage = c(0.001,0.01,0.1),n.minobsinnode = 10) \n",
    "\n",
    "sgb_fit = train(Final_note~ .,data=train_set1,\n",
    "                method = 'gbm',\n",
    "                 trControl = Control,\n",
    "                 tuneGrid = grid_sgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stochastic Gradient Boosting \n",
       "\n",
       "276 samples\n",
       " 30 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 249, 250, 248, 248, 248, 248, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  shrinkage  interaction.depth  n.trees  RMSE      Rsquared   MAE     \n",
       "  0.001      1                  200      4.427702  0.1999377  3.380071\n",
       "  0.001      1                  300      4.386423  0.2001891  3.350723\n",
       "  0.001      1                  400      4.352236  0.1997708  3.327404\n",
       "  0.001      3                  200      4.395095  0.2434503  3.362036\n",
       "  0.001      3                  300      4.337157  0.2467734  3.321781\n",
       "  0.001      3                  400      4.287979  0.2487856  3.285194\n",
       "  0.001      5                  200      4.375988  0.2647243  3.345178\n",
       "  0.001      5                  300      4.311328  0.2690959  3.298528\n",
       "  0.001      5                  400      4.256154  0.2699916  3.256939\n",
       "  0.010      1                  200      4.094134  0.2302880  3.187696\n",
       "  0.010      1                  300      4.021787  0.2448797  3.143433\n",
       "  0.010      1                  400      3.987522  0.2471085  3.122802\n",
       "  0.010      3                  200      3.940533  0.2768288  3.074106\n",
       "  0.010      3                  300      3.893049  0.2785283  3.041801\n",
       "  0.010      3                  400      3.874790  0.2790758  3.017470\n",
       "  0.010      5                  200      3.906457  0.2783872  3.043272\n",
       "  0.010      5                  300      3.861412  0.2801599  3.005386\n",
       "  0.010      5                  400      3.858461  0.2781978  3.000099\n",
       "  0.100      1                  200      4.030419  0.2478609  3.169597\n",
       "  0.100      1                  300      4.065468  0.2433943  3.205610\n",
       "  0.100      1                  400      4.129957  0.2307107  3.283241\n",
       "  0.100      3                  200      4.107990  0.2374451  3.190579\n",
       "  0.100      3                  300      4.205576  0.2169400  3.268174\n",
       "  0.100      3                  400      4.256965  0.2092691  3.286625\n",
       "  0.100      5                  200      4.257210  0.2041340  3.318735\n",
       "  0.100      5                  300      4.340624  0.1970572  3.373476\n",
       "  0.100      5                  400      4.390540  0.1935920  3.370895\n",
       "\n",
       "Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were n.trees = 400, interaction.depth =\n",
       " 5, shrinkage = 0.01 and n.minobsinnode = 10."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgb_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE of sgb at n.trees = 400, interaction.depth =5, shrinkage = 0.01 and n.minobsinnode = 10\n",
    "model_sgb_rmse = 3.858461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAaVBMVEUAAAAAZAAAgP9NRT5N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\nYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(sgb_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction by using Stochastic Gradient Boosting\n",
    "predict_sgb = predict(sgb_fit, test_set1 )\n",
    "#RMSE calculation between prediction and test data\n",
    "model_predict_comp_sgb=sqrt(mean((test_set1$Final_note - predict_sgb)^2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_sgb = c()\n",
    "comp_sgb[1] = as.numeric(model_sgb_rmse)\n",
    "comp_sgb[2]= as.numeric(model_predict_comp_sgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Comparison\n",
    "model = c()\n",
    "model[1] = \"Penalized Regression Approaches (PRA)\"\n",
    "model[2] = \"Decision Trees (DT)\"\n",
    "model[3] = \"Random Forests (RF)\"\n",
    "model[4] = \"Stochastic Gradient Boosting (SGB)\"\n",
    "data=matrix(0,4,3)\n",
    "data[,1] = t(model)\n",
    "data[1,2:3] = signif(comp_lasso,digits = 4)\n",
    "data[2,2:3] = signif(comp_tree, digits =4)\n",
    "data[3,2:3] = signif(comp_forest, digits =4)\n",
    "data[4,2:3] = signif(comp_sgb, digits=4)\n",
    "colnames(data) = c('Model','RMSE of Model', 'RMSE of Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Model</th><th scope=col>RMSE of Model</th><th scope=col>RMSE of Prediction</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Penalized Regression Approaches (PRA)</td><td>4.322                                </td><td>4.939                                </td></tr>\n",
       "\t<tr><td>Decision Trees (DT)                  </td><td>4.234                                </td><td>4.554                                </td></tr>\n",
       "\t<tr><td>Random Forests (RF)                  </td><td>3.844                                </td><td>4.288                                </td></tr>\n",
       "\t<tr><td>Stochastic Gradient Boosting (SGB)   </td><td>3.858                                </td><td>4.286                                </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lll}\n",
       " Model & RMSE of Model & RMSE of Prediction\\\\\n",
       "\\hline\n",
       "\t Penalized Regression Approaches (PRA) & 4.322                                 & 4.939                                \\\\\n",
       "\t Decision Trees (DT)                   & 4.234                                 & 4.554                                \\\\\n",
       "\t Random Forests (RF)                   & 3.844                                 & 4.288                                \\\\\n",
       "\t Stochastic Gradient Boosting (SGB)    & 3.858                                 & 4.286                                \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Model | RMSE of Model | RMSE of Prediction |\n",
       "|---|---|---|\n",
       "| Penalized Regression Approaches (PRA) | 4.322                                 | 4.939                                 |\n",
       "| Decision Trees (DT)                   | 4.234                                 | 4.554                                 |\n",
       "| Random Forests (RF)                   | 3.844                                 | 4.288                                 |\n",
       "| Stochastic Gradient Boosting (SGB)    | 3.858                                 | 4.286                                 |\n",
       "\n"
      ],
      "text/plain": [
       "     Model                                 RMSE of Model RMSE of Prediction\n",
       "[1,] Penalized Regression Approaches (PRA) 4.322         4.939             \n",
       "[2,] Decision Trees (DT)                   4.234         4.554             \n",
       "[3,] Random Forests (RF)                   3.844         4.288             \n",
       "[4,] Stochastic Gradient Boosting (SGB)    3.858         4.286             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### According to RMSE values random forest approach is the best approach to model the training data of student performance dataset. In the random forest approach the model minimum number of observations per tree leaf has lowest RMSE value. When we investigate the RMSE values calculated between test data and predicted data, the best model is Stochastic Gradient Boosting (SGB). However, the RMSE value of random forest also very similar to this model. SGB method is better than other methods in training weak models, since boosted trees are grown sequentially. In the model generation, learning rate with 0.01 value has the smallest RMSE value. Normally, learning rate is in between 0.001 and 0.3. Small values of of learning rate make model rebust, however in this model learnin rate is avarage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
