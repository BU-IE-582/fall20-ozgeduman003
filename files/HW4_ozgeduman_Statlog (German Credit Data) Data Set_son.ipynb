{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset-1 Statlog (German Credit Data) Data Set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This dataset classifies people described by a set of attributes as good or bad credit risks. Two datasets are provided. The original dataset is used in this homework in the form provided by Prof. Hofmann, contains categorical/symbolic attributes and is in the file \"german.data\". In this part of homework, it is aimed to predict the status of existing checking account, which is a multi-class classification problem. Additionally, this has a class imbalance problem.\n",
    "\n",
    "### Features of Dataset \n",
    "Data Set Characteristics:Multivariate\n",
    "Number of Instances:1000\n",
    "Area:Financial\n",
    "Attribute Characteristics:Categorical, Integer\n",
    "Number of Attributes:20\n",
    "Associated Tasks:Classification\n",
    "Missing Values:N/A\n",
    "\n",
    "### Attributes of Dataset\n",
    "Attribute 1: (qualitative)\n",
    "Status of existing checking account\n",
    "A11 : ... < 0 DM\n",
    "A12 : 0 <= ... < 200 DM\n",
    "A13 : ... >= 200 DM / salary assignments for at least 1 year\n",
    "A14 : no checking account\n",
    "\n",
    "Attribute 2: (numerical)\n",
    "Duration in month\n",
    "\n",
    "Attribute 3: (qualitative)\n",
    "Credit history\n",
    "A30 : no credits taken/ all credits paid back duly\n",
    "A31 : all credits at this bank paid back duly\n",
    "A32 : existing credits paid back duly till now\n",
    "A33 : delay in paying off in the past\n",
    "A34 : critical account/ other credits existing (not at this bank)\n",
    "\n",
    "Attribute 4: (qualitative)\n",
    "Purpose\n",
    "A40 : car (new)\n",
    "A41 : car (used)\n",
    "A42 : furniture/equipment\n",
    "A43 : radio/television\n",
    "A44 : domestic appliances\n",
    "A45 : repairs\n",
    "A46 : education\n",
    "A47 : (vacation - does not exist?)\n",
    "A48 : retraining\n",
    "A49 : business\n",
    "A410 : others\n",
    "\n",
    "Attribute 5: (numerical)\n",
    "Credit amount\n",
    "\n",
    "Attibute 6: (qualitative)\n",
    "Savings account/bonds\n",
    "A61 : ... < 100 DM\n",
    "A62 : 100 <= ... < 500 DM\n",
    "A63 : 500 <= ... < 1000 DM\n",
    "A64 : .. >= 1000 DM\n",
    "A65 : unknown/ no savings account\n",
    "\n",
    "Attribute 7: (qualitative)\n",
    "Present employment since\n",
    "A71 : unemployed\n",
    "A72 : ... < 1 year\n",
    "A73 : 1 <= ... < 4 years\n",
    "A74 : 4 <= ... < 7 years\n",
    "A75 : .. >= 7 years\n",
    "\n",
    "Attribute 8: (numerical)\n",
    "Installment rate in percentage of disposable income\n",
    "\n",
    "Attribute 9: (qualitative)\n",
    "Personal status and sex\n",
    "A91 : male : divorced/separated\n",
    "A92 : female : divorced/separated/married\n",
    "A93 : male : single\n",
    "A94 : male : married/widowed\n",
    "A95 : female : single\n",
    "\n",
    "Attribute 10: (qualitative)\n",
    "Other debtors / guarantors\n",
    "A101 : none\n",
    "A102 : co-applicant\n",
    "A103 : guarantor\n",
    "\n",
    "Attribute 11: (numerical)\n",
    "Present residence since\n",
    "\n",
    "Attribute 12: (qualitative)\n",
    "Property\n",
    "A121 : real estate\n",
    "A122 : if not A121 : building society savings agreement/ life insurance\n",
    "A123 : if not A121/A122 : car or other, not in attribute 6\n",
    "A124 : unknown / no property\n",
    "\n",
    "Attribute 13: (numerical)\n",
    "Age in years\n",
    "\n",
    "Attribute 14: (qualitative)\n",
    "Other installment plans\n",
    "A141 : bank\n",
    "A142 : stores\n",
    "A143 : none\n",
    "\n",
    "Attribute 15: (qualitative)\n",
    "Housing\n",
    "A151 : rent\n",
    "A152 : own\n",
    "A153 : for free\n",
    "\n",
    "Attribute 16: (numerical)\n",
    "Number of existing credits at this bank\n",
    "\n",
    "Attribute 17: (qualitative)\n",
    "Job\n",
    "A171 : unemployed/ unskilled - non-resident\n",
    "A172 : unskilled - resident\n",
    "A173 : skilled employee / official\n",
    "A174 : management/ self-employed/\n",
    "highly qualified employee/ officer\n",
    "\n",
    "Attribute 18: (numerical)\n",
    "Number of people being liable to provide maintenance for\n",
    "\n",
    "Attribute 19: (qualitative)\n",
    "Telephone\n",
    "A191 : none\n",
    "A192 : yes, registered under the customers name\n",
    "\n",
    "Attribute 20: (qualitative)\n",
    "foreign worker\n",
    "A201 : yes\n",
    "A202 : no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#used libraries\n",
    "library(data.table)\n",
    "library(Matrix)\n",
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(glmnet)\n",
    "library(caret)\n",
    "library(data.table)\n",
    "require(lubridate)\n",
    "library(forecast)\n",
    "library(e1071)\n",
    "library(rpart)\n",
    "require(data.table)\n",
    "require(lubridate)\n",
    "require(caret)\n",
    "library(gbm)\n",
    "library(rpart.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading dataset\n",
    "data_set3 = read.table(\"C:/Users/OZGE/OneDrive - boun.edu.tr/doktora_ders/IE582/HW4/german.data\")\n",
    "data_set3 = as.data.frame(data_set3)\n",
    "size_set3 = nrow(data_set3)\n",
    "column_set3 =ncol(data_set3)\n",
    "#training size determined as 0.75*dataset size\n",
    "train_size3 = size_set3*0.75\n",
    "\n",
    "#Saving as factors of nonnumeric variables and class\n",
    "for (i in 1:column_set3){\n",
    "    if (i != 2 & i != 5 & i !=8 & i !=11 & i !=13 & i !=16 &  i!=18 &  i!=21){\n",
    "        data_set3[,i] = as.factor(data_set3[,i])\n",
    "    }\n",
    "}\n",
    "#generating training set and testing set\n",
    "train_set3 = matrix(0,train_size3,column_set3)\n",
    "test_set3 = matrix(0,(size_set3-train_size3+1),column_set3)\n",
    "train_set3 = data_set3[1:train_size3,]\n",
    "test_set3 = data_set3[(train_size3):size_set3,]\n",
    "class_3_test = test_set3[,1]\n",
    "class_3_train = train_set3[,1]\n",
    "att_test3 = test_set3[,2:column_set3]\n",
    "att_train3 = train_set3[,2:column_set3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_3_test = test_set3[,1]\n",
    "class_3_train = train_set3[,1]\n",
    "att_test3 = test_set3[,2:column_set3]\n",
    "att_train3 = train_set3[,2:column_set3]\n",
    "train_set3=data.frame(train_set3)\n",
    "colnames(train_set3) <- c(\"class\",paste0(\"att_\", 1:20))\n",
    "colnames(test_set3) <- c(\"class\",paste0(\"att_\", 1:20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1 - Lasso Regression\n",
    "set.seed(1)\n",
    "#lambda is determined between 0.0005 and 0.000001 with 6 values\n",
    "lambda_seq = c(seq(0.000001,0.0005,length=6))\n",
    "n_repeats=5\n",
    "n_folds=10\n",
    "lasso_grid = expand.grid(alpha=1,lambda=lambda_seq)\n",
    "Control=trainControl(method = \"repeatedcv\",\n",
    "                           number = n_folds,\n",
    "                           repeats = n_repeats)                         \n",
    "lassolr_fit = train(class~ .,data=train_set3,\n",
    "                 method = \"glmnet\", \n",
    "                 tuneGrid = lasso_grid,\n",
    "                 trControl = Control) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Length Class      Mode     \n",
       "a0          340    -none-     numeric  \n",
       "beta          4    -none-     list     \n",
       "dfmat       340    -none-     numeric  \n",
       "df           85    -none-     numeric  \n",
       "dim           2    -none-     numeric  \n",
       "lambda       85    -none-     numeric  \n",
       "dev.ratio    85    -none-     numeric  \n",
       "nulldev       1    -none-     numeric  \n",
       "npasses       1    -none-     numeric  \n",
       "jerr          1    -none-     numeric  \n",
       "offset        1    -none-     logical  \n",
       "classnames    4    -none-     character\n",
       "grouped       1    -none-     logical  \n",
       "call          5    -none-     call     \n",
       "nobs          1    -none-     numeric  \n",
       "lambdaOpt     1    -none-     numeric  \n",
       "xNames       46    -none-     character\n",
       "problemType   1    -none-     character\n",
       "tuneValue     2    data.frame list     \n",
       "obsLevels     4    -none-     character\n",
       "param         0    -none-     list     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "glmnet \n",
       "\n",
       "750 samples\n",
       " 20 predictor\n",
       "  4 classes: 'A11', 'A12', 'A13', 'A14' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 677, 675, 675, 675, 674, 674, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  lambda     Accuracy   Kappa    \n",
       "  0.0000010  0.4821929  0.2303634\n",
       "  0.0001008  0.4821894  0.2302060\n",
       "  0.0002006  0.4819372  0.2291584\n",
       "  0.0003004  0.4808740  0.2271886\n",
       "  0.0004002  0.4811372  0.2271513\n",
       "  0.0005000  0.4805968  0.2261679\n",
       "\n",
       "Tuning parameter 'alpha' was held constant at a value of 1\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were alpha = 1 and lambda = 1e-06."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lassolr_fit)\n",
    "lassolr_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of lasso model at alpha = 1 and lambda = 1e-06\n",
    "model_lasso_accuracy = 0.4821929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction A11 A12 A13 A14\n",
       "       A11  41   9   2  16\n",
       "       A12  13  21   4  16\n",
       "       A13   3   2   1   1\n",
       "       A14  21  23   5  73\n",
       "\n",
       "Overall Statistics\n",
       "                                         \n",
       "               Accuracy : 0.5418         \n",
       "                 95% CI : (0.478, 0.6046)\n",
       "    No Information Rate : 0.4223         \n",
       "    P-Value [Acc > NIR] : 9.089e-05      \n",
       "                                         \n",
       "                  Kappa : 0.308          \n",
       "                                         \n",
       " Mcnemar's Test P-Value : 0.402          \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: A11 Class: A12 Class: A13 Class: A14\n",
       "Sensitivity              0.5256    0.38182   0.083333     0.6887\n",
       "Specificity              0.8439    0.83163   0.974895     0.6621\n",
       "Pos Pred Value           0.6029    0.38889   0.142857     0.5984\n",
       "Neg Pred Value           0.7978    0.82741   0.954918     0.7442\n",
       "Prevalence               0.3108    0.21912   0.047809     0.4223\n",
       "Detection Rate           0.1633    0.08367   0.003984     0.2908\n",
       "Detection Prevalence     0.2709    0.21514   0.027888     0.4861\n",
       "Balanced Accuracy        0.6848    0.60673   0.529114     0.6754"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prediction with lasso\n",
    "predict_lasso = predict(lassolr_fit, test_set3 )\n",
    "cm = confusionMatrix(predict_lasso, test_set3$class)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall Accuracy\n",
    "overall <- cm$overall\n",
    "overall.accuracy <- overall['Accuracy'] \n",
    "comp_lasso = c()\n",
    "comp_lasso[1] = as.numeric(model_lasso_accuracy)\n",
    "comp_lasso[2]= as.numeric(overall.accuracy)\n",
    "overall.kappa = overall['Kappa']\n",
    "overall.pvalue = overall['AccuracyPValue']\n",
    "comp_lasso[3] = as.numeric(overall.kappa)\n",
    "comp_lasso[4] = as.numeric(overall.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2- Decision Tree\n",
    "set.seed(1)\n",
    "n_repeats=5\n",
    "n_folds=10\n",
    "Control=trainControl(method = \"repeatedcv\",\n",
    "                           number = n_folds,\n",
    "                           repeats = n_repeats)\n",
    "#complexity parameter is selected as 0.01, 0.03, 0.05\n",
    "grid_tree = expand.grid(cp=c(0.01, 0.03, 0.05))\n",
    "#Three different model is trained with different minbucket values\n",
    "tree_fit_minbucket7 = train(class~ ., data=train_set3,\n",
    "                 method = \"rpart\", \n",
    "                 trControl = Control,\n",
    "                control = rpart.control(minbucket=7),\n",
    "                tuneGrid = grid_tree)\n",
    "tree_fit_minbucket10 = train(class~ ., data=train_set3,\n",
    "                 method = \"rpart\", \n",
    "                 trControl = Control,\n",
    "                control = rpart.control(minbucket=10),\n",
    "                            tuneGrid = grid_tree)\n",
    "tree_fit_minbucket5 = train(class~ ., data=train_set3,\n",
    "                 method = \"rpart\", \n",
    "                 trControl = Control,\n",
    "                control = rpart.control(minbucket=5),\n",
    "                           tuneGrid = grid_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results @ minbucket=7"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "750 samples\n",
       " 20 predictor\n",
       "  4 classes: 'A11', 'A12', 'A13', 'A14' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 677, 675, 675, 675, 674, 674, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp    Accuracy   Kappa    \n",
       "  0.01  0.5104073  0.2543352\n",
       "  0.03  0.4672426  0.1800375\n",
       "  0.05  0.4451353  0.1446334\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results @ minbucket=5"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "750 samples\n",
       " 20 predictor\n",
       "  4 classes: 'A11', 'A12', 'A13', 'A14' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 675, 675, 675, 675, 676, 674, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp    Accuracy   Kappa    \n",
       "  0.01  0.5130635  0.2569987\n",
       "  0.03  0.4705939  0.1853562\n",
       "  0.05  0.4477355  0.1485529\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results @ minbucket=10"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "750 samples\n",
       " 20 predictor\n",
       "  4 classes: 'A11', 'A12', 'A13', 'A14' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 675, 676, 675, 675, 674, 676, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp    Accuracy   Kappa    \n",
       "  0.01  0.4976578  0.2324374\n",
       "  0.03  0.4633516  0.1741557\n",
       "  0.05  0.4420515  0.1405564\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat(\"Decision Tree Results @ minbucket=7\")\n",
    "tree_fit_minbucket7\n",
    "cat(\"Decision Tree Results @ minbucket=5\")\n",
    "tree_fit_minbucket5\n",
    "cat(\"Decision Tree Results @ minbucket=10\")\n",
    "tree_fit_minbucket10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy of decision tree at cp = 0.01 and minbucket=5\n",
    "model_tree_accuracy = 0.5130635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAaVBMVEUAAAAXFxcqKio8PDxN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\nAXgAkQA8gEgAHkAkAA/8P+zNHSM+GYstAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Accuracy of the model when minbucket is equal to 5 is higher than the others.\n",
    "rpart.plot(tree_fit_minbucket5$finalModel, box.palette=\"RdBu\", shadow.col=\"gray\", nn=TRUE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A13 is unused according to results, which is an indication of low occurancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction A11 A12 A13 A14\n",
       "       A11  41  12   3  13\n",
       "       A12   7   9   0   3\n",
       "       A13   0   0   0   0\n",
       "       A14  30  34   9  90\n",
       "\n",
       "Overall Statistics\n",
       "                                         \n",
       "               Accuracy : 0.5578         \n",
       "                 95% CI : (0.494, 0.6202)\n",
       "    No Information Rate : 0.4223         \n",
       "    P-Value [Acc > NIR] : 1.075e-05      \n",
       "                                         \n",
       "                  Kappa : 0.291          \n",
       "                                         \n",
       " Mcnemar's Test P-Value : NA             \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: A11 Class: A12 Class: A13 Class: A14\n",
       "Sensitivity              0.5256    0.16364    0.00000     0.8491\n",
       "Specificity              0.8382    0.94898    1.00000     0.4966\n",
       "Pos Pred Value           0.5942    0.47368        NaN     0.5521\n",
       "Neg Pred Value           0.7967    0.80172    0.95219     0.8182\n",
       "Prevalence               0.3108    0.21912    0.04781     0.4223\n",
       "Detection Rate           0.1633    0.03586    0.00000     0.3586\n",
       "Detection Prevalence     0.2749    0.07570    0.00000     0.6494\n",
       "Balanced Accuracy        0.6819    0.55631    0.50000     0.6728"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Accuracy of the model when minbucket is equal to 5 is higher than the others.\n",
    "#For this reason this model is used to predict.\n",
    "predict_tree = predict(tree_fit_minbucket5, test_set3 )\n",
    "cm1 = confusionMatrix(predict_tree, test_set3$class)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_1 <- cm1$overall\n",
    "overall.accuracy_1 <- overall_1['Accuracy'] \n",
    "comp_tree = c()\n",
    "comp_tree[1] = as.numeric(model_tree_accuracy)\n",
    "comp_tree[2]= as.numeric(overall.accuracy_1)\n",
    "overall.kappa_1 = overall_1['Kappa']\n",
    "overall.pvalue_1 = overall_1['AccuracyPValue']\n",
    "comp_tree[3] = as.numeric(overall.kappa_1)\n",
    "comp_tree[4] = as.numeric(overall.pvalue_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Random Forest\n",
    "set.seed(1)\n",
    "n_folds=10\n",
    "Control=trainControl(method = \"cv\",\n",
    "                           number = n_folds)  \n",
    "#the minimal number of observations per tree leaf is determined with different values.\n",
    "#Normally, it is set to 5\n",
    "grid_random_forest <- expand.grid(mtry = c(1,5,9,11,15)) \n",
    "\n",
    "rf_fit = train(class~ ., data=train_set3,\n",
    "                 method = \"rf\", \n",
    "                 ntree=500,\n",
    "                 nodesize=5,\n",
    "                 trControl = Control,\n",
    "                 tuneGrid = grid_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest \n",
       "\n",
       "750 samples\n",
       " 20 predictor\n",
       "  4 classes: 'A11', 'A12', 'A13', 'A14' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 677, 675, 675, 675, 674, 674, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  mtry  Accuracy   Kappa    \n",
       "   1    0.3933363  0.0144007\n",
       "   5    0.5401113  0.3081724\n",
       "   9    0.5281098  0.2919901\n",
       "  11    0.5281795  0.2928325\n",
       "  15    0.5375693  0.3086983\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was mtry = 5."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAgP9NTU1oaGh8\nfHyMjIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHm5ubp6enw8PD////lZQhBAAAACXBIWXMA\nABJ0AAASdAHeZh94AAAgAElEQVR4nO2di3qqOhBGUy/VVrt13v9lt4AXVFQCQzIT1vpO97Fe\nIoP/aiBECAIAowm5FwCgBBAJQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQAFEAlAA\nkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJ\nQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAU\nQCQABRAJQAFEAlAAkQAUQCQABRAJQAFEAlAAkQZS7oqjMmttF025K47KrLVdNOWuOCqz1nbR\nlLviqMxa20VT7oqjMmttF025K47KrLVdNOWuOCqz1nbRlLviqMxa20VT7oqjMmttF025K47K\nrLVdtw/gkeigT2FPW59/AP6IVmryHmni9rPxL/cCTAaVyYDcItJAiJs/EMkgxM0fiGQQ4uYP\nRDIIcfMHIhmEuPkDkQxC3PyBSAYhbv5AJIMQN38gkkGImz8QySDEzR+IZBDi5g9EMghx8wci\nGYS4+QORDELc/IFIBiFu/kAkgxA3fyCSQYibPxDJIMTNH4hkEOLmD0QyCHHzByIZhLj5A5EM\nQtz8gUgGIW7+QCSDEDd/IJJBiJs/EMkgxM0fiGQQ4uYPRDIIcfMHIhmEuPkDkQxC3PyBSAYh\nbv5AJIMQN38gkkGImz8QySDEzR+IZBDi5g9EssfXV+4lmAxEEkRKxEmjf8WqhEiCSIn4qj4U\nRPIGIhmjUuiflGoSIgkipaEy6LRlh0jOQCRrfFX/fX2VuZuESIJIiTgp1Aw2lOgSIgkiJeMm\nUHEdEyIJIiXj6+5DKcolRBJESsbX44dSTseESIJIqfjq/FDKcAmRBJFS0S2SFNExFStSzCeD\nSGl4KVL9oG+XChUpbloXIiXh61PcPHdMpYoUNa0LkZLwUaT6SU5dKlOkyGldiJSEXiKJ046p\nVJHqzwKRTNFXpPq53lwqUaTmLxqbdsY4byb0f74rmQoT6eu89hlssEesSPVr3LhUkEj3f8EY\n/rbGEJHETcdUhkhfHWubA7K2qD+fgXFz4JJ/kV79xUIkW4wRSex3TK5F6uqIriCSLUaKVDdh\n2CW3In38C4VItlAQSQx3TC5F6rU2EckUzQemEjeTLnkT6e3W3B2IZApFkcRix+RJpLi1h0im\n0BWpbtGUS05E6t8RXUEkS5w/POW4GeqYHIg0cG0hkiWmEalu2YZLtkUa0BFdQSRLTCeS2OiY\n7Io0du0gkiUmFal+g8wumRRpTEd0BZEMcfk0J41b1o7JnEhqawORDJFEpPqNcrlkSSSVjugK\nIhkimUiSq2OyIpJ+9Yhkh+tHmypu6V0yIJJuR3QFkeyQXCRJ3jFlFmnCahHJDjlEqt83nUsZ\nRZr4TwYi2SGXSJKuY8oj0kRbc3cgkhluH3W2uE3+HvyJEESamtwiSYLUJa0sRUd0BZHMYECk\niknDl6yy5KP7iGSF1ueee5B4uhSmOkKW/hAZIlnBkEgV04Rx6sryzX9CJCsYE0kmSeWEleXp\niK4gkhXsiVShHM6JKjPwDRFEMkI7CIZEEt2U6leWuSO6gkhGsCtSRYYvG/TAiEM1iGQE2yKJ\nUmrVKrPSEV1BJBvchcKkSBWjw6t1xj5TDtUgkg18iCRjU8w5ZAWRJsWNSBX3YZ7oNIpPzZrb\nmrsDkWzgSiRp9Qz1xVN75zviop53zZp2qAaRTHCfEgciVXxdr0A8gUi3f+xLVIFIJnApktx6\nir5J71vZ133zDkAkE3gVSb7OXcZE5C6vP4hkgYfAOBJp+k07JyCSBTyLlGSwwT6IZAHHIqUb\n/rYNIlnAtUgxUJkg0nQ8/u0lbv5AJAMgkn8QyQCI5B9Eys/TXjVx8wci5QeRCgCR8oNIBYBI\n+UGkAkCk7DwfeCRu/kCk7CBSCSBSdhCpBBApNx1TyoibPxApN4hUBIiUG0QqAkTKDSIVASJl\nputbN8TNH4iUGUQqA0TKDCKVASLlpfP71MTNH4iUF0QqBETKCyIVAiLlBZEKAZGy0n3KKeLm\nD0TKCiKVAiJlBZFKAZFy8uJkosTNH4iUE0QqBkTKCSIVAyLlBJGKAZEy8up6C8TNH4iUEUQq\nB0TKCCKVAyLl4+WVtIibPxApH4hUEIiUD0QqCETKByIVBCJl4/XFhombPxApG4hUEoiUDUQq\nCUTKxWuPiJtDECkXiFQUiJQLRCoKRMoFIhUFImXijUfEzSGIlAlEKgtEygQilQUi5eGdR8TN\nIYiUB0QqDETKAyIVBiLlAZEKA5Gy8NYj4uYQRMoCIpUGImUBkUoDkXLw3iPi5hBEygEiFQci\n5QCRigORcoBIxYFIGfjgEXFzCCJlAJHKA5EygEjlgUjp+eQRcXMIIqUHkQoEkdKDSAWCSOlB\npAJBpOR89Ii4OQSRkoNIJYJIyUGkEkGk1Hz2iLg5BJFSg0hFgkipQaQiQaTUIFKRIFJienhE\n3ByCSIlBpDJBpMQgUpkgUlr6eETcHIJIaUGkQkGktCBSoSBSWhCpUBApKb08Im4OQaSkIFKp\nIFJSEKlUECkl/Twibg5BpJQgUu4FmAxESgki5V6AyUCklCBS7gWYDERKSE+PiJtDECkhiERl\ngkjjQSQqE0QaTV+PiJtDECkdiERlFYg0EkSisgpEGgkiUVkFIo2jt0fEzSGIlAxEorIaRBoH\nIlFZDSKNor9HxM0hiJQKRBIqq0GkUSCSUFkNIo0CkYTKahBpDBEeETeHIFIiEKmCygSRxoFI\nFVQmiDQORKqgMkGkUcR4RNwcgkhpQKQaKhNEGgUi1VCZINIYojwibg5BpCQgUgOVSQqRQgjt\n2+df2/eOaz8fiNRAZZJApNB+Tei8d9wC5QORGqhMphcp3L0odN47boGyEecRcXOIVZFC570j\nFygbiHSGyiS1SNc9pNdNIZI7qExy9Ejh8d765o1/TvjKvQBgiVaCpxfpelcJPVJkh8TfbYdY\n7ZGudyFSSVCZINJwEOkClUmWUbsyRIr1iLg5xJBIzwdkw9O94xYoE4h0hcok5RSh+5lB7qcI\nIdIVKhMmrQ4l2iPi5hBEmhxEukFlgkhDQaQbVCaINBREukFlgkgDifeIuDkEkaYGkVpQmSDS\nQBCpBZUJIg1jgEfEzSGINDGI1IbKREOk/WYVQlht9rEtKS1QDhCpDZXJeJF+l9fvMy13sW2p\nLFAOEKkNlclYkQ6rsPr5O55uHffb0+1DbGsKC5SBIR4RN4ekEmkXNsfWr4dNGN8pIZI7qExG\nirQ+Pjx4/I5t7m37VkGkO6hMGLUbwiCPiJtDEGlSEOkeKhNEGgIi3UNloiHSdhl3Pi/tBUoP\nIt1DZaIg0jb2xHjaC5ScYR4RN4ekFGkRfmKbiGrfHoj0AJWJgkhKHdHL9u2BSA9QmSiItA6P\nB5PGYV6kgR4RN4ekFOmwWClNV+1u3xyI9AiVicqm3cwGGxDpESoTRIoHkR6hMuGAbDRDPSJu\nDkGk6UCkJ6hMVET6rb4hu/6Nbah3+7ZApCeoTDREWp33kFaxLSktUFoGe0TcHJJSpJ+wqL7N\nt9Oa4YBI7qAyURBpGf7q//+FZWxTvdo3BiI9Q2WiOUVoHsPfiPQMlYlqj7SIbapX+7YY7hFx\ncwj7SFOBSB1QmTBqFwkidUBlonMcaT2b40gjPCJuDmFmw0QgUhdUJogUByJ1QWUyUqRqxHtW\ns78RqQsqE0SKYoxHxM0hbNpNAyJ1QmWCSFEgUidUJppThBbFz2wY5RFxc0gOkQ7l7yMhUjdU\nJqOvj9Sm+NnfiNQNlcnYHmnZ9kjnrFyI5A4qE860GsE4j4ibQxi1mwJEegGViaZI+3VsU3Ht\nZweRXkBloiHSZiYzG0Z6RNwcklKkm0fjr2g+aIFSgUivoDJRuT7Sr6zC4bAKhY/aIdIrqEyU\nRu22p97oT+krsojkDioTJZF21fkaCt9HGusRcXNI2guN/cohLGWPSO8hbv5IKdKuEqg+Acp3\nbFM6C5QIRHoJlYnG8Pe2uuc7hE1sSz3bt8Foj4ibQ5jZoA4ivYbKBJH6gkivoTIZfc6GO2Kb\n0lmgNCDSa6hMEKkn4z0ibg5Jumm3rs/9vV/oDNohkj+oTFTm2l2uRqEzbIdI7qAy4fpI/VDw\niLg5JO2k1RlcHwmR3kFlorJpt6imfe8WYRvblM4CpQCR3kFlonl9JJ0vyCKSP6hMFK+PpPO1\nPpsiaXhE3BzCzAZdEOktVCaI1AtEeguVCZd16YOKR8TNIYikCiK9h8qETbs+INJ7qEwQqQ+I\n9B4qE2Z/90DHI+LmEETSBJE+QGXCpl0PEOkDVCaI9Bklj4ibQ7gahSKI9AkqE65G8RlE+gSV\nCVej+AwifYLKhKtRfETLI+LmEK5GoQcifYTKhKtRfASRPkJlwtUoPqHmEXFzCFejUAORPkNl\nwtUoPoFIn6EyGSmS1nkaXrVvAET6DJXJ2Emri80h9vUx7edHzyPi5pBUIi1Pe0Yr5W4JkdxB\nZTJ2H+mwWZxc2vzFNtK3/ewgUg+oTBQGG/bfJ5WWP8fYdvq2nxVFj4ibQxLP/v6tRr+/lTbx\nEMkdVCZaX6M4bk+7SwWeRB+R+kBlovh9pF2JMxsQqQ9UJvRIb9H0iLg5hH0kHRCpF1QmGnPt\nCh61Q6ReUJmMFWlfHUdalHocSdUj4uYQZjaogEj9oDIZPdduq7ZJ19V+ZhCpH1QmI0XSOUvD\n6/Yzg0j9oDLRGv5WOob0sv0s6HpE3ByCSBogUk+oTBDpDYjUEyoTRHqNskfEzSGIpAAi9YXK\nBJFeg0h9oTLhsi6vQaS+UJloiPSzFDksw1LpoJIVkbQ9Im4OSX6CyOrMDYWdRB+RekNloiDS\nKvzKX1jKb2En0Uek3lCZKJ1E/686zWpZ35BV94i4OSS1SOvqImOI9B7i5o+0m3Z/u+pb5oVt\n2iFSf6hMdAYbQthWHVJRl75EpP5QmagMfy/qC1Esf2Nb6tl+FvQ9Im4O4YDsWBApAioTRHoB\nIkVAZcLMhm4m8Ii4OYSZDSNBpBioTJjZ0A0ixUBlwsyGbhApBioTZjZ0MoVHxM0hzGwYByJF\nQWXCzIZOECkKKhNmNnQxiUfEzSEckB0FIsVBZYJIXSBSHFQmKiLV1xlbK23ZIZI/qEw0RKo0\nqtAZtDMg0jQeETeHpBTpJyyq4brdIvzENqWzQOogUiRUJgoiLUNzvb5qmpAGiOQOKhOlmQ33\nN8aRXaSJPCJuDsnTIy1im+rVfnIQKRYqE/aRnkGkWKhMGLV7BpFioTLROY60Luk40lQeETeH\nMLNhOIgUDZWJgkjrTWwLce2nBpGioTLRHP5WIrNIk3lE3BySdvj7GNtEVPuJQaR4qEwURDqu\nV0on4upuPzGIFA+Vicqm3ZXYpnQWSBdEiofKBJEemM4j4uYQhr+HgkgDoDJBpAcQaQBUJqNF\nOnzXM+yOS52Jdk/tJ2ZCj4ibQ5KJdFiEdfX/XQiLQ2xLSgukCSINgcpkrEjL8N0cRdqvlL7X\nh0j+oDIZKdKuOjPkmXXQmbaKSO6gMhkp0ndrVsOhgFMWT+kRcXNIKpHCy1+Gg0juoDIZKdIC\nkfpD3PyRbtPuduL8XTN+N5qMIk3qEXFzSCqR/m6D3oeF/8EGRBoGlcnY4e9NWGyrkwj9bRcF\nnLMBkYZBZTJ6ZsP2OmP1O7YhrQXSA5GGQWUyfq7dYVOfQn+rNK8hp0jTekTcHMKk1SEg0kCo\nTBCpBSINhMpkpEjrx9M1HMfvKWUTaWKPiJtD0s2127RVOmwULsiMSO6gMhn9NYpVWP38VTId\n99vTbYUhB0RyB5XJ+H2k3+V1AHw5vjsaskBaINJQqEw0Bhv29QD4aqN0Uq5cIk3tEXFzCKN2\n8SDSYKhMEOkKIg2GygSRLkzuEXFzCCJFg0jDoTJBpAuINBwqE0S6gEjDoTJBpDPTe0TcHJL0\n+kh636DobD8NiDQCKhOdq1GouoRI7qAy0bjQ2O+3qktZRErgEXFzSOp9pP12qeYSIrmDykRv\nsOFvceqXNC5JgUjuoDJRE2m3qieAK5xJCJHcQWWiI9Jxu6i+RHE82TT+JJE5RErhEXFzSNqv\nUVSDDZu/5sHxGiCSO6hMNI4jnTqjn8sXzsMitrnxC6QAIo2CykTjONJa5YuxL9tPQBKPiJtD\nkh5Him0gsv0EINI4qEw09pGOm2p7brFRMgqR3EFloiDSYVGPMKhdjRmR3EFloiDSqrke83Hj\n9vpIaTwibg5JO2n18cY4EMkdVCYKIi3OF2Q+ItJ7iJs/Uoq0CavqjHb7VdjENqWzQGNJ5BFx\nc0jSUbvV+USrXq/Yh0hjoTJRmWv3u6400pj53d3+xCDSWKhMOGcDIo2HygSRknlE3BySRaS9\nz+NIiDQaKhMNkTbX67rENqWzQCNBpNFQmagMf194MQv80bBwvvOFeYlFSuYRcXNI2gOyv7IK\nh8MqdF8gKTy8ptHn9dsikjuoTJSmCG1PvdFf94Gk8PCiIIhUGlQmSiLtqvMHvdtSC61fH7uo\nsQs0DkQaD5WJgkjr06bdISxlHyXS4x5SuPEvJV9J3w3KpZXgYSLtqhfW04S+P4sUWj8vHE7b\nI6XrkPi77ZCkw9/b6p7v8GLO6p1ID/4YGLVDJAWoTKaf2RBe/PuyqaQiJfSIuDkk6T7S+29P\n3Cn0sA2JSGVAZaL5Ddl3Tw8P9zzfO3yBxoBIGlCZKIi0DO9PH/Q02h067x2+QGNAJA2oTBRE\nOq5X3VMari8IzyN3zxOHhi/QCFJ6RNwckviKfW4nrSKSClQmiJQO4uYPQ8Pf0SQUKalHxM0h\niNQLRNKBygSR0kHc/ME+Ui8QSQcqk1mLlNYj4uaQDJt2+5XOuU8QyR9UJor7SMfur1FEg0ju\noDLRHGzwtmmX2CPi5pAcIv0oXIj5XfvqIJIWVCaqgw3b2KZ0FmgoiKQFlYmiSEuls+gjkjuo\nTGZ8QDa1R8TNIYj0GURSg8pEQ6TjphplWGzef79vePsTgUhqUJkoiHRYhOZMdYtDbFM6CzSM\n5B4RN4ekFGkVvqu+6LgJri7rgkh6UJlonvzE1wFZRNKDykRBpMX55CdHRHoPcfNH2usj1Sc/\n2a9enGp1bPvTkN4j4uaQpKN2q/MR2c6rusSDSO6gMlE5jvS7rjRSmtiASP6gMpnrAdkMHhE3\nhyDSBxBJEyqTuc5sQCRNqEzmOrMBkTShMpnpzIYcHhE3hzCz4T2IpAqVyUxnNiCSKlQm85zZ\nkMUj4uYQZja8BZF0oTKZ58wGRNKFymSeB2QRSRcqE0WR/jZezmuXxyPi5pDkIh22y+DmBJGI\npAyViYpIx99ltZO0i22pb/vaIJIyVCYKIv02o3Y684M62lcnk0fEzSHJRNp9nxxabP6UDsYO\nWqBYEEkbKpORIi0qi6rDsYj0GeLmj1QihctsBkT6DHHzBz3Sa3J5RNwcknofaY9InyFu/mDU\n7jWIpA6VieJxpLWP40jZPCJuDmFmw0sQSR8qk/nNtUMkfahM5jf7G5H0oTKZnUj5PCJuDkGk\nVyDSBFCZIFI6iJs/EOkFGT0ibg5BpBcg0hRQmSBSOoibPxDpBYg0BVQmMxMpp0fEzSGI1A0i\nTQKVCSKlg7j5A5E6yeoRcXMIInWCSNNAZYJI6SBu/kCkThBpGqhMZiVSXo+Im0MQqQtEmggq\nE0RKB3HzByJ1kNkj4uYQROoAkaaCygSR0kHc/IFIHSDSVFCZzEik3B4RN4cg0jOINBlUJoiU\nDuLmD0R6IrtHxM0hiPQEIk0HlQkipYO4+QORnkCk6aAymY1I+T0ibg5BpEcQaUKoTBApHcTN\nH4j0CCJNCJXJXEQy4BFxcwgiPYBIU0JlgkjpIG7+QKR7LHhE3ByCSPcg0qRQmSBSOoibPxDp\nHkSaFCqTeYhkwiPi5hBEugORpoXKBJHSQdz8gUhtbHhE3ByCSG0QaWKoTBApHcTNH4jUBpEm\nhspkDiIZ8Yi4OQSRWiDS1FCZIFI6iJs/EOmGFY+Im0MQ6QYiTQ6VCSKlg7j5A5FuINLkUJmU\nL5IZj4ibQxDpCiJND5UJIqWDuPkDkS7Y8Yi4OQSRLiBSAqhMECkdxM0fiHQBkRJAZVK6SIY8\nIm4OQaQziJQCKhNESgdx8wciNVjyiLg5BJEaECkJVCaIlA7i5g9EakCkJFCZlC2SKY+Im0MQ\nqQaR0kBlgkjpIG7+QKQKWx4RN4cgUgUiJYLKBJHSQdz8gUgViJQIKpOSRTLmEXFzCCIJIqWD\nygSR0kHc/IFI9jwibg5BJERKCJUJIqWDuPkDkRApIVQm5YpkziPi5hBEQqSEUJkgUjqImz8Q\nyZ5HxM0hiIRICaEyQaR0EDd/IBIiJYTKpFSRDHpE3ByCSBqNKEPc/IFIGo0oQ9z8MXeRLHpE\n3ByCSAYhbv5AJIMQN38gkkGImz9mLpJJj4ibQxDJIMTNH4hkEOLmj3mLZNMj4uYQRDIIcfMH\nIhmEuPkDkQxC3Pwxa5GMekTcHIJIBiFu/kAkgxA3f8xZJKseETeHIJJBiJs/EMkgxM0fiGQQ\n4uaPGYtk1iPi5hBEMghx8wciGYS4+WO+Itn1iLg5BJEMQtz8gUgGIW7+QCSDEDd/zFYkwx4R\nN4cgkkGImz8QySDEzR9zFcmyR8TNIYhkEOLmD0QyCHHzByIZhLj5Y6YimfaIuDkEkQxC3PyB\nSAYhbv6Yp0i2PSJuDkEkgxA3fyCSQYibPxDJIMTNH7MUybhHxM0hiGQQ4uYPRDIIcfPHHEWy\n7hFxcwgiGYS4+QORDELc/IFIBiFu/pihSOY9Im4OQSSDEDd/IJJBiJs/5ieSfY+Im0MQySDE\nzR+IZBDi5g9EMghx88fsRHLgEXFzCCIZhLj5A5EMQtz8YUqkEO5fEjrvHd6++PCIuDnEkkjh\n4TWNQI/3jlggQaTMUJlML1J4eFFoOdTZFCK5g8okuUhBEKk4qEzKEMmFR8TNIWZFCvJCpHDj\nXzRf8S8B0KWV4OlFehhnoEcqAyqTtD3S7V9VkXx4RNwcYlWka9eHSCVBZZJ++JseqTyoTDIc\nkH3cURq9QIiUGyqTlFOE2iN3mlOEnHhE3BxiSqSp20ek3FCZIFI6iJs/5iSSF4+Im0MQySDE\nzR+IZBDi5g9EMghx88eMRHLjEXFzCCIZhLj5A5EMQtz8MR+R/HhE3ByCSAYhbv5AJIMQN38g\nkkGImz9mI5Ijj4ibQxDJIMTNH4hkEOLmj7mI5Mkj4uaQeYj09YVIJqAycSxSZZErk4ibP2Yh\nkiCSEahM/Ir01fw4Mom4+QORDELc/DEDkRqFHHlE3BwyC5EYbLAClYljkZxpRNw8Mg+RnEHc\n/IFIBiFu/kAkgxA3fyCSQYibPxDJIMTNH4hkEOLmD0QyCHHzByIZhLj5A5EMQtz8gUgGIW7+\nQCSDEDd/IJJBiJs/EMkgxM0fiGQQ4uYPRDIIcfMHIhmEuPkDkQxC3PyBSAYhbv5AJIMQN38g\nkkGImz8QySDEzR+IZBDi5g9EMghx8wciGYS4+QORDELc/IFIBiFu/kAkgxA3fyCSQYibPxDJ\nIMTNH4hkEOLmD0QyCHHzByIZhLj5A5EMQtz8gUgGIW7+QCSDEDd/IJJBiJs/EMkgxM0fiGQQ\n4uYP1yIBeCQ66FPYMwfKXXFUZq3toil3xVGZtbaLptwVR2XW2i6aclcclVlru2jKXXFUZq3t\noil3xVGZtbaLptwVR2XW2i6aclcclVlru2jKXXFUZq3toil3xVGZtbYBZgMiASiASAAKIBKA\nAogEoAAiASiASAAKIBKAAogEoAAiASiASEMYdn4MB5xrKrC4pqDpPrjiVlgSSl1r54wFKa7E\nVmUTvcFkLZdMoWstNIVNnbkMhMmLKmp1paLQlRakVJHuK5vqLSCWUveQihVJLpVN98EVtrrS\nMPVft3yULtL1n2nahyGUuOoKF+np5iTtQxwlrjpEUmgf4ihx1SGSQvvQlyKTVlO4SBNWVtjq\nSkSBRywbij0gO3llpa2vRBQ9/F1keVNXVtwKA8gBIgEogEgACiASgAKIBKAAIgEogEgACiAS\ngAKIBKAAIgEogEgACiASgAKIBKAAIgEogEgACiASgAKIBKAAIgEogEgACiASgAKINICwkOPp\n53K5nbDaf3zF+/Xc/fBxszy1/dO7qd3HxpvFXXwfPi3Mw5u8aBluIFI8f2Et+9PPVaQQPpk0\nRKTj4pz7Y7+mli8eeBLp1OQ7k55FetUy3GAVxfMTfuqfa942YfXhJUNE+g6rU94Pq7Dp19Sr\nB+5Eqv49Pjb5qZ3yTs6lD6sonu9TB7SuO6FLwj4mbYhIIdRd0fHhwfEinbdL+y8MIn2GVRRJ\nuPEo0m592mjaNL8f1mGxrR/bLE5//5sn/CzD8uf8/G39+CbUncPJmbCsn335vzzG9/Taxc/t\n7uuv9RtUXdf12j/3D206RDpvvR2X9fZp1/ObJ3a0fFn+5rW71Wknjh2oCkSKpEukZtNu29zb\niFHv31Qmraob6/qJq2Zkon68fvJudX7B6eGmi5PfsL280ya0BgXWrdfe/dq0etqPusT98aH1\nix6pfmTz4vm35W213F7++rU/TcWPwyGzBJGi2Yfv+kdaVv3Vv/xWItSnlw6r4ylmy+r3xZ/8\nLap7Lzd/r483/9ahll3T4ne4yXMK7nLTDGPsqqee9m12TcZbv/5WN7/PNsrDQ9f3PtPcbHa7\n6nd/9fxmee9bflx+kUVV9++tD50ziBTNzylK1Y/chr//bo+eRbrsQTUdza65uatvrm6PH+Q2\nSLasd4nuUrn7rrqE6lXr+sFjtTnVNHX9tX6Dcxcj8vxQ897XhbsNBJ6HGruff130u5Yflv/0\nPzbrLiBSNFWnsW46jjphy8UlTofddnUW6fLo5bL0XTfvn/VTbdTtb1t2Dfvtogrtw+Zkx27a\nrbnHhx4N5zYAAAIaSURBVF4cR7o+2vX87pYfSznt4a3/Wn9E5gwiRfK8j7QP582x1eXuQSLV\nf/u34ekIz1/VSamJJI+3x4gk22pX8O1BqdmASJE8i3TqnqrBr1NPtfzZHQaLdPr7vpPlsvVG\nrRsPMnS6cRf31s1PInXd01Ok05beZsk+UgUixbKv5zXUIwPnQP1dBhtO/zyK1OxY7Nv7SOsX\nIv2d9rVaW3br82hY3VOtb3sjt6ZqVp17MnK7uX8vUvfzq5/ullvL39HofGElxHKb19AKYzNf\naC9/j/tIuxejdiJPIskyLFpbdqdA/xxP/1tV71W/9vS25xC3fv2pBtA2zdha9eLWQ7sXo3Z3\nt7uf3+y0dbTcXv7TAv8yancGkWJZ1/Maml3sc6COdZe0OW/x7e9EqQ/TfNc328dhRJ5F2oW7\nTF7aux3iqXdHWk3VeyeXoz2nWNcTFloPtd5b2st7d7vz+bc3eWr5tvzVWP+5YECkWBbhePpp\nbl/CuKm7pO9qHvjTptu2NbNhcZvZIM8iHcP9mN3f96l3WP02v/yc0twabbv+2oydVbf2y2bm\nT+uh7YuZDXe3u57fPPjU8v3yn2c24FEFItlhF57H7MAJiGSHFZNt/IJIVrjsDYFLEMkKi+Zo\nFPgEkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAUQCQABRAJQAFEAlAAkQAUQCQA\nBRAJQAFEAlDgP/CrEOsAg1sKAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_fit\n",
    "plot(rf_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy increases as the number of randomly selected predictors increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy of random forest at mtry=5\n",
    "model_forest_accuracy = 0.5401113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction by using random forests method\n",
    "predict_forest = predict(rf_fit, test_set3 )\n",
    "cm_2 = confusionMatrix(predict_forest, test_set3$class)\n",
    "overall_2 <- cm_2$overall\n",
    "overall.accuracy_2 <- overall_2['Accuracy'] \n",
    "comp_forest = c()\n",
    "comp_forest[1] = as.numeric(model_forest_accuracy)\n",
    "comp_forest[2]= as.numeric(overall.accuracy_2)\n",
    "overall.kappa_2 = overall_2['Kappa']\n",
    "overall.pvalue_2 = overall_2['AccuracyPValue']\n",
    "comp_forest[3] = as.numeric(overall.kappa_2)\n",
    "comp_forest[4] = as.numeric(overall.pvalue_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0007\n",
      "     2        1.3858             nan     0.0010    0.0007\n",
      "     3        1.3853             nan     0.0010    0.0007\n",
      "     4        1.3848             nan     0.0010    0.0006\n",
      "     5        1.3843             nan     0.0010    0.0006\n",
      "     6        1.3839             nan     0.0010    0.0007\n",
      "     7        1.3834             nan     0.0010    0.0007\n",
      "     8        1.3829             nan     0.0010    0.0007\n",
      "     9        1.3824             nan     0.0010    0.0007\n",
      "    10        1.3820             nan     0.0010    0.0007\n",
      "    20        1.3774             nan     0.0010    0.0007\n",
      "    40        1.3686             nan     0.0010    0.0006\n",
      "    60        1.3602             nan     0.0010    0.0005\n",
      "    80        1.3523             nan     0.0010    0.0005\n",
      "   100        1.3447             nan     0.0010    0.0005\n",
      "   120        1.3374             nan     0.0010    0.0004\n",
      "   140        1.3305             nan     0.0010    0.0005\n",
      "   160        1.3239             nan     0.0010    0.0005\n",
      "   180        1.3176             nan     0.0010    0.0004\n",
      "   200        1.3114             nan     0.0010    0.0004\n",
      "   220        1.3057             nan     0.0010    0.0004\n",
      "   240        1.3004             nan     0.0010    0.0003\n",
      "   260        1.2951             nan     0.0010    0.0004\n",
      "   280        1.2900             nan     0.0010    0.0004\n",
      "   300        1.2854             nan     0.0010    0.0003\n",
      "   320        1.2806             nan     0.0010    0.0003\n",
      "   340        1.2762             nan     0.0010    0.0003\n",
      "   360        1.2719             nan     0.0010    0.0002\n",
      "   380        1.2678             nan     0.0010    0.0003\n",
      "   400        1.2638             nan     0.0010    0.0002\n",
      "   420        1.2599             nan     0.0010    0.0002\n",
      "   440        1.2563             nan     0.0010    0.0002\n",
      "   460        1.2526             nan     0.0010    0.0002\n",
      "   480        1.2491             nan     0.0010    0.0002\n",
      "   500        1.2457             nan     0.0010    0.0002\n",
      "   520        1.2425             nan     0.0010    0.0002\n",
      "   540        1.2394             nan     0.0010    0.0002\n",
      "   560        1.2365             nan     0.0010    0.0002\n",
      "   580        1.2336             nan     0.0010    0.0001\n",
      "   600        1.2308             nan     0.0010    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0007\n",
      "     2        1.3857             nan     0.0010    0.0008\n",
      "     3        1.3851             nan     0.0010    0.0008\n",
      "     4        1.3845             nan     0.0010    0.0008\n",
      "     5        1.3839             nan     0.0010    0.0008\n",
      "     6        1.3833             nan     0.0010    0.0008\n",
      "     7        1.3826             nan     0.0010    0.0008\n",
      "     8        1.3821             nan     0.0010    0.0007\n",
      "     9        1.3815             nan     0.0010    0.0008\n",
      "    10        1.3808             nan     0.0010    0.0008\n",
      "    20        1.3750             nan     0.0010    0.0007\n",
      "    40        1.3634             nan     0.0010    0.0007\n",
      "    60        1.3524             nan     0.0010    0.0007\n",
      "    80        1.3421             nan     0.0010    0.0006\n",
      "   100        1.3321             nan     0.0010    0.0006\n",
      "   120        1.3226             nan     0.0010    0.0006\n",
      "   140        1.3135             nan     0.0010    0.0006\n",
      "   160        1.3047             nan     0.0010    0.0005\n",
      "   180        1.2963             nan     0.0010    0.0005\n",
      "   200        1.2881             nan     0.0010    0.0005\n",
      "   220        1.2804             nan     0.0010    0.0003\n",
      "   240        1.2729             nan     0.0010    0.0005\n",
      "   260        1.2657             nan     0.0010    0.0004\n",
      "   280        1.2587             nan     0.0010    0.0004\n",
      "   300        1.2522             nan     0.0010    0.0004\n",
      "   320        1.2457             nan     0.0010    0.0004\n",
      "   340        1.2395             nan     0.0010    0.0003\n",
      "   360        1.2333             nan     0.0010    0.0003\n",
      "   380        1.2276             nan     0.0010    0.0003\n",
      "   400        1.2220             nan     0.0010    0.0003\n",
      "   420        1.2166             nan     0.0010    0.0003\n",
      "   440        1.2112             nan     0.0010    0.0003\n",
      "   460        1.2062             nan     0.0010    0.0002\n",
      "   480        1.2012             nan     0.0010    0.0002\n",
      "   500        1.1964             nan     0.0010    0.0002\n",
      "   520        1.1917             nan     0.0010    0.0002\n",
      "   540        1.1871             nan     0.0010    0.0002\n",
      "   560        1.1826             nan     0.0010    0.0001\n",
      "   580        1.1783             nan     0.0010    0.0002\n",
      "   600        1.1740             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0008\n",
      "     2        1.3856             nan     0.0010    0.0007\n",
      "     3        1.3849             nan     0.0010    0.0009\n",
      "     4        1.3841             nan     0.0010    0.0008\n",
      "     5        1.3834             nan     0.0010    0.0010\n",
      "     6        1.3827             nan     0.0010    0.0009\n",
      "     7        1.3820             nan     0.0010    0.0007\n",
      "     8        1.3813             nan     0.0010    0.0009\n",
      "     9        1.3806             nan     0.0010    0.0010\n",
      "    10        1.3798             nan     0.0010    0.0008\n",
      "    20        1.3729             nan     0.0010    0.0008\n",
      "    40        1.3599             nan     0.0010    0.0008\n",
      "    60        1.3471             nan     0.0010    0.0007\n",
      "    80        1.3349             nan     0.0010    0.0006\n",
      "   100        1.3235             nan     0.0010    0.0006\n",
      "   120        1.3121             nan     0.0010    0.0006\n",
      "   140        1.3011             nan     0.0010    0.0006\n",
      "   160        1.2907             nan     0.0010    0.0006\n",
      "   180        1.2808             nan     0.0010    0.0004\n",
      "   200        1.2714             nan     0.0010    0.0004\n",
      "   220        1.2621             nan     0.0010    0.0005\n",
      "   240        1.2532             nan     0.0010    0.0004\n",
      "   260        1.2445             nan     0.0010    0.0004\n",
      "   280        1.2362             nan     0.0010    0.0004\n",
      "   300        1.2282             nan     0.0010    0.0002\n",
      "   320        1.2205             nan     0.0010    0.0004\n",
      "   340        1.2128             nan     0.0010    0.0004\n",
      "   360        1.2057             nan     0.0010    0.0003\n",
      "   380        1.1987             nan     0.0010    0.0003\n",
      "   400        1.1917             nan     0.0010    0.0003\n",
      "   420        1.1851             nan     0.0010    0.0002\n",
      "   440        1.1787             nan     0.0010    0.0002\n",
      "   460        1.1726             nan     0.0010    0.0002\n",
      "   480        1.1663             nan     0.0010    0.0003\n",
      "   500        1.1604             nan     0.0010    0.0004\n",
      "   520        1.1547             nan     0.0010    0.0002\n",
      "   540        1.1491             nan     0.0010    0.0002\n",
      "   560        1.1437             nan     0.0010    0.0001\n",
      "   580        1.1383             nan     0.0010    0.0002\n",
      "   600        1.1330             nan     0.0010    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0069\n",
      "     2        1.3815             nan     0.0100    0.0069\n",
      "     3        1.3766             nan     0.0100    0.0064\n",
      "     4        1.3725             nan     0.0100    0.0062\n",
      "     5        1.3683             nan     0.0100    0.0056\n",
      "     6        1.3641             nan     0.0100    0.0058\n",
      "     7        1.3599             nan     0.0100    0.0054\n",
      "     8        1.3561             nan     0.0100    0.0057\n",
      "     9        1.3517             nan     0.0100    0.0049\n",
      "    10        1.3484             nan     0.0100    0.0052\n",
      "    20        1.3143             nan     0.0100    0.0039\n",
      "    40        1.2656             nan     0.0100    0.0027\n",
      "    60        1.2316             nan     0.0100    0.0015\n",
      "    80        1.2069             nan     0.0100    0.0007\n",
      "   100        1.1885             nan     0.0100    0.0009\n",
      "   120        1.1741             nan     0.0100    0.0000\n",
      "   140        1.1626             nan     0.0100    0.0003\n",
      "   160        1.1528             nan     0.0100    0.0003\n",
      "   180        1.1443             nan     0.0100   -0.0003\n",
      "   200        1.1366             nan     0.0100   -0.0003\n",
      "   220        1.1302             nan     0.0100   -0.0003\n",
      "   240        1.1242             nan     0.0100   -0.0003\n",
      "   260        1.1185             nan     0.0100   -0.0008\n",
      "   280        1.1131             nan     0.0100   -0.0003\n",
      "   300        1.1078             nan     0.0100   -0.0004\n",
      "   320        1.1028             nan     0.0100   -0.0005\n",
      "   340        1.0979             nan     0.0100   -0.0002\n",
      "   360        1.0937             nan     0.0100   -0.0006\n",
      "   380        1.0897             nan     0.0100   -0.0006\n",
      "   400        1.0860             nan     0.0100   -0.0002\n",
      "   420        1.0822             nan     0.0100   -0.0004\n",
      "   440        1.0784             nan     0.0100   -0.0003\n",
      "   460        1.0747             nan     0.0100   -0.0008\n",
      "   480        1.0715             nan     0.0100   -0.0003\n",
      "   500        1.0681             nan     0.0100   -0.0007\n",
      "   520        1.0650             nan     0.0100   -0.0005\n",
      "   540        1.0621             nan     0.0100   -0.0002\n",
      "   560        1.0588             nan     0.0100   -0.0005\n",
      "   580        1.0559             nan     0.0100   -0.0004\n",
      "   600        1.0529             nan     0.0100   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0072\n",
      "     2        1.3803             nan     0.0100    0.0075\n",
      "     3        1.3743             nan     0.0100    0.0075\n",
      "     4        1.3687             nan     0.0100    0.0070\n",
      "     5        1.3634             nan     0.0100    0.0056\n",
      "     6        1.3582             nan     0.0100    0.0071\n",
      "     7        1.3525             nan     0.0100    0.0069\n",
      "     8        1.3475             nan     0.0100    0.0050\n",
      "     9        1.3426             nan     0.0100    0.0061\n",
      "    10        1.3376             nan     0.0100    0.0062\n",
      "    20        1.2930             nan     0.0100    0.0044\n",
      "    40        1.2245             nan     0.0100    0.0030\n",
      "    60        1.1742             nan     0.0100    0.0020\n",
      "    80        1.1372             nan     0.0100    0.0004\n",
      "   100        1.1081             nan     0.0100    0.0006\n",
      "   120        1.0835             nan     0.0100    0.0003\n",
      "   140        1.0616             nan     0.0100    0.0003\n",
      "   160        1.0418             nan     0.0100   -0.0002\n",
      "   180        1.0244             nan     0.0100   -0.0003\n",
      "   200        1.0094             nan     0.0100   -0.0009\n",
      "   220        0.9959             nan     0.0100   -0.0010\n",
      "   240        0.9827             nan     0.0100   -0.0008\n",
      "   260        0.9699             nan     0.0100   -0.0009\n",
      "   280        0.9582             nan     0.0100   -0.0006\n",
      "   300        0.9465             nan     0.0100   -0.0013\n",
      "   320        0.9354             nan     0.0100   -0.0009\n",
      "   340        0.9247             nan     0.0100   -0.0009\n",
      "   360        0.9147             nan     0.0100   -0.0002\n",
      "   380        0.9042             nan     0.0100   -0.0009\n",
      "   400        0.8942             nan     0.0100   -0.0015\n",
      "   420        0.8848             nan     0.0100   -0.0004\n",
      "   440        0.8767             nan     0.0100   -0.0010\n",
      "   460        0.8684             nan     0.0100   -0.0011\n",
      "   480        0.8598             nan     0.0100   -0.0005\n",
      "   500        0.8511             nan     0.0100   -0.0009\n",
      "   520        0.8430             nan     0.0100   -0.0012\n",
      "   540        0.8358             nan     0.0100   -0.0006\n",
      "   560        0.8281             nan     0.0100   -0.0006\n",
      "   580        0.8206             nan     0.0100   -0.0012\n",
      "   600        0.8129             nan     0.0100   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0089\n",
      "     2        1.3793             nan     0.0100    0.0090\n",
      "     3        1.3721             nan     0.0100    0.0093\n",
      "     4        1.3653             nan     0.0100    0.0077\n",
      "     5        1.3586             nan     0.0100    0.0068\n",
      "     6        1.3525             nan     0.0100    0.0080\n",
      "     7        1.3459             nan     0.0100    0.0052\n",
      "     8        1.3398             nan     0.0100    0.0082\n",
      "     9        1.3335             nan     0.0100    0.0061\n",
      "    10        1.3277             nan     0.0100    0.0065\n",
      "    20        1.2744             nan     0.0100    0.0039\n",
      "    40        1.1938             nan     0.0100    0.0014\n",
      "    60        1.1348             nan     0.0100    0.0017\n",
      "    80        1.0876             nan     0.0100    0.0003\n",
      "   100        1.0492             nan     0.0100    0.0004\n",
      "   120        1.0173             nan     0.0100   -0.0003\n",
      "   140        0.9888             nan     0.0100    0.0002\n",
      "   160        0.9627             nan     0.0100   -0.0009\n",
      "   180        0.9406             nan     0.0100   -0.0008\n",
      "   200        0.9206             nan     0.0100   -0.0014\n",
      "   220        0.9012             nan     0.0100   -0.0006\n",
      "   240        0.8819             nan     0.0100   -0.0012\n",
      "   260        0.8648             nan     0.0100   -0.0007\n",
      "   280        0.8481             nan     0.0100   -0.0012\n",
      "   300        0.8323             nan     0.0100   -0.0015\n",
      "   320        0.8172             nan     0.0100   -0.0007\n",
      "   340        0.8026             nan     0.0100   -0.0005\n",
      "   360        0.7883             nan     0.0100   -0.0015\n",
      "   380        0.7755             nan     0.0100   -0.0011\n",
      "   400        0.7623             nan     0.0100   -0.0008\n",
      "   420        0.7496             nan     0.0100   -0.0013\n",
      "   440        0.7381             nan     0.0100   -0.0012\n",
      "   460        0.7261             nan     0.0100   -0.0014\n",
      "   480        0.7153             nan     0.0100   -0.0012\n",
      "   500        0.7044             nan     0.0100   -0.0011\n",
      "   520        0.6937             nan     0.0100   -0.0007\n",
      "   540        0.6836             nan     0.0100   -0.0013\n",
      "   560        0.6731             nan     0.0100   -0.0010\n",
      "   580        0.6629             nan     0.0100   -0.0012\n",
      "   600        0.6530             nan     0.0100   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0577\n",
      "     2        1.3451             nan     0.1000    0.0496\n",
      "     3        1.3110             nan     0.1000    0.0377\n",
      "     4        1.2838             nan     0.1000    0.0250\n",
      "     5        1.2632             nan     0.1000    0.0206\n",
      "     6        1.2467             nan     0.1000    0.0173\n",
      "     7        1.2326             nan     0.1000    0.0142\n",
      "     8        1.2176             nan     0.1000    0.0121\n",
      "     9        1.2068             nan     0.1000    0.0111\n",
      "    10        1.1966             nan     0.1000    0.0049\n",
      "    20        1.1405             nan     0.1000    0.0007\n",
      "    40        1.0897             nan     0.1000   -0.0047\n",
      "    60        1.0600             nan     0.1000   -0.0061\n",
      "    80        1.0376             nan     0.1000   -0.0040\n",
      "   100        1.0161             nan     0.1000   -0.0085\n",
      "   120        1.0001             nan     0.1000   -0.0056\n",
      "   140        0.9881             nan     0.1000   -0.0074\n",
      "   160        0.9764             nan     0.1000   -0.0065\n",
      "   180        0.9638             nan     0.1000   -0.0078\n",
      "   200        0.9555             nan     0.1000   -0.0063\n",
      "   220        0.9461             nan     0.1000   -0.0089\n",
      "   240        0.9394             nan     0.1000   -0.0095\n",
      "   260        0.9304             nan     0.1000   -0.0061\n",
      "   280        0.9262             nan     0.1000   -0.0085\n",
      "   300        0.9196             nan     0.1000   -0.0069\n",
      "   320        0.9161             nan     0.1000   -0.0055\n",
      "   340        0.9093             nan     0.1000   -0.0095\n",
      "   360        0.9056             nan     0.1000   -0.0085\n",
      "   380        0.9004             nan     0.1000   -0.0067\n",
      "   400        0.8970             nan     0.1000   -0.0086\n",
      "   420        0.8915             nan     0.1000   -0.0106\n",
      "   440        0.8870             nan     0.1000   -0.0071\n",
      "   460        0.8822             nan     0.1000   -0.0088\n",
      "   480        0.8776             nan     0.1000   -0.0068\n",
      "   500        0.8742             nan     0.1000   -0.0078\n",
      "   520        0.8709             nan     0.1000   -0.0083\n",
      "   540        0.8674             nan     0.1000   -0.0072\n",
      "   560        0.8635             nan     0.1000   -0.0078\n",
      "   580        0.8601             nan     0.1000   -0.0101\n",
      "   600        0.8567             nan     0.1000   -0.0073\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0551\n",
      "     2        1.3347             nan     0.1000    0.0506\n",
      "     3        1.2886             nan     0.1000    0.0441\n",
      "     4        1.2517             nan     0.1000    0.0367\n",
      "     5        1.2215             nan     0.1000    0.0257\n",
      "     6        1.1985             nan     0.1000    0.0197\n",
      "     7        1.1752             nan     0.1000    0.0142\n",
      "     8        1.1537             nan     0.1000    0.0081\n",
      "     9        1.1355             nan     0.1000   -0.0051\n",
      "    10        1.1222             nan     0.1000    0.0053\n",
      "    20        1.0221             nan     0.1000   -0.0114\n",
      "    40        0.9139             nan     0.1000   -0.0085\n",
      "    60        0.8376             nan     0.1000   -0.0121\n",
      "    80        0.7681             nan     0.1000   -0.0079\n",
      "   100        0.7135             nan     0.1000   -0.0107\n",
      "   120        0.6623             nan     0.1000   -0.0125\n",
      "   140        0.6196             nan     0.1000   -0.0080\n",
      "   160        0.5815             nan     0.1000   -0.0100\n",
      "   180        0.5431             nan     0.1000   -0.0088\n",
      "   200        0.5111             nan     0.1000   -0.0081\n",
      "   220        0.4819             nan     0.1000   -0.0080\n",
      "   240        0.4534             nan     0.1000   -0.0080\n",
      "   260        0.4276             nan     0.1000   -0.0044\n",
      "   280        0.4053             nan     0.1000   -0.0063\n",
      "   300        0.3839             nan     0.1000   -0.0061\n",
      "   320        0.3648             nan     0.1000   -0.0076\n",
      "   340        0.3428             nan     0.1000   -0.0066\n",
      "   360        0.3250             nan     0.1000   -0.0042\n",
      "   380        0.3084             nan     0.1000   -0.0059\n",
      "   400        0.2923             nan     0.1000   -0.0059\n",
      "   420        0.2791             nan     0.1000   -0.0049\n",
      "   440        0.2642             nan     0.1000   -0.0055\n",
      "   460        0.2514             nan     0.1000   -0.0034\n",
      "   480        0.2404             nan     0.1000   -0.0054\n",
      "   500        0.2291             nan     0.1000   -0.0036\n",
      "   520        0.2182             nan     0.1000   -0.0038\n",
      "   540        0.2077             nan     0.1000   -0.0035\n",
      "   560        0.1966             nan     0.1000   -0.0040\n",
      "   580        0.1892             nan     0.1000   -0.0037\n",
      "   600        0.1810             nan     0.1000   -0.0032\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0613\n",
      "     2        1.3264             nan     0.1000    0.0450\n",
      "     3        1.2730             nan     0.1000    0.0303\n",
      "     4        1.2337             nan     0.1000    0.0339\n",
      "     5        1.1935             nan     0.1000    0.0244\n",
      "     6        1.1640             nan     0.1000    0.0174\n",
      "     7        1.1369             nan     0.1000    0.0170\n",
      "     8        1.1116             nan     0.1000    0.0055\n",
      "     9        1.0905             nan     0.1000    0.0119\n",
      "    10        1.0697             nan     0.1000    0.0025\n",
      "    20        0.9380             nan     0.1000   -0.0116\n",
      "    40        0.7728             nan     0.1000   -0.0150\n",
      "    60        0.6668             nan     0.1000   -0.0122\n",
      "    80        0.5780             nan     0.1000   -0.0143\n",
      "   100        0.5098             nan     0.1000   -0.0141\n",
      "   120        0.4492             nan     0.1000   -0.0124\n",
      "   140        0.3975             nan     0.1000   -0.0071\n",
      "   160        0.3511             nan     0.1000   -0.0078\n",
      "   180        0.3146             nan     0.1000   -0.0085\n",
      "   200        0.2825             nan     0.1000   -0.0073\n",
      "   220        0.2555             nan     0.1000   -0.0049\n",
      "   240        0.2286             nan     0.1000   -0.0031\n",
      "   260        0.2056             nan     0.1000   -0.0048\n",
      "   280        0.1863             nan     0.1000   -0.0025\n",
      "   300        0.1685             nan     0.1000   -0.0037\n",
      "   320        0.1522             nan     0.1000   -0.0028\n",
      "   340        0.1367             nan     0.1000   -0.0024\n",
      "   360        0.1246             nan     0.1000   -0.0031\n",
      "   380        0.1116             nan     0.1000   -0.0027\n",
      "   400        0.1017             nan     0.1000   -0.0026\n",
      "   420        0.0924             nan     0.1000   -0.0028\n",
      "   440        0.0844             nan     0.1000   -0.0022\n",
      "   460        0.0767             nan     0.1000   -0.0017\n",
      "   480        0.0700             nan     0.1000   -0.0013\n",
      "   500        0.0635             nan     0.1000   -0.0013\n",
      "   520        0.0582             nan     0.1000   -0.0016\n",
      "   540        0.0534             nan     0.1000   -0.0013\n",
      "   560        0.0487             nan     0.1000   -0.0012\n",
      "   580        0.0447             nan     0.1000   -0.0008\n",
      "   600        0.0406             nan     0.1000   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0007\n",
      "     2        1.3858             nan     0.0010    0.0007\n",
      "     3        1.3853             nan     0.0010    0.0008\n",
      "     4        1.3848             nan     0.0010    0.0007\n",
      "     5        1.3843             nan     0.0010    0.0007\n",
      "     6        1.3839             nan     0.0010    0.0005\n",
      "     7        1.3834             nan     0.0010    0.0006\n",
      "     8        1.3829             nan     0.0010    0.0007\n",
      "     9        1.3825             nan     0.0010    0.0005\n",
      "    10        1.3820             nan     0.0010    0.0007\n",
      "    20        1.3772             nan     0.0010    0.0007\n",
      "    40        1.3681             nan     0.0010    0.0007\n",
      "    60        1.3595             nan     0.0010    0.0006\n",
      "    80        1.3515             nan     0.0010    0.0005\n",
      "   100        1.3438             nan     0.0010    0.0006\n",
      "   120        1.3367             nan     0.0010    0.0005\n",
      "   140        1.3297             nan     0.0010    0.0005\n",
      "   160        1.3231             nan     0.0010    0.0005\n",
      "   180        1.3165             nan     0.0010    0.0004\n",
      "   200        1.3106             nan     0.0010    0.0004\n",
      "   220        1.3048             nan     0.0010    0.0004\n",
      "   240        1.2994             nan     0.0010    0.0004\n",
      "   260        1.2943             nan     0.0010    0.0003\n",
      "   280        1.2895             nan     0.0010    0.0004\n",
      "   300        1.2846             nan     0.0010    0.0003\n",
      "   320        1.2798             nan     0.0010    0.0003\n",
      "   340        1.2755             nan     0.0010    0.0003\n",
      "   360        1.2711             nan     0.0010    0.0003\n",
      "   380        1.2672             nan     0.0010    0.0003\n",
      "   400        1.2635             nan     0.0010    0.0003\n",
      "   420        1.2597             nan     0.0010    0.0003\n",
      "   440        1.2561             nan     0.0010    0.0003\n",
      "   460        1.2526             nan     0.0010    0.0002\n",
      "   480        1.2492             nan     0.0010    0.0002\n",
      "   500        1.2460             nan     0.0010    0.0002\n",
      "   520        1.2429             nan     0.0010    0.0002\n",
      "   540        1.2399             nan     0.0010    0.0001\n",
      "   560        1.2369             nan     0.0010    0.0002\n",
      "   580        1.2341             nan     0.0010    0.0002\n",
      "   600        1.2313             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0009\n",
      "     2        1.3857             nan     0.0010    0.0007\n",
      "     3        1.3851             nan     0.0010    0.0007\n",
      "     4        1.3846             nan     0.0010    0.0008\n",
      "     5        1.3839             nan     0.0010    0.0008\n",
      "     6        1.3833             nan     0.0010    0.0008\n",
      "     7        1.3827             nan     0.0010    0.0008\n",
      "     8        1.3821             nan     0.0010    0.0007\n",
      "     9        1.3815             nan     0.0010    0.0008\n",
      "    10        1.3809             nan     0.0010    0.0008\n",
      "    20        1.3749             nan     0.0010    0.0008\n",
      "    40        1.3636             nan     0.0010    0.0007\n",
      "    60        1.3530             nan     0.0010    0.0006\n",
      "    80        1.3423             nan     0.0010    0.0007\n",
      "   100        1.3322             nan     0.0010    0.0006\n",
      "   120        1.3225             nan     0.0010    0.0005\n",
      "   140        1.3133             nan     0.0010    0.0006\n",
      "   160        1.3045             nan     0.0010    0.0006\n",
      "   180        1.2960             nan     0.0010    0.0004\n",
      "   200        1.2882             nan     0.0010    0.0005\n",
      "   220        1.2804             nan     0.0010    0.0004\n",
      "   240        1.2729             nan     0.0010    0.0003\n",
      "   260        1.2658             nan     0.0010    0.0004\n",
      "   280        1.2589             nan     0.0010    0.0004\n",
      "   300        1.2521             nan     0.0010    0.0004\n",
      "   320        1.2458             nan     0.0010    0.0003\n",
      "   340        1.2396             nan     0.0010    0.0003\n",
      "   360        1.2338             nan     0.0010    0.0003\n",
      "   380        1.2278             nan     0.0010    0.0002\n",
      "   400        1.2224             nan     0.0010    0.0003\n",
      "   420        1.2169             nan     0.0010    0.0002\n",
      "   440        1.2118             nan     0.0010    0.0002\n",
      "   460        1.2070             nan     0.0010    0.0003\n",
      "   480        1.2020             nan     0.0010    0.0002\n",
      "   500        1.1974             nan     0.0010    0.0003\n",
      "   520        1.1929             nan     0.0010    0.0003\n",
      "   540        1.1884             nan     0.0010    0.0002\n",
      "   560        1.1841             nan     0.0010    0.0001\n",
      "   580        1.1798             nan     0.0010    0.0001\n",
      "   600        1.1758             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0009\n",
      "     2        1.3855             nan     0.0010    0.0008\n",
      "     3        1.3848             nan     0.0010    0.0007\n",
      "     4        1.3841             nan     0.0010    0.0008\n",
      "     5        1.3833             nan     0.0010    0.0009\n",
      "     6        1.3826             nan     0.0010    0.0008\n",
      "     7        1.3819             nan     0.0010    0.0009\n",
      "     8        1.3812             nan     0.0010    0.0007\n",
      "     9        1.3805             nan     0.0010    0.0009\n",
      "    10        1.3798             nan     0.0010    0.0008\n",
      "    20        1.3729             nan     0.0010    0.0008\n",
      "    40        1.3596             nan     0.0010    0.0008\n",
      "    60        1.3470             nan     0.0010    0.0006\n",
      "    80        1.3351             nan     0.0010    0.0007\n",
      "   100        1.3236             nan     0.0010    0.0005\n",
      "   120        1.3123             nan     0.0010    0.0005\n",
      "   140        1.3016             nan     0.0010    0.0005\n",
      "   160        1.2912             nan     0.0010    0.0006\n",
      "   180        1.2814             nan     0.0010    0.0004\n",
      "   200        1.2719             nan     0.0010    0.0005\n",
      "   220        1.2626             nan     0.0010    0.0005\n",
      "   240        1.2537             nan     0.0010    0.0004\n",
      "   260        1.2453             nan     0.0010    0.0004\n",
      "   280        1.2372             nan     0.0010    0.0005\n",
      "   300        1.2292             nan     0.0010    0.0003\n",
      "   320        1.2217             nan     0.0010    0.0003\n",
      "   340        1.2143             nan     0.0010    0.0003\n",
      "   360        1.2073             nan     0.0010    0.0003\n",
      "   380        1.2004             nan     0.0010    0.0003\n",
      "   400        1.1937             nan     0.0010    0.0003\n",
      "   420        1.1874             nan     0.0010    0.0002\n",
      "   440        1.1811             nan     0.0010    0.0002\n",
      "   460        1.1750             nan     0.0010    0.0003\n",
      "   480        1.1691             nan     0.0010    0.0003\n",
      "   500        1.1635             nan     0.0010    0.0002\n",
      "   520        1.1582             nan     0.0010    0.0002\n",
      "   540        1.1527             nan     0.0010    0.0002\n",
      "   560        1.1474             nan     0.0010    0.0002\n",
      "   580        1.1422             nan     0.0010    0.0002\n",
      "   600        1.1371             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0059\n",
      "     2        1.3821             nan     0.0100    0.0066\n",
      "     3        1.3772             nan     0.0100    0.0069\n",
      "     4        1.3727             nan     0.0100    0.0059\n",
      "     5        1.3685             nan     0.0100    0.0067\n",
      "     6        1.3640             nan     0.0100    0.0054\n",
      "     7        1.3597             nan     0.0100    0.0060\n",
      "     8        1.3550             nan     0.0100    0.0052\n",
      "     9        1.3514             nan     0.0100    0.0055\n",
      "    10        1.3473             nan     0.0100    0.0053\n",
      "    20        1.3137             nan     0.0100    0.0042\n",
      "    40        1.2652             nan     0.0100    0.0022\n",
      "    60        1.2325             nan     0.0100    0.0011\n",
      "    80        1.2095             nan     0.0100    0.0009\n",
      "   100        1.1926             nan     0.0100    0.0007\n",
      "   120        1.1778             nan     0.0100    0.0003\n",
      "   140        1.1663             nan     0.0100    0.0003\n",
      "   160        1.1564             nan     0.0100   -0.0003\n",
      "   180        1.1482             nan     0.0100   -0.0007\n",
      "   200        1.1411             nan     0.0100   -0.0004\n",
      "   220        1.1350             nan     0.0100   -0.0001\n",
      "   240        1.1294             nan     0.0100   -0.0005\n",
      "   260        1.1240             nan     0.0100   -0.0002\n",
      "   280        1.1191             nan     0.0100   -0.0002\n",
      "   300        1.1143             nan     0.0100   -0.0004\n",
      "   320        1.1098             nan     0.0100   -0.0003\n",
      "   340        1.1055             nan     0.0100   -0.0004\n",
      "   360        1.1011             nan     0.0100   -0.0001\n",
      "   380        1.0970             nan     0.0100   -0.0007\n",
      "   400        1.0938             nan     0.0100   -0.0001\n",
      "   420        1.0900             nan     0.0100   -0.0005\n",
      "   440        1.0864             nan     0.0100   -0.0005\n",
      "   460        1.0833             nan     0.0100   -0.0004\n",
      "   480        1.0802             nan     0.0100   -0.0007\n",
      "   500        1.0774             nan     0.0100   -0.0009\n",
      "   520        1.0744             nan     0.0100   -0.0006\n",
      "   540        1.0716             nan     0.0100   -0.0006\n",
      "   560        1.0690             nan     0.0100   -0.0005\n",
      "   580        1.0663             nan     0.0100   -0.0005\n",
      "   600        1.0638             nan     0.0100   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0080\n",
      "     2        1.3803             nan     0.0100    0.0065\n",
      "     3        1.3749             nan     0.0100    0.0083\n",
      "     4        1.3685             nan     0.0100    0.0074\n",
      "     5        1.3626             nan     0.0100    0.0067\n",
      "     6        1.3570             nan     0.0100    0.0071\n",
      "     7        1.3509             nan     0.0100    0.0063\n",
      "     8        1.3455             nan     0.0100    0.0062\n",
      "     9        1.3400             nan     0.0100    0.0064\n",
      "    10        1.3348             nan     0.0100    0.0072\n",
      "    20        1.2891             nan     0.0100    0.0052\n",
      "    40        1.2226             nan     0.0100    0.0025\n",
      "    60        1.1757             nan     0.0100    0.0019\n",
      "    80        1.1411             nan     0.0100    0.0010\n",
      "   100        1.1131             nan     0.0100    0.0000\n",
      "   120        1.0898             nan     0.0100   -0.0001\n",
      "   140        1.0699             nan     0.0100   -0.0008\n",
      "   160        1.0516             nan     0.0100   -0.0000\n",
      "   180        1.0357             nan     0.0100   -0.0006\n",
      "   200        1.0211             nan     0.0100   -0.0006\n",
      "   220        1.0071             nan     0.0100   -0.0005\n",
      "   240        0.9939             nan     0.0100   -0.0006\n",
      "   260        0.9819             nan     0.0100   -0.0008\n",
      "   280        0.9708             nan     0.0100   -0.0008\n",
      "   300        0.9600             nan     0.0100   -0.0011\n",
      "   320        0.9490             nan     0.0100   -0.0005\n",
      "   340        0.9389             nan     0.0100   -0.0005\n",
      "   360        0.9288             nan     0.0100   -0.0011\n",
      "   380        0.9191             nan     0.0100   -0.0008\n",
      "   400        0.9099             nan     0.0100   -0.0010\n",
      "   420        0.9005             nan     0.0100   -0.0011\n",
      "   440        0.8908             nan     0.0100   -0.0012\n",
      "   460        0.8819             nan     0.0100   -0.0008\n",
      "   480        0.8733             nan     0.0100   -0.0013\n",
      "   500        0.8651             nan     0.0100   -0.0011\n",
      "   520        0.8577             nan     0.0100   -0.0009\n",
      "   540        0.8499             nan     0.0100   -0.0010\n",
      "   560        0.8413             nan     0.0100   -0.0011\n",
      "   580        0.8336             nan     0.0100   -0.0011\n",
      "   600        0.8258             nan     0.0100   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0087\n",
      "     2        1.3788             nan     0.0100    0.0083\n",
      "     3        1.3716             nan     0.0100    0.0066\n",
      "     4        1.3653             nan     0.0100    0.0070\n",
      "     5        1.3587             nan     0.0100    0.0066\n",
      "     6        1.3519             nan     0.0100    0.0065\n",
      "     7        1.3456             nan     0.0100    0.0074\n",
      "     8        1.3393             nan     0.0100    0.0067\n",
      "     9        1.3335             nan     0.0100    0.0065\n",
      "    10        1.3279             nan     0.0100    0.0064\n",
      "    20        1.2753             nan     0.0100    0.0048\n",
      "    40        1.1970             nan     0.0100    0.0019\n",
      "    60        1.1407             nan     0.0100    0.0021\n",
      "    80        1.0960             nan     0.0100    0.0012\n",
      "   100        1.0575             nan     0.0100    0.0001\n",
      "   120        1.0254             nan     0.0100   -0.0004\n",
      "   140        0.9989             nan     0.0100   -0.0002\n",
      "   160        0.9743             nan     0.0100   -0.0011\n",
      "   180        0.9521             nan     0.0100   -0.0015\n",
      "   200        0.9316             nan     0.0100   -0.0005\n",
      "   220        0.9123             nan     0.0100   -0.0011\n",
      "   240        0.8944             nan     0.0100   -0.0007\n",
      "   260        0.8762             nan     0.0100   -0.0008\n",
      "   280        0.8594             nan     0.0100   -0.0012\n",
      "   300        0.8432             nan     0.0100   -0.0010\n",
      "   320        0.8284             nan     0.0100   -0.0013\n",
      "   340        0.8145             nan     0.0100   -0.0009\n",
      "   360        0.8002             nan     0.0100   -0.0007\n",
      "   380        0.7864             nan     0.0100   -0.0009\n",
      "   400        0.7722             nan     0.0100   -0.0013\n",
      "   420        0.7600             nan     0.0100   -0.0011\n",
      "   440        0.7478             nan     0.0100   -0.0010\n",
      "   460        0.7355             nan     0.0100   -0.0013\n",
      "   480        0.7241             nan     0.0100   -0.0013\n",
      "   500        0.7129             nan     0.0100   -0.0012\n",
      "   520        0.7015             nan     0.0100   -0.0011\n",
      "   540        0.6904             nan     0.0100   -0.0013\n",
      "   560        0.6801             nan     0.0100   -0.0011\n",
      "   580        0.6699             nan     0.0100   -0.0011\n",
      "   600        0.6599             nan     0.0100   -0.0013\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0682\n",
      "     2        1.3409             nan     0.1000    0.0375\n",
      "     3        1.3105             nan     0.1000    0.0345\n",
      "     4        1.2808             nan     0.1000    0.0222\n",
      "     5        1.2595             nan     0.1000    0.0198\n",
      "     6        1.2405             nan     0.1000    0.0141\n",
      "     7        1.2281             nan     0.1000    0.0058\n",
      "     8        1.2183             nan     0.1000    0.0124\n",
      "     9        1.2060             nan     0.1000    0.0083\n",
      "    10        1.1968             nan     0.1000    0.0076\n",
      "    20        1.1480             nan     0.1000   -0.0055\n",
      "    40        1.0966             nan     0.1000   -0.0037\n",
      "    60        1.0653             nan     0.1000   -0.0046\n",
      "    80        1.0431             nan     0.1000   -0.0065\n",
      "   100        1.0231             nan     0.1000   -0.0102\n",
      "   120        1.0078             nan     0.1000   -0.0088\n",
      "   140        0.9963             nan     0.1000   -0.0050\n",
      "   160        0.9854             nan     0.1000   -0.0085\n",
      "   180        0.9770             nan     0.1000   -0.0074\n",
      "   200        0.9649             nan     0.1000   -0.0103\n",
      "   220        0.9571             nan     0.1000   -0.0068\n",
      "   240        0.9511             nan     0.1000   -0.0079\n",
      "   260        0.9456             nan     0.1000   -0.0073\n",
      "   280        0.9361             nan     0.1000   -0.0064\n",
      "   300        0.9287             nan     0.1000   -0.0094\n",
      "   320        0.9215             nan     0.1000   -0.0074\n",
      "   340        0.9157             nan     0.1000   -0.0092\n",
      "   360        0.9095             nan     0.1000   -0.0040\n",
      "   380        0.9042             nan     0.1000   -0.0075\n",
      "   400        0.8990             nan     0.1000   -0.0063\n",
      "   420        0.8930             nan     0.1000   -0.0094\n",
      "   440        0.8893             nan     0.1000   -0.0034\n",
      "   460        0.8852             nan     0.1000   -0.0102\n",
      "   480        0.8809             nan     0.1000   -0.0083\n",
      "   500        0.8764             nan     0.1000   -0.0087\n",
      "   520        0.8737             nan     0.1000   -0.0054\n",
      "   540        0.8701             nan     0.1000   -0.0049\n",
      "   560        0.8660             nan     0.1000   -0.0055\n",
      "   580        0.8631             nan     0.1000   -0.0054\n",
      "   600        0.8593             nan     0.1000   -0.0100\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0659\n",
      "     2        1.3259             nan     0.1000    0.0513\n",
      "     3        1.2867             nan     0.1000    0.0250\n",
      "     4        1.2554             nan     0.1000    0.0289\n",
      "     5        1.2266             nan     0.1000    0.0214\n",
      "     6        1.2012             nan     0.1000    0.0168\n",
      "     7        1.1803             nan     0.1000    0.0111\n",
      "     8        1.1606             nan     0.1000    0.0023\n",
      "     9        1.1448             nan     0.1000    0.0040\n",
      "    10        1.1331             nan     0.1000    0.0083\n",
      "    20        1.0333             nan     0.1000   -0.0014\n",
      "    40        0.9225             nan     0.1000   -0.0113\n",
      "    60        0.8484             nan     0.1000   -0.0101\n",
      "    80        0.7806             nan     0.1000   -0.0150\n",
      "   100        0.7188             nan     0.1000   -0.0121\n",
      "   120        0.6680             nan     0.1000   -0.0096\n",
      "   140        0.6190             nan     0.1000   -0.0093\n",
      "   160        0.5813             nan     0.1000   -0.0074\n",
      "   180        0.5425             nan     0.1000   -0.0082\n",
      "   200        0.5091             nan     0.1000   -0.0062\n",
      "   220        0.4793             nan     0.1000   -0.0066\n",
      "   240        0.4541             nan     0.1000   -0.0081\n",
      "   260        0.4302             nan     0.1000   -0.0060\n",
      "   280        0.4091             nan     0.1000   -0.0102\n",
      "   300        0.3858             nan     0.1000   -0.0073\n",
      "   320        0.3625             nan     0.1000   -0.0097\n",
      "   340        0.3433             nan     0.1000   -0.0044\n",
      "   360        0.3236             nan     0.1000   -0.0062\n",
      "   380        0.3079             nan     0.1000   -0.0046\n",
      "   400        0.2940             nan     0.1000   -0.0064\n",
      "   420        0.2783             nan     0.1000   -0.0060\n",
      "   440        0.2647             nan     0.1000   -0.0031\n",
      "   460        0.2507             nan     0.1000   -0.0048\n",
      "   480        0.2402             nan     0.1000   -0.0057\n",
      "   500        0.2281             nan     0.1000   -0.0046\n",
      "   520        0.2169             nan     0.1000   -0.0034\n",
      "   540        0.2072             nan     0.1000   -0.0033\n",
      "   560        0.1980             nan     0.1000   -0.0026\n",
      "   580        0.1890             nan     0.1000   -0.0022\n",
      "   600        0.1810             nan     0.1000   -0.0032\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0795\n",
      "     2        1.3230             nan     0.1000    0.0483\n",
      "     3        1.2721             nan     0.1000    0.0354\n",
      "     4        1.2267             nan     0.1000    0.0246\n",
      "     5        1.1931             nan     0.1000    0.0231\n",
      "     6        1.1630             nan     0.1000    0.0194\n",
      "     7        1.1355             nan     0.1000    0.0040\n",
      "     8        1.1144             nan     0.1000    0.0063\n",
      "     9        1.0942             nan     0.1000    0.0053\n",
      "    10        1.0739             nan     0.1000    0.0017\n",
      "    20        0.9462             nan     0.1000   -0.0104\n",
      "    40        0.7890             nan     0.1000   -0.0094\n",
      "    60        0.6783             nan     0.1000   -0.0082\n",
      "    80        0.5934             nan     0.1000   -0.0078\n",
      "   100        0.5246             nan     0.1000   -0.0146\n",
      "   120        0.4643             nan     0.1000   -0.0138\n",
      "   140        0.4101             nan     0.1000   -0.0117\n",
      "   160        0.3625             nan     0.1000   -0.0093\n",
      "   180        0.3270             nan     0.1000   -0.0068\n",
      "   200        0.2941             nan     0.1000   -0.0063\n",
      "   220        0.2647             nan     0.1000   -0.0034\n",
      "   240        0.2383             nan     0.1000   -0.0068\n",
      "   260        0.2137             nan     0.1000   -0.0062\n",
      "   280        0.1929             nan     0.1000   -0.0060\n",
      "   300        0.1750             nan     0.1000   -0.0040\n",
      "   320        0.1597             nan     0.1000   -0.0045\n",
      "   340        0.1448             nan     0.1000   -0.0029\n",
      "   360        0.1325             nan     0.1000   -0.0031\n",
      "   380        0.1202             nan     0.1000   -0.0027\n",
      "   400        0.1099             nan     0.1000   -0.0022\n",
      "   420        0.0999             nan     0.1000   -0.0020\n",
      "   440        0.0915             nan     0.1000   -0.0017\n",
      "   460        0.0841             nan     0.1000   -0.0016\n",
      "   480        0.0755             nan     0.1000   -0.0011\n",
      "   500        0.0686             nan     0.1000   -0.0016\n",
      "   520        0.0622             nan     0.1000   -0.0013\n",
      "   540        0.0567             nan     0.1000   -0.0007\n",
      "   560        0.0514             nan     0.1000   -0.0010\n",
      "   580        0.0470             nan     0.1000   -0.0011\n",
      "   600        0.0429             nan     0.1000   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0007\n",
      "     2        1.3858             nan     0.0010    0.0007\n",
      "     3        1.3853             nan     0.0010    0.0007\n",
      "     4        1.3848             nan     0.0010    0.0007\n",
      "     5        1.3843             nan     0.0010    0.0007\n",
      "     6        1.3839             nan     0.0010    0.0007\n",
      "     7        1.3834             nan     0.0010    0.0007\n",
      "     8        1.3829             nan     0.0010    0.0007\n",
      "     9        1.3824             nan     0.0010    0.0007\n",
      "    10        1.3819             nan     0.0010    0.0007\n",
      "    20        1.3774             nan     0.0010    0.0007\n",
      "    40        1.3684             nan     0.0010    0.0007\n",
      "    60        1.3598             nan     0.0010    0.0005\n",
      "    80        1.3514             nan     0.0010    0.0005\n",
      "   100        1.3438             nan     0.0010    0.0005\n",
      "   120        1.3363             nan     0.0010    0.0006\n",
      "   140        1.3295             nan     0.0010    0.0004\n",
      "   160        1.3226             nan     0.0010    0.0005\n",
      "   180        1.3162             nan     0.0010    0.0005\n",
      "   200        1.3101             nan     0.0010    0.0004\n",
      "   220        1.3043             nan     0.0010    0.0004\n",
      "   240        1.2988             nan     0.0010    0.0003\n",
      "   260        1.2934             nan     0.0010    0.0003\n",
      "   280        1.2884             nan     0.0010    0.0004\n",
      "   300        1.2836             nan     0.0010    0.0004\n",
      "   320        1.2788             nan     0.0010    0.0003\n",
      "   340        1.2745             nan     0.0010    0.0003\n",
      "   360        1.2701             nan     0.0010    0.0003\n",
      "   380        1.2659             nan     0.0010    0.0003\n",
      "   400        1.2618             nan     0.0010    0.0003\n",
      "   420        1.2579             nan     0.0010    0.0003\n",
      "   440        1.2541             nan     0.0010    0.0003\n",
      "   460        1.2506             nan     0.0010    0.0002\n",
      "   480        1.2471             nan     0.0010    0.0002\n",
      "   500        1.2439             nan     0.0010    0.0002\n",
      "   520        1.2408             nan     0.0010    0.0002\n",
      "   540        1.2377             nan     0.0010    0.0002\n",
      "   560        1.2348             nan     0.0010    0.0002\n",
      "   580        1.2319             nan     0.0010    0.0001\n",
      "   600        1.2293             nan     0.0010    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0008\n",
      "     2        1.3856             nan     0.0010    0.0007\n",
      "     3        1.3850             nan     0.0010    0.0009\n",
      "     4        1.3844             nan     0.0010    0.0008\n",
      "     5        1.3838             nan     0.0010    0.0008\n",
      "     6        1.3832             nan     0.0010    0.0008\n",
      "     7        1.3826             nan     0.0010    0.0008\n",
      "     8        1.3820             nan     0.0010    0.0008\n",
      "     9        1.3813             nan     0.0010    0.0008\n",
      "    10        1.3807             nan     0.0010    0.0008\n",
      "    20        1.3746             nan     0.0010    0.0007\n",
      "    40        1.3631             nan     0.0010    0.0008\n",
      "    60        1.3521             nan     0.0010    0.0007\n",
      "    80        1.3414             nan     0.0010    0.0007\n",
      "   100        1.3312             nan     0.0010    0.0005\n",
      "   120        1.3217             nan     0.0010    0.0006\n",
      "   140        1.3128             nan     0.0010    0.0006\n",
      "   160        1.3040             nan     0.0010    0.0005\n",
      "   180        1.2955             nan     0.0010    0.0005\n",
      "   200        1.2872             nan     0.0010    0.0005\n",
      "   220        1.2794             nan     0.0010    0.0004\n",
      "   240        1.2721             nan     0.0010    0.0004\n",
      "   260        1.2648             nan     0.0010    0.0004\n",
      "   280        1.2579             nan     0.0010    0.0004\n",
      "   300        1.2512             nan     0.0010    0.0004\n",
      "   320        1.2448             nan     0.0010    0.0004\n",
      "   340        1.2386             nan     0.0010    0.0003\n",
      "   360        1.2326             nan     0.0010    0.0003\n",
      "   380        1.2268             nan     0.0010    0.0003\n",
      "   400        1.2213             nan     0.0010    0.0003\n",
      "   420        1.2160             nan     0.0010    0.0003\n",
      "   440        1.2108             nan     0.0010    0.0003\n",
      "   460        1.2059             nan     0.0010    0.0003\n",
      "   480        1.2009             nan     0.0010    0.0002\n",
      "   500        1.1961             nan     0.0010    0.0003\n",
      "   520        1.1916             nan     0.0010    0.0002\n",
      "   540        1.1871             nan     0.0010    0.0001\n",
      "   560        1.1828             nan     0.0010    0.0001\n",
      "   580        1.1786             nan     0.0010    0.0002\n",
      "   600        1.1746             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0009\n",
      "     2        1.3856             nan     0.0010    0.0008\n",
      "     3        1.3849             nan     0.0010    0.0009\n",
      "     4        1.3841             nan     0.0010    0.0008\n",
      "     5        1.3834             nan     0.0010    0.0007\n",
      "     6        1.3828             nan     0.0010    0.0009\n",
      "     7        1.3820             nan     0.0010    0.0008\n",
      "     8        1.3814             nan     0.0010    0.0008\n",
      "     9        1.3807             nan     0.0010    0.0008\n",
      "    10        1.3800             nan     0.0010    0.0006\n",
      "    20        1.3728             nan     0.0010    0.0008\n",
      "    40        1.3595             nan     0.0010    0.0007\n",
      "    60        1.3465             nan     0.0010    0.0007\n",
      "    80        1.3343             nan     0.0010    0.0007\n",
      "   100        1.3227             nan     0.0010    0.0007\n",
      "   120        1.3116             nan     0.0010    0.0006\n",
      "   140        1.3008             nan     0.0010    0.0006\n",
      "   160        1.2906             nan     0.0010    0.0005\n",
      "   180        1.2810             nan     0.0010    0.0004\n",
      "   200        1.2715             nan     0.0010    0.0006\n",
      "   220        1.2622             nan     0.0010    0.0005\n",
      "   240        1.2533             nan     0.0010    0.0004\n",
      "   260        1.2449             nan     0.0010    0.0004\n",
      "   280        1.2367             nan     0.0010    0.0004\n",
      "   300        1.2286             nan     0.0010    0.0004\n",
      "   320        1.2209             nan     0.0010    0.0003\n",
      "   340        1.2137             nan     0.0010    0.0003\n",
      "   360        1.2063             nan     0.0010    0.0002\n",
      "   380        1.1995             nan     0.0010    0.0002\n",
      "   400        1.1927             nan     0.0010    0.0003\n",
      "   420        1.1861             nan     0.0010    0.0002\n",
      "   440        1.1798             nan     0.0010    0.0001\n",
      "   460        1.1738             nan     0.0010    0.0002\n",
      "   480        1.1679             nan     0.0010    0.0002\n",
      "   500        1.1620             nan     0.0010    0.0002\n",
      "   520        1.1564             nan     0.0010    0.0002\n",
      "   540        1.1510             nan     0.0010    0.0002\n",
      "   560        1.1457             nan     0.0010    0.0001\n",
      "   580        1.1407             nan     0.0010    0.0002\n",
      "   600        1.1357             nan     0.0010    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0065\n",
      "     2        1.3814             nan     0.0100    0.0069\n",
      "     3        1.3764             nan     0.0100    0.0069\n",
      "     4        1.3715             nan     0.0100    0.0066\n",
      "     5        1.3668             nan     0.0100    0.0061\n",
      "     6        1.3626             nan     0.0100    0.0059\n",
      "     7        1.3580             nan     0.0100    0.0063\n",
      "     8        1.3537             nan     0.0100    0.0057\n",
      "     9        1.3498             nan     0.0100    0.0054\n",
      "    10        1.3458             nan     0.0100    0.0053\n",
      "    20        1.3107             nan     0.0100    0.0045\n",
      "    40        1.2624             nan     0.0100    0.0021\n",
      "    60        1.2298             nan     0.0100    0.0017\n",
      "    80        1.2059             nan     0.0100    0.0010\n",
      "   100        1.1872             nan     0.0100    0.0006\n",
      "   120        1.1730             nan     0.0100    0.0001\n",
      "   140        1.1617             nan     0.0100    0.0001\n",
      "   160        1.1522             nan     0.0100    0.0000\n",
      "   180        1.1434             nan     0.0100   -0.0000\n",
      "   200        1.1364             nan     0.0100   -0.0002\n",
      "   220        1.1296             nan     0.0100   -0.0004\n",
      "   240        1.1240             nan     0.0100   -0.0002\n",
      "   260        1.1183             nan     0.0100   -0.0004\n",
      "   280        1.1130             nan     0.0100   -0.0006\n",
      "   300        1.1082             nan     0.0100   -0.0003\n",
      "   320        1.1039             nan     0.0100   -0.0006\n",
      "   340        1.0996             nan     0.0100   -0.0004\n",
      "   360        1.0956             nan     0.0100   -0.0006\n",
      "   380        1.0916             nan     0.0100   -0.0002\n",
      "   400        1.0880             nan     0.0100   -0.0004\n",
      "   420        1.0840             nan     0.0100   -0.0007\n",
      "   440        1.0805             nan     0.0100   -0.0006\n",
      "   460        1.0769             nan     0.0100   -0.0005\n",
      "   480        1.0737             nan     0.0100   -0.0006\n",
      "   500        1.0706             nan     0.0100   -0.0005\n",
      "   520        1.0677             nan     0.0100   -0.0004\n",
      "   540        1.0645             nan     0.0100   -0.0006\n",
      "   560        1.0617             nan     0.0100   -0.0005\n",
      "   580        1.0593             nan     0.0100   -0.0006\n",
      "   600        1.0563             nan     0.0100   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0083\n",
      "     2        1.3801             nan     0.0100    0.0068\n",
      "     3        1.3738             nan     0.0100    0.0077\n",
      "     4        1.3681             nan     0.0100    0.0075\n",
      "     5        1.3627             nan     0.0100    0.0074\n",
      "     6        1.3572             nan     0.0100    0.0071\n",
      "     7        1.3514             nan     0.0100    0.0072\n",
      "     8        1.3460             nan     0.0100    0.0077\n",
      "     9        1.3405             nan     0.0100    0.0057\n",
      "    10        1.3358             nan     0.0100    0.0069\n",
      "    20        1.2912             nan     0.0100    0.0039\n",
      "    40        1.2240             nan     0.0100    0.0031\n",
      "    60        1.1766             nan     0.0100    0.0020\n",
      "    80        1.1411             nan     0.0100    0.0014\n",
      "   100        1.1128             nan     0.0100   -0.0003\n",
      "   120        1.0891             nan     0.0100    0.0002\n",
      "   140        1.0686             nan     0.0100   -0.0002\n",
      "   160        1.0506             nan     0.0100    0.0003\n",
      "   180        1.0338             nan     0.0100   -0.0003\n",
      "   200        1.0192             nan     0.0100   -0.0004\n",
      "   220        1.0045             nan     0.0100   -0.0011\n",
      "   240        0.9920             nan     0.0100   -0.0005\n",
      "   260        0.9801             nan     0.0100   -0.0005\n",
      "   280        0.9690             nan     0.0100   -0.0006\n",
      "   300        0.9576             nan     0.0100   -0.0015\n",
      "   320        0.9470             nan     0.0100   -0.0009\n",
      "   340        0.9371             nan     0.0100   -0.0010\n",
      "   360        0.9274             nan     0.0100   -0.0001\n",
      "   380        0.9174             nan     0.0100   -0.0009\n",
      "   400        0.9082             nan     0.0100   -0.0009\n",
      "   420        0.8988             nan     0.0100   -0.0004\n",
      "   440        0.8905             nan     0.0100   -0.0008\n",
      "   460        0.8816             nan     0.0100   -0.0012\n",
      "   480        0.8734             nan     0.0100   -0.0009\n",
      "   500        0.8656             nan     0.0100   -0.0010\n",
      "   520        0.8579             nan     0.0100   -0.0012\n",
      "   540        0.8499             nan     0.0100   -0.0011\n",
      "   560        0.8428             nan     0.0100   -0.0008\n",
      "   580        0.8346             nan     0.0100   -0.0014\n",
      "   600        0.8273             nan     0.0100   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0095\n",
      "     2        1.3797             nan     0.0100    0.0094\n",
      "     3        1.3724             nan     0.0100    0.0073\n",
      "     4        1.3654             nan     0.0100    0.0079\n",
      "     5        1.3588             nan     0.0100    0.0078\n",
      "     6        1.3518             nan     0.0100    0.0065\n",
      "     7        1.3455             nan     0.0100    0.0068\n",
      "     8        1.3394             nan     0.0100    0.0064\n",
      "     9        1.3335             nan     0.0100    0.0054\n",
      "    10        1.3278             nan     0.0100    0.0049\n",
      "    20        1.2759             nan     0.0100    0.0048\n",
      "    40        1.1958             nan     0.0100    0.0037\n",
      "    60        1.1366             nan     0.0100    0.0010\n",
      "    80        1.0918             nan     0.0100    0.0010\n",
      "   100        1.0550             nan     0.0100    0.0007\n",
      "   120        1.0236             nan     0.0100   -0.0003\n",
      "   140        0.9967             nan     0.0100   -0.0006\n",
      "   160        0.9726             nan     0.0100   -0.0013\n",
      "   180        0.9503             nan     0.0100   -0.0005\n",
      "   200        0.9303             nan     0.0100   -0.0016\n",
      "   220        0.9107             nan     0.0100   -0.0005\n",
      "   240        0.8918             nan     0.0100   -0.0004\n",
      "   260        0.8751             nan     0.0100   -0.0009\n",
      "   280        0.8588             nan     0.0100   -0.0011\n",
      "   300        0.8434             nan     0.0100   -0.0006\n",
      "   320        0.8281             nan     0.0100   -0.0006\n",
      "   340        0.8136             nan     0.0100   -0.0011\n",
      "   360        0.7999             nan     0.0100   -0.0009\n",
      "   380        0.7863             nan     0.0100   -0.0013\n",
      "   400        0.7737             nan     0.0100   -0.0019\n",
      "   420        0.7611             nan     0.0100   -0.0015\n",
      "   440        0.7486             nan     0.0100   -0.0009\n",
      "   460        0.7368             nan     0.0100   -0.0010\n",
      "   480        0.7247             nan     0.0100   -0.0006\n",
      "   500        0.7126             nan     0.0100   -0.0018\n",
      "   520        0.7025             nan     0.0100   -0.0012\n",
      "   540        0.6917             nan     0.0100   -0.0012\n",
      "   560        0.6811             nan     0.0100   -0.0013\n",
      "   580        0.6711             nan     0.0100   -0.0013\n",
      "   600        0.6614             nan     0.0100   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0628\n",
      "     2        1.3380             nan     0.1000    0.0465\n",
      "     3        1.3035             nan     0.1000    0.0332\n",
      "     4        1.2770             nan     0.1000    0.0246\n",
      "     5        1.2557             nan     0.1000    0.0187\n",
      "     6        1.2407             nan     0.1000    0.0076\n",
      "     7        1.2295             nan     0.1000    0.0133\n",
      "     8        1.2178             nan     0.1000    0.0144\n",
      "     9        1.2076             nan     0.1000    0.0081\n",
      "    10        1.1980             nan     0.1000    0.0063\n",
      "    20        1.1418             nan     0.1000   -0.0040\n",
      "    40        1.0935             nan     0.1000   -0.0024\n",
      "    60        1.0602             nan     0.1000   -0.0101\n",
      "    80        1.0355             nan     0.1000   -0.0041\n",
      "   100        1.0176             nan     0.1000   -0.0088\n",
      "   120        1.0013             nan     0.1000   -0.0109\n",
      "   140        0.9888             nan     0.1000   -0.0047\n",
      "   160        0.9789             nan     0.1000   -0.0083\n",
      "   180        0.9681             nan     0.1000   -0.0087\n",
      "   200        0.9584             nan     0.1000   -0.0052\n",
      "   220        0.9497             nan     0.1000   -0.0069\n",
      "   240        0.9432             nan     0.1000   -0.0083\n",
      "   260        0.9376             nan     0.1000   -0.0123\n",
      "   280        0.9300             nan     0.1000   -0.0087\n",
      "   300        0.9235             nan     0.1000   -0.0077\n",
      "   320        0.9170             nan     0.1000   -0.0066\n",
      "   340        0.9126             nan     0.1000   -0.0081\n",
      "   360        0.9067             nan     0.1000   -0.0051\n",
      "   380        0.9012             nan     0.1000   -0.0096\n",
      "   400        0.8978             nan     0.1000   -0.0047\n",
      "   420        0.8909             nan     0.1000   -0.0083\n",
      "   440        0.8877             nan     0.1000   -0.0067\n",
      "   460        0.8839             nan     0.1000   -0.0078\n",
      "   480        0.8785             nan     0.1000   -0.0057\n",
      "   500        0.8763             nan     0.1000   -0.0051\n",
      "   520        0.8728             nan     0.1000   -0.0062\n",
      "   540        0.8697             nan     0.1000   -0.0088\n",
      "   560        0.8673             nan     0.1000   -0.0063\n",
      "   580        0.8629             nan     0.1000   -0.0074\n",
      "   600        0.8598             nan     0.1000   -0.0073\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0716\n",
      "     2        1.3284             nan     0.1000    0.0589\n",
      "     3        1.2816             nan     0.1000    0.0364\n",
      "     4        1.2450             nan     0.1000    0.0214\n",
      "     5        1.2179             nan     0.1000    0.0239\n",
      "     6        1.1920             nan     0.1000    0.0191\n",
      "     7        1.1691             nan     0.1000    0.0149\n",
      "     8        1.1494             nan     0.1000    0.0050\n",
      "     9        1.1334             nan     0.1000    0.0077\n",
      "    10        1.1199             nan     0.1000    0.0077\n",
      "    20        1.0276             nan     0.1000   -0.0047\n",
      "    40        0.9135             nan     0.1000   -0.0076\n",
      "    60        0.8353             nan     0.1000   -0.0114\n",
      "    80        0.7655             nan     0.1000   -0.0104\n",
      "   100        0.7058             nan     0.1000   -0.0106\n",
      "   120        0.6602             nan     0.1000   -0.0085\n",
      "   140        0.6207             nan     0.1000   -0.0107\n",
      "   160        0.5774             nan     0.1000   -0.0049\n",
      "   180        0.5451             nan     0.1000   -0.0073\n",
      "   200        0.5152             nan     0.1000   -0.0102\n",
      "   220        0.4848             nan     0.1000   -0.0091\n",
      "   240        0.4550             nan     0.1000   -0.0092\n",
      "   260        0.4303             nan     0.1000   -0.0049\n",
      "   280        0.4056             nan     0.1000   -0.0061\n",
      "   300        0.3850             nan     0.1000   -0.0085\n",
      "   320        0.3628             nan     0.1000   -0.0093\n",
      "   340        0.3434             nan     0.1000   -0.0038\n",
      "   360        0.3240             nan     0.1000   -0.0068\n",
      "   380        0.3083             nan     0.1000   -0.0042\n",
      "   400        0.2948             nan     0.1000   -0.0033\n",
      "   420        0.2799             nan     0.1000   -0.0055\n",
      "   440        0.2644             nan     0.1000   -0.0047\n",
      "   460        0.2524             nan     0.1000   -0.0051\n",
      "   480        0.2403             nan     0.1000   -0.0020\n",
      "   500        0.2272             nan     0.1000   -0.0033\n",
      "   520        0.2155             nan     0.1000   -0.0043\n",
      "   540        0.2038             nan     0.1000   -0.0030\n",
      "   560        0.1943             nan     0.1000   -0.0038\n",
      "   580        0.1855             nan     0.1000   -0.0015\n",
      "   600        0.1756             nan     0.1000   -0.0030\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0574\n",
      "     2        1.3198             nan     0.1000    0.0616\n",
      "     3        1.2661             nan     0.1000    0.0319\n",
      "     4        1.2297             nan     0.1000    0.0316\n",
      "     5        1.1921             nan     0.1000    0.0170\n",
      "     6        1.1646             nan     0.1000    0.0066\n",
      "     7        1.1399             nan     0.1000    0.0106\n",
      "     8        1.1152             nan     0.1000    0.0030\n",
      "     9        1.0960             nan     0.1000    0.0102\n",
      "    10        1.0758             nan     0.1000    0.0067\n",
      "    20        0.9445             nan     0.1000    0.0011\n",
      "    40        0.7930             nan     0.1000   -0.0178\n",
      "    60        0.6737             nan     0.1000   -0.0171\n",
      "    80        0.5865             nan     0.1000   -0.0095\n",
      "   100        0.5134             nan     0.1000   -0.0134\n",
      "   120        0.4561             nan     0.1000   -0.0095\n",
      "   140        0.4051             nan     0.1000   -0.0083\n",
      "   160        0.3598             nan     0.1000   -0.0069\n",
      "   180        0.3215             nan     0.1000   -0.0081\n",
      "   200        0.2873             nan     0.1000   -0.0057\n",
      "   220        0.2578             nan     0.1000   -0.0081\n",
      "   240        0.2328             nan     0.1000   -0.0036\n",
      "   260        0.2098             nan     0.1000   -0.0038\n",
      "   280        0.1891             nan     0.1000   -0.0035\n",
      "   300        0.1691             nan     0.1000   -0.0055\n",
      "   320        0.1526             nan     0.1000   -0.0034\n",
      "   340        0.1389             nan     0.1000   -0.0031\n",
      "   360        0.1253             nan     0.1000   -0.0020\n",
      "   380        0.1144             nan     0.1000   -0.0028\n",
      "   400        0.1042             nan     0.1000   -0.0026\n",
      "   420        0.0947             nan     0.1000   -0.0022\n",
      "   440        0.0859             nan     0.1000   -0.0020\n",
      "   460        0.0782             nan     0.1000   -0.0021\n",
      "   480        0.0713             nan     0.1000   -0.0019\n",
      "   500        0.0651             nan     0.1000   -0.0014\n",
      "   520        0.0586             nan     0.1000   -0.0016\n",
      "   540        0.0538             nan     0.1000   -0.0014\n",
      "   560        0.0491             nan     0.1000   -0.0012\n",
      "   580        0.0450             nan     0.1000   -0.0010\n",
      "   600        0.0413             nan     0.1000   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0006\n",
      "     2        1.3858             nan     0.0010    0.0007\n",
      "     3        1.3854             nan     0.0010    0.0007\n",
      "     4        1.3849             nan     0.0010    0.0007\n",
      "     5        1.3844             nan     0.0010    0.0007\n",
      "     6        1.3839             nan     0.0010    0.0007\n",
      "     7        1.3834             nan     0.0010    0.0006\n",
      "     8        1.3830             nan     0.0010    0.0007\n",
      "     9        1.3824             nan     0.0010    0.0007\n",
      "    10        1.3819             nan     0.0010    0.0007\n",
      "    20        1.3772             nan     0.0010    0.0007\n",
      "    40        1.3682             nan     0.0010    0.0006\n",
      "    60        1.3594             nan     0.0010    0.0006\n",
      "    80        1.3508             nan     0.0010    0.0005\n",
      "   100        1.3428             nan     0.0010    0.0005\n",
      "   120        1.3354             nan     0.0010    0.0005\n",
      "   140        1.3282             nan     0.0010    0.0005\n",
      "   160        1.3212             nan     0.0010    0.0005\n",
      "   180        1.3146             nan     0.0010    0.0005\n",
      "   200        1.3084             nan     0.0010    0.0004\n",
      "   220        1.3024             nan     0.0010    0.0004\n",
      "   240        1.2968             nan     0.0010    0.0004\n",
      "   260        1.2914             nan     0.0010    0.0003\n",
      "   280        1.2863             nan     0.0010    0.0003\n",
      "   300        1.2813             nan     0.0010    0.0003\n",
      "   320        1.2767             nan     0.0010    0.0003\n",
      "   340        1.2721             nan     0.0010    0.0003\n",
      "   360        1.2676             nan     0.0010    0.0003\n",
      "   380        1.2633             nan     0.0010    0.0003\n",
      "   400        1.2592             nan     0.0010    0.0003\n",
      "   420        1.2553             nan     0.0010    0.0002\n",
      "   440        1.2515             nan     0.0010    0.0002\n",
      "   460        1.2479             nan     0.0010    0.0003\n",
      "   480        1.2445             nan     0.0010    0.0003\n",
      "   500        1.2412             nan     0.0010    0.0002\n",
      "   520        1.2379             nan     0.0010    0.0002\n",
      "   540        1.2349             nan     0.0010    0.0001\n",
      "   560        1.2318             nan     0.0010    0.0002\n",
      "   580        1.2288             nan     0.0010    0.0002\n",
      "   600        1.2260             nan     0.0010    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0009\n",
      "     2        1.3857             nan     0.0010    0.0008\n",
      "     3        1.3851             nan     0.0010    0.0008\n",
      "     4        1.3845             nan     0.0010    0.0008\n",
      "     5        1.3838             nan     0.0010    0.0008\n",
      "     6        1.3832             nan     0.0010    0.0009\n",
      "     7        1.3825             nan     0.0010    0.0008\n",
      "     8        1.3819             nan     0.0010    0.0009\n",
      "     9        1.3812             nan     0.0010    0.0008\n",
      "    10        1.3806             nan     0.0010    0.0008\n",
      "    20        1.3745             nan     0.0010    0.0008\n",
      "    40        1.3626             nan     0.0010    0.0006\n",
      "    60        1.3516             nan     0.0010    0.0007\n",
      "    80        1.3407             nan     0.0010    0.0006\n",
      "   100        1.3306             nan     0.0010    0.0005\n",
      "   120        1.3209             nan     0.0010    0.0006\n",
      "   140        1.3114             nan     0.0010    0.0005\n",
      "   160        1.3024             nan     0.0010    0.0005\n",
      "   180        1.2937             nan     0.0010    0.0005\n",
      "   200        1.2854             nan     0.0010    0.0005\n",
      "   220        1.2774             nan     0.0010    0.0004\n",
      "   240        1.2698             nan     0.0010    0.0004\n",
      "   260        1.2625             nan     0.0010    0.0003\n",
      "   280        1.2554             nan     0.0010    0.0004\n",
      "   300        1.2487             nan     0.0010    0.0003\n",
      "   320        1.2422             nan     0.0010    0.0003\n",
      "   340        1.2359             nan     0.0010    0.0002\n",
      "   360        1.2298             nan     0.0010    0.0004\n",
      "   380        1.2240             nan     0.0010    0.0003\n",
      "   400        1.2183             nan     0.0010    0.0003\n",
      "   420        1.2128             nan     0.0010    0.0002\n",
      "   440        1.2077             nan     0.0010    0.0002\n",
      "   460        1.2026             nan     0.0010    0.0002\n",
      "   480        1.1977             nan     0.0010    0.0002\n",
      "   500        1.1927             nan     0.0010    0.0003\n",
      "   520        1.1880             nan     0.0010    0.0002\n",
      "   540        1.1835             nan     0.0010    0.0002\n",
      "   560        1.1791             nan     0.0010    0.0002\n",
      "   580        1.1749             nan     0.0010    0.0002\n",
      "   600        1.1708             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0008\n",
      "     2        1.3855             nan     0.0010    0.0009\n",
      "     3        1.3848             nan     0.0010    0.0008\n",
      "     4        1.3841             nan     0.0010    0.0008\n",
      "     5        1.3834             nan     0.0010    0.0008\n",
      "     6        1.3827             nan     0.0010    0.0008\n",
      "     7        1.3820             nan     0.0010    0.0009\n",
      "     8        1.3812             nan     0.0010    0.0008\n",
      "     9        1.3806             nan     0.0010    0.0008\n",
      "    10        1.3799             nan     0.0010    0.0009\n",
      "    20        1.3727             nan     0.0010    0.0008\n",
      "    40        1.3591             nan     0.0010    0.0008\n",
      "    60        1.3460             nan     0.0010    0.0007\n",
      "    80        1.3336             nan     0.0010    0.0007\n",
      "   100        1.3219             nan     0.0010    0.0006\n",
      "   120        1.3107             nan     0.0010    0.0006\n",
      "   140        1.2998             nan     0.0010    0.0006\n",
      "   160        1.2893             nan     0.0010    0.0005\n",
      "   180        1.2793             nan     0.0010    0.0005\n",
      "   200        1.2698             nan     0.0010    0.0005\n",
      "   220        1.2605             nan     0.0010    0.0005\n",
      "   240        1.2517             nan     0.0010    0.0004\n",
      "   260        1.2430             nan     0.0010    0.0004\n",
      "   280        1.2348             nan     0.0010    0.0004\n",
      "   300        1.2268             nan     0.0010    0.0004\n",
      "   320        1.2190             nan     0.0010    0.0004\n",
      "   340        1.2116             nan     0.0010    0.0004\n",
      "   360        1.2042             nan     0.0010    0.0003\n",
      "   380        1.1973             nan     0.0010    0.0002\n",
      "   400        1.1906             nan     0.0010    0.0002\n",
      "   420        1.1839             nan     0.0010    0.0003\n",
      "   440        1.1777             nan     0.0010    0.0003\n",
      "   460        1.1715             nan     0.0010    0.0002\n",
      "   480        1.1655             nan     0.0010    0.0002\n",
      "   500        1.1598             nan     0.0010    0.0003\n",
      "   520        1.1540             nan     0.0010    0.0003\n",
      "   540        1.1484             nan     0.0010    0.0002\n",
      "   560        1.1429             nan     0.0010    0.0002\n",
      "   580        1.1376             nan     0.0010    0.0002\n",
      "   600        1.1326             nan     0.0010    0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0074\n",
      "     2        1.3815             nan     0.0100    0.0064\n",
      "     3        1.3765             nan     0.0100    0.0064\n",
      "     4        1.3719             nan     0.0100    0.0066\n",
      "     5        1.3668             nan     0.0100    0.0066\n",
      "     6        1.3624             nan     0.0100    0.0062\n",
      "     7        1.3576             nan     0.0100    0.0051\n",
      "     8        1.3539             nan     0.0100    0.0061\n",
      "     9        1.3498             nan     0.0100    0.0058\n",
      "    10        1.3454             nan     0.0100    0.0059\n",
      "    20        1.3099             nan     0.0100    0.0039\n",
      "    40        1.2591             nan     0.0100    0.0020\n",
      "    60        1.2261             nan     0.0100    0.0019\n",
      "    80        1.2023             nan     0.0100    0.0013\n",
      "   100        1.1842             nan     0.0100    0.0007\n",
      "   120        1.1699             nan     0.0100   -0.0004\n",
      "   140        1.1586             nan     0.0100   -0.0002\n",
      "   160        1.1494             nan     0.0100    0.0002\n",
      "   180        1.1412             nan     0.0100   -0.0000\n",
      "   200        1.1339             nan     0.0100   -0.0002\n",
      "   220        1.1273             nan     0.0100   -0.0003\n",
      "   240        1.1216             nan     0.0100   -0.0002\n",
      "   260        1.1164             nan     0.0100   -0.0003\n",
      "   280        1.1111             nan     0.0100   -0.0002\n",
      "   300        1.1066             nan     0.0100   -0.0005\n",
      "   320        1.1018             nan     0.0100   -0.0003\n",
      "   340        1.0976             nan     0.0100   -0.0004\n",
      "   360        1.0936             nan     0.0100   -0.0005\n",
      "   380        1.0896             nan     0.0100   -0.0004\n",
      "   400        1.0857             nan     0.0100   -0.0003\n",
      "   420        1.0821             nan     0.0100   -0.0003\n",
      "   440        1.0786             nan     0.0100   -0.0004\n",
      "   460        1.0756             nan     0.0100   -0.0005\n",
      "   480        1.0722             nan     0.0100   -0.0006\n",
      "   500        1.0692             nan     0.0100   -0.0010\n",
      "   520        1.0664             nan     0.0100   -0.0007\n",
      "   540        1.0633             nan     0.0100   -0.0002\n",
      "   560        1.0605             nan     0.0100   -0.0007\n",
      "   580        1.0578             nan     0.0100   -0.0004\n",
      "   600        1.0553             nan     0.0100   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0084\n",
      "     2        1.3799             nan     0.0100    0.0075\n",
      "     3        1.3744             nan     0.0100    0.0064\n",
      "     4        1.3690             nan     0.0100    0.0078\n",
      "     5        1.3629             nan     0.0100    0.0065\n",
      "     6        1.3572             nan     0.0100    0.0073\n",
      "     7        1.3516             nan     0.0100    0.0065\n",
      "     8        1.3462             nan     0.0100    0.0064\n",
      "     9        1.3407             nan     0.0100    0.0066\n",
      "    10        1.3359             nan     0.0100    0.0061\n",
      "    20        1.2898             nan     0.0100    0.0041\n",
      "    40        1.2210             nan     0.0100    0.0032\n",
      "    60        1.1729             nan     0.0100    0.0025\n",
      "    80        1.1376             nan     0.0100    0.0005\n",
      "   100        1.1076             nan     0.0100    0.0006\n",
      "   120        1.0825             nan     0.0100   -0.0005\n",
      "   140        1.0622             nan     0.0100   -0.0007\n",
      "   160        1.0439             nan     0.0100   -0.0004\n",
      "   180        1.0276             nan     0.0100   -0.0002\n",
      "   200        1.0126             nan     0.0100   -0.0006\n",
      "   220        0.9979             nan     0.0100   -0.0008\n",
      "   240        0.9850             nan     0.0100   -0.0008\n",
      "   260        0.9725             nan     0.0100   -0.0004\n",
      "   280        0.9608             nan     0.0100   -0.0007\n",
      "   300        0.9494             nan     0.0100   -0.0013\n",
      "   320        0.9381             nan     0.0100   -0.0009\n",
      "   340        0.9267             nan     0.0100   -0.0005\n",
      "   360        0.9169             nan     0.0100   -0.0011\n",
      "   380        0.9070             nan     0.0100   -0.0011\n",
      "   400        0.8981             nan     0.0100   -0.0002\n",
      "   420        0.8883             nan     0.0100    0.0000\n",
      "   440        0.8794             nan     0.0100   -0.0011\n",
      "   460        0.8706             nan     0.0100   -0.0010\n",
      "   480        0.8623             nan     0.0100   -0.0008\n",
      "   500        0.8543             nan     0.0100   -0.0012\n",
      "   520        0.8460             nan     0.0100   -0.0008\n",
      "   540        0.8381             nan     0.0100   -0.0003\n",
      "   560        0.8310             nan     0.0100   -0.0010\n",
      "   580        0.8238             nan     0.0100   -0.0007\n",
      "   600        0.8164             nan     0.0100   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0081\n",
      "     2        1.3790             nan     0.0100    0.0073\n",
      "     3        1.3720             nan     0.0100    0.0086\n",
      "     4        1.3651             nan     0.0100    0.0066\n",
      "     5        1.3592             nan     0.0100    0.0082\n",
      "     6        1.3524             nan     0.0100    0.0079\n",
      "     7        1.3455             nan     0.0100    0.0066\n",
      "     8        1.3400             nan     0.0100    0.0052\n",
      "     9        1.3343             nan     0.0100    0.0076\n",
      "    10        1.3280             nan     0.0100    0.0080\n",
      "    20        1.2743             nan     0.0100    0.0048\n",
      "    40        1.1924             nan     0.0100    0.0038\n",
      "    60        1.1330             nan     0.0100    0.0018\n",
      "    80        1.0877             nan     0.0100    0.0001\n",
      "   100        1.0500             nan     0.0100    0.0007\n",
      "   120        1.0191             nan     0.0100    0.0001\n",
      "   140        0.9925             nan     0.0100   -0.0008\n",
      "   160        0.9676             nan     0.0100   -0.0002\n",
      "   180        0.9443             nan     0.0100   -0.0002\n",
      "   200        0.9227             nan     0.0100   -0.0003\n",
      "   220        0.9035             nan     0.0100   -0.0011\n",
      "   240        0.8861             nan     0.0100   -0.0011\n",
      "   260        0.8681             nan     0.0100   -0.0002\n",
      "   280        0.8518             nan     0.0100   -0.0013\n",
      "   300        0.8347             nan     0.0100   -0.0006\n",
      "   320        0.8196             nan     0.0100   -0.0009\n",
      "   340        0.8051             nan     0.0100   -0.0008\n",
      "   360        0.7906             nan     0.0100   -0.0007\n",
      "   380        0.7764             nan     0.0100   -0.0009\n",
      "   400        0.7630             nan     0.0100   -0.0012\n",
      "   420        0.7499             nan     0.0100   -0.0009\n",
      "   440        0.7379             nan     0.0100   -0.0012\n",
      "   460        0.7260             nan     0.0100   -0.0010\n",
      "   480        0.7140             nan     0.0100   -0.0013\n",
      "   500        0.7025             nan     0.0100   -0.0012\n",
      "   520        0.6909             nan     0.0100   -0.0012\n",
      "   540        0.6805             nan     0.0100   -0.0011\n",
      "   560        0.6702             nan     0.0100   -0.0012\n",
      "   580        0.6596             nan     0.0100   -0.0008\n",
      "   600        0.6496             nan     0.0100   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0578\n",
      "     2        1.3404             nan     0.1000    0.0446\n",
      "     3        1.3047             nan     0.1000    0.0405\n",
      "     4        1.2758             nan     0.1000    0.0250\n",
      "     5        1.2541             nan     0.1000    0.0250\n",
      "     6        1.2354             nan     0.1000    0.0170\n",
      "     7        1.2215             nan     0.1000    0.0126\n",
      "     8        1.2111             nan     0.1000    0.0047\n",
      "     9        1.2029             nan     0.1000    0.0082\n",
      "    10        1.1944             nan     0.1000   -0.0045\n",
      "    20        1.1382             nan     0.1000   -0.0003\n",
      "    40        1.0884             nan     0.1000   -0.0112\n",
      "    60        1.0572             nan     0.1000   -0.0068\n",
      "    80        1.0372             nan     0.1000   -0.0061\n",
      "   100        1.0197             nan     0.1000   -0.0041\n",
      "   120        1.0058             nan     0.1000   -0.0064\n",
      "   140        0.9922             nan     0.1000   -0.0073\n",
      "   160        0.9797             nan     0.1000   -0.0055\n",
      "   180        0.9685             nan     0.1000   -0.0078\n",
      "   200        0.9603             nan     0.1000   -0.0072\n",
      "   220        0.9500             nan     0.1000   -0.0087\n",
      "   240        0.9438             nan     0.1000   -0.0087\n",
      "   260        0.9363             nan     0.1000   -0.0041\n",
      "   280        0.9303             nan     0.1000   -0.0092\n",
      "   300        0.9239             nan     0.1000   -0.0090\n",
      "   320        0.9187             nan     0.1000   -0.0067\n",
      "   340        0.9127             nan     0.1000   -0.0087\n",
      "   360        0.9068             nan     0.1000   -0.0071\n",
      "   380        0.9019             nan     0.1000   -0.0080\n",
      "   400        0.8961             nan     0.1000   -0.0082\n",
      "   420        0.8925             nan     0.1000   -0.0068\n",
      "   440        0.8889             nan     0.1000   -0.0058\n",
      "   460        0.8852             nan     0.1000   -0.0058\n",
      "   480        0.8790             nan     0.1000   -0.0073\n",
      "   500        0.8748             nan     0.1000   -0.0061\n",
      "   520        0.8712             nan     0.1000   -0.0061\n",
      "   540        0.8674             nan     0.1000   -0.0064\n",
      "   560        0.8637             nan     0.1000   -0.0062\n",
      "   580        0.8601             nan     0.1000   -0.0056\n",
      "   600        0.8567             nan     0.1000   -0.0053\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0702\n",
      "     2        1.3232             nan     0.1000    0.0453\n",
      "     3        1.2818             nan     0.1000    0.0407\n",
      "     4        1.2439             nan     0.1000    0.0270\n",
      "     5        1.2131             nan     0.1000    0.0174\n",
      "     6        1.1897             nan     0.1000    0.0097\n",
      "     7        1.1681             nan     0.1000    0.0095\n",
      "     8        1.1496             nan     0.1000    0.0046\n",
      "     9        1.1339             nan     0.1000    0.0045\n",
      "    10        1.1210             nan     0.1000    0.0050\n",
      "    20        1.0238             nan     0.1000   -0.0052\n",
      "    40        0.9109             nan     0.1000   -0.0098\n",
      "    60        0.8264             nan     0.1000   -0.0142\n",
      "    80        0.7563             nan     0.1000   -0.0103\n",
      "   100        0.7014             nan     0.1000   -0.0118\n",
      "   120        0.6509             nan     0.1000   -0.0106\n",
      "   140        0.6098             nan     0.1000   -0.0125\n",
      "   160        0.5736             nan     0.1000   -0.0084\n",
      "   180        0.5389             nan     0.1000   -0.0102\n",
      "   200        0.5031             nan     0.1000   -0.0077\n",
      "   220        0.4725             nan     0.1000   -0.0083\n",
      "   240        0.4473             nan     0.1000   -0.0092\n",
      "   260        0.4212             nan     0.1000   -0.0086\n",
      "   280        0.3963             nan     0.1000   -0.0074\n",
      "   300        0.3760             nan     0.1000   -0.0074\n",
      "   320        0.3558             nan     0.1000   -0.0068\n",
      "   340        0.3356             nan     0.1000   -0.0060\n",
      "   360        0.3186             nan     0.1000   -0.0067\n",
      "   380        0.3017             nan     0.1000   -0.0052\n",
      "   400        0.2851             nan     0.1000   -0.0069\n",
      "   420        0.2686             nan     0.1000   -0.0036\n",
      "   440        0.2530             nan     0.1000   -0.0053\n",
      "   460        0.2385             nan     0.1000   -0.0047\n",
      "   480        0.2265             nan     0.1000   -0.0038\n",
      "   500        0.2145             nan     0.1000   -0.0024\n",
      "   520        0.2048             nan     0.1000   -0.0041\n",
      "   540        0.1944             nan     0.1000   -0.0037\n",
      "   560        0.1843             nan     0.1000   -0.0029\n",
      "   580        0.1761             nan     0.1000   -0.0028\n",
      "   600        0.1682             nan     0.1000   -0.0035\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0618\n",
      "     2        1.3205             nan     0.1000    0.0554\n",
      "     3        1.2674             nan     0.1000    0.0326\n",
      "     4        1.2213             nan     0.1000    0.0285\n",
      "     5        1.1852             nan     0.1000    0.0157\n",
      "     6        1.1559             nan     0.1000    0.0131\n",
      "     7        1.1304             nan     0.1000    0.0083\n",
      "     8        1.1108             nan     0.1000    0.0056\n",
      "     9        1.0872             nan     0.1000    0.0119\n",
      "    10        1.0653             nan     0.1000    0.0066\n",
      "    20        0.9410             nan     0.1000   -0.0159\n",
      "    40        0.7825             nan     0.1000   -0.0097\n",
      "    60        0.6678             nan     0.1000   -0.0134\n",
      "    80        0.5764             nan     0.1000   -0.0091\n",
      "   100        0.5045             nan     0.1000   -0.0144\n",
      "   120        0.4453             nan     0.1000   -0.0106\n",
      "   140        0.3953             nan     0.1000   -0.0084\n",
      "   160        0.3539             nan     0.1000   -0.0078\n",
      "   180        0.3129             nan     0.1000   -0.0081\n",
      "   200        0.2781             nan     0.1000   -0.0073\n",
      "   220        0.2493             nan     0.1000   -0.0078\n",
      "   240        0.2218             nan     0.1000   -0.0050\n",
      "   260        0.1986             nan     0.1000   -0.0041\n",
      "   280        0.1784             nan     0.1000   -0.0042\n",
      "   300        0.1610             nan     0.1000   -0.0036\n",
      "   320        0.1448             nan     0.1000   -0.0026\n",
      "   340        0.1302             nan     0.1000   -0.0030\n",
      "   360        0.1177             nan     0.1000   -0.0025\n",
      "   380        0.1063             nan     0.1000   -0.0023\n",
      "   400        0.0970             nan     0.1000   -0.0022\n",
      "   420        0.0878             nan     0.1000   -0.0014\n",
      "   440        0.0801             nan     0.1000   -0.0024\n",
      "   460        0.0729             nan     0.1000   -0.0016\n",
      "   480        0.0660             nan     0.1000   -0.0016\n",
      "   500        0.0596             nan     0.1000   -0.0015\n",
      "   520        0.0543             nan     0.1000   -0.0011\n",
      "   540        0.0493             nan     0.1000   -0.0010\n",
      "   560        0.0447             nan     0.1000   -0.0013\n",
      "   580        0.0405             nan     0.1000   -0.0014\n",
      "   600        0.0370             nan     0.1000   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0007\n",
      "     2        1.3858             nan     0.0010    0.0008\n",
      "     3        1.3853             nan     0.0010    0.0007\n",
      "     4        1.3848             nan     0.0010    0.0007\n",
      "     5        1.3842             nan     0.0010    0.0006\n",
      "     6        1.3837             nan     0.0010    0.0007\n",
      "     7        1.3832             nan     0.0010    0.0008\n",
      "     8        1.3828             nan     0.0010    0.0006\n",
      "     9        1.3823             nan     0.0010    0.0006\n",
      "    10        1.3818             nan     0.0010    0.0006\n",
      "    20        1.3770             nan     0.0010    0.0007\n",
      "    40        1.3676             nan     0.0010    0.0007\n",
      "    60        1.3587             nan     0.0010    0.0005\n",
      "    80        1.3503             nan     0.0010    0.0006\n",
      "   100        1.3421             nan     0.0010    0.0006\n",
      "   120        1.3345             nan     0.0010    0.0006\n",
      "   140        1.3272             nan     0.0010    0.0005\n",
      "   160        1.3204             nan     0.0010    0.0005\n",
      "   180        1.3138             nan     0.0010    0.0005\n",
      "   200        1.3077             nan     0.0010    0.0004\n",
      "   220        1.3018             nan     0.0010    0.0004\n",
      "   240        1.2960             nan     0.0010    0.0004\n",
      "   260        1.2906             nan     0.0010    0.0004\n",
      "   280        1.2853             nan     0.0010    0.0003\n",
      "   300        1.2801             nan     0.0010    0.0003\n",
      "   320        1.2752             nan     0.0010    0.0003\n",
      "   340        1.2704             nan     0.0010    0.0003\n",
      "   360        1.2661             nan     0.0010    0.0002\n",
      "   380        1.2618             nan     0.0010    0.0002\n",
      "   400        1.2578             nan     0.0010    0.0003\n",
      "   420        1.2540             nan     0.0010    0.0002\n",
      "   440        1.2504             nan     0.0010    0.0002\n",
      "   460        1.2467             nan     0.0010    0.0002\n",
      "   480        1.2432             nan     0.0010    0.0002\n",
      "   500        1.2398             nan     0.0010    0.0002\n",
      "   520        1.2365             nan     0.0010    0.0002\n",
      "   540        1.2331             nan     0.0010    0.0002\n",
      "   560        1.2303             nan     0.0010    0.0002\n",
      "   580        1.2273             nan     0.0010    0.0002\n",
      "   600        1.2244             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0007\n",
      "     2        1.3857             nan     0.0010    0.0009\n",
      "     3        1.3850             nan     0.0010    0.0008\n",
      "     4        1.3842             nan     0.0010    0.0007\n",
      "     5        1.3837             nan     0.0010    0.0008\n",
      "     6        1.3830             nan     0.0010    0.0008\n",
      "     7        1.3823             nan     0.0010    0.0008\n",
      "     8        1.3817             nan     0.0010    0.0008\n",
      "     9        1.3810             nan     0.0010    0.0008\n",
      "    10        1.3803             nan     0.0010    0.0009\n",
      "    20        1.3741             nan     0.0010    0.0007\n",
      "    40        1.3621             nan     0.0010    0.0008\n",
      "    60        1.3505             nan     0.0010    0.0007\n",
      "    80        1.3397             nan     0.0010    0.0007\n",
      "   100        1.3292             nan     0.0010    0.0007\n",
      "   120        1.3192             nan     0.0010    0.0006\n",
      "   140        1.3094             nan     0.0010    0.0006\n",
      "   160        1.3002             nan     0.0010    0.0005\n",
      "   180        1.2915             nan     0.0010    0.0005\n",
      "   200        1.2834             nan     0.0010    0.0004\n",
      "   220        1.2754             nan     0.0010    0.0004\n",
      "   240        1.2676             nan     0.0010    0.0004\n",
      "   260        1.2602             nan     0.0010    0.0004\n",
      "   280        1.2532             nan     0.0010    0.0004\n",
      "   300        1.2464             nan     0.0010    0.0005\n",
      "   320        1.2399             nan     0.0010    0.0003\n",
      "   340        1.2335             nan     0.0010    0.0003\n",
      "   360        1.2274             nan     0.0010    0.0003\n",
      "   380        1.2213             nan     0.0010    0.0003\n",
      "   400        1.2155             nan     0.0010    0.0003\n",
      "   420        1.2099             nan     0.0010    0.0003\n",
      "   440        1.2045             nan     0.0010    0.0003\n",
      "   460        1.1992             nan     0.0010    0.0003\n",
      "   480        1.1940             nan     0.0010    0.0002\n",
      "   500        1.1891             nan     0.0010    0.0002\n",
      "   520        1.1843             nan     0.0010    0.0003\n",
      "   540        1.1796             nan     0.0010    0.0002\n",
      "   560        1.1751             nan     0.0010    0.0002\n",
      "   580        1.1707             nan     0.0010    0.0001\n",
      "   600        1.1665             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0010\n",
      "     2        1.3855             nan     0.0010    0.0009\n",
      "     3        1.3848             nan     0.0010    0.0009\n",
      "     4        1.3840             nan     0.0010    0.0009\n",
      "     5        1.3832             nan     0.0010    0.0010\n",
      "     6        1.3825             nan     0.0010    0.0009\n",
      "     7        1.3818             nan     0.0010    0.0009\n",
      "     8        1.3810             nan     0.0010    0.0009\n",
      "     9        1.3802             nan     0.0010    0.0009\n",
      "    10        1.3795             nan     0.0010    0.0008\n",
      "    20        1.3724             nan     0.0010    0.0008\n",
      "    40        1.3584             nan     0.0010    0.0008\n",
      "    60        1.3454             nan     0.0010    0.0007\n",
      "    80        1.3325             nan     0.0010    0.0008\n",
      "   100        1.3206             nan     0.0010    0.0005\n",
      "   120        1.3091             nan     0.0010    0.0006\n",
      "   140        1.2978             nan     0.0010    0.0005\n",
      "   160        1.2872             nan     0.0010    0.0005\n",
      "   180        1.2770             nan     0.0010    0.0006\n",
      "   200        1.2672             nan     0.0010    0.0005\n",
      "   220        1.2576             nan     0.0010    0.0004\n",
      "   240        1.2485             nan     0.0010    0.0005\n",
      "   260        1.2399             nan     0.0010    0.0004\n",
      "   280        1.2315             nan     0.0010    0.0004\n",
      "   300        1.2233             nan     0.0010    0.0003\n",
      "   320        1.2153             nan     0.0010    0.0004\n",
      "   340        1.2075             nan     0.0010    0.0004\n",
      "   360        1.2000             nan     0.0010    0.0003\n",
      "   380        1.1928             nan     0.0010    0.0003\n",
      "   400        1.1859             nan     0.0010    0.0003\n",
      "   420        1.1792             nan     0.0010    0.0003\n",
      "   440        1.1726             nan     0.0010    0.0003\n",
      "   460        1.1663             nan     0.0010    0.0002\n",
      "   480        1.1603             nan     0.0010    0.0002\n",
      "   500        1.1543             nan     0.0010    0.0004\n",
      "   520        1.1484             nan     0.0010    0.0002\n",
      "   540        1.1427             nan     0.0010    0.0001\n",
      "   560        1.1374             nan     0.0010    0.0003\n",
      "   580        1.1321             nan     0.0010    0.0002\n",
      "   600        1.1269             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0072\n",
      "     2        1.3806             nan     0.0100    0.0069\n",
      "     3        1.3757             nan     0.0100    0.0068\n",
      "     4        1.3710             nan     0.0100    0.0070\n",
      "     5        1.3660             nan     0.0100    0.0067\n",
      "     6        1.3613             nan     0.0100    0.0067\n",
      "     7        1.3567             nan     0.0100    0.0066\n",
      "     8        1.3525             nan     0.0100    0.0053\n",
      "     9        1.3484             nan     0.0100    0.0061\n",
      "    10        1.3441             nan     0.0100    0.0058\n",
      "    20        1.3097             nan     0.0100    0.0048\n",
      "    40        1.2596             nan     0.0100    0.0029\n",
      "    60        1.2259             nan     0.0100    0.0017\n",
      "    80        1.2008             nan     0.0100    0.0011\n",
      "   100        1.1815             nan     0.0100    0.0007\n",
      "   120        1.1659             nan     0.0100    0.0002\n",
      "   140        1.1543             nan     0.0100    0.0005\n",
      "   160        1.1441             nan     0.0100   -0.0000\n",
      "   180        1.1356             nan     0.0100   -0.0001\n",
      "   200        1.1274             nan     0.0100   -0.0003\n",
      "   220        1.1208             nan     0.0100   -0.0003\n",
      "   240        1.1142             nan     0.0100   -0.0003\n",
      "   260        1.1084             nan     0.0100   -0.0002\n",
      "   280        1.1028             nan     0.0100   -0.0005\n",
      "   300        1.0979             nan     0.0100   -0.0005\n",
      "   320        1.0931             nan     0.0100   -0.0004\n",
      "   340        1.0888             nan     0.0100   -0.0004\n",
      "   360        1.0842             nan     0.0100   -0.0006\n",
      "   380        1.0801             nan     0.0100   -0.0004\n",
      "   400        1.0760             nan     0.0100   -0.0006\n",
      "   420        1.0721             nan     0.0100   -0.0004\n",
      "   440        1.0684             nan     0.0100   -0.0005\n",
      "   460        1.0647             nan     0.0100   -0.0006\n",
      "   480        1.0614             nan     0.0100   -0.0007\n",
      "   500        1.0578             nan     0.0100   -0.0007\n",
      "   520        1.0547             nan     0.0100   -0.0007\n",
      "   540        1.0514             nan     0.0100   -0.0002\n",
      "   560        1.0481             nan     0.0100   -0.0006\n",
      "   580        1.0451             nan     0.0100   -0.0005\n",
      "   600        1.0423             nan     0.0100   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0088\n",
      "     2        1.3800             nan     0.0100    0.0084\n",
      "     3        1.3736             nan     0.0100    0.0071\n",
      "     4        1.3681             nan     0.0100    0.0078\n",
      "     5        1.3621             nan     0.0100    0.0067\n",
      "     6        1.3564             nan     0.0100    0.0077\n",
      "     7        1.3502             nan     0.0100    0.0073\n",
      "     8        1.3446             nan     0.0100    0.0058\n",
      "     9        1.3397             nan     0.0100    0.0059\n",
      "    10        1.3346             nan     0.0100    0.0068\n",
      "    20        1.2871             nan     0.0100    0.0050\n",
      "    40        1.2181             nan     0.0100    0.0034\n",
      "    60        1.1685             nan     0.0100    0.0018\n",
      "    80        1.1319             nan     0.0100    0.0007\n",
      "   100        1.1010             nan     0.0100    0.0007\n",
      "   120        1.0755             nan     0.0100   -0.0003\n",
      "   140        1.0544             nan     0.0100    0.0000\n",
      "   160        1.0347             nan     0.0100    0.0002\n",
      "   180        1.0174             nan     0.0100   -0.0000\n",
      "   200        1.0020             nan     0.0100   -0.0005\n",
      "   220        0.9869             nan     0.0100   -0.0009\n",
      "   240        0.9746             nan     0.0100   -0.0008\n",
      "   260        0.9614             nan     0.0100   -0.0005\n",
      "   280        0.9485             nan     0.0100   -0.0009\n",
      "   300        0.9368             nan     0.0100   -0.0010\n",
      "   320        0.9260             nan     0.0100   -0.0007\n",
      "   340        0.9152             nan     0.0100   -0.0008\n",
      "   360        0.9050             nan     0.0100   -0.0012\n",
      "   380        0.8956             nan     0.0100   -0.0014\n",
      "   400        0.8859             nan     0.0100   -0.0009\n",
      "   420        0.8766             nan     0.0100   -0.0004\n",
      "   440        0.8675             nan     0.0100   -0.0005\n",
      "   460        0.8586             nan     0.0100   -0.0013\n",
      "   480        0.8500             nan     0.0100   -0.0005\n",
      "   500        0.8418             nan     0.0100   -0.0007\n",
      "   520        0.8339             nan     0.0100   -0.0004\n",
      "   540        0.8266             nan     0.0100   -0.0010\n",
      "   560        0.8186             nan     0.0100   -0.0005\n",
      "   580        0.8102             nan     0.0100   -0.0007\n",
      "   600        0.8033             nan     0.0100   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0096\n",
      "     2        1.3785             nan     0.0100    0.0094\n",
      "     3        1.3709             nan     0.0100    0.0082\n",
      "     4        1.3637             nan     0.0100    0.0090\n",
      "     5        1.3568             nan     0.0100    0.0079\n",
      "     6        1.3500             nan     0.0100    0.0070\n",
      "     7        1.3439             nan     0.0100    0.0083\n",
      "     8        1.3377             nan     0.0100    0.0075\n",
      "     9        1.3312             nan     0.0100    0.0073\n",
      "    10        1.3254             nan     0.0100    0.0064\n",
      "    20        1.2709             nan     0.0100    0.0048\n",
      "    40        1.1879             nan     0.0100    0.0028\n",
      "    60        1.1291             nan     0.0100    0.0017\n",
      "    80        1.0820             nan     0.0100    0.0011\n",
      "   100        1.0447             nan     0.0100   -0.0003\n",
      "   120        1.0120             nan     0.0100   -0.0002\n",
      "   140        0.9832             nan     0.0100   -0.0001\n",
      "   160        0.9571             nan     0.0100   -0.0004\n",
      "   180        0.9342             nan     0.0100   -0.0007\n",
      "   200        0.9137             nan     0.0100   -0.0007\n",
      "   220        0.8943             nan     0.0100   -0.0011\n",
      "   240        0.8753             nan     0.0100   -0.0007\n",
      "   260        0.8576             nan     0.0100   -0.0012\n",
      "   280        0.8408             nan     0.0100   -0.0007\n",
      "   300        0.8254             nan     0.0100   -0.0001\n",
      "   320        0.8092             nan     0.0100   -0.0011\n",
      "   340        0.7945             nan     0.0100   -0.0006\n",
      "   360        0.7802             nan     0.0100   -0.0008\n",
      "   380        0.7663             nan     0.0100   -0.0013\n",
      "   400        0.7525             nan     0.0100   -0.0012\n",
      "   420        0.7389             nan     0.0100   -0.0011\n",
      "   440        0.7265             nan     0.0100   -0.0009\n",
      "   460        0.7146             nan     0.0100   -0.0012\n",
      "   480        0.7020             nan     0.0100   -0.0010\n",
      "   500        0.6900             nan     0.0100   -0.0008\n",
      "   520        0.6783             nan     0.0100   -0.0009\n",
      "   540        0.6679             nan     0.0100   -0.0011\n",
      "   560        0.6584             nan     0.0100   -0.0013\n",
      "   580        0.6481             nan     0.0100   -0.0006\n",
      "   600        0.6386             nan     0.0100   -0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0660\n",
      "     2        1.3382             nan     0.1000    0.0486\n",
      "     3        1.3028             nan     0.1000    0.0370\n",
      "     4        1.2767             nan     0.1000    0.0293\n",
      "     5        1.2541             nan     0.1000    0.0214\n",
      "     6        1.2367             nan     0.1000    0.0156\n",
      "     7        1.2237             nan     0.1000    0.0129\n",
      "     8        1.2113             nan     0.1000    0.0091\n",
      "     9        1.2006             nan     0.1000    0.0051\n",
      "    10        1.1914             nan     0.1000    0.0087\n",
      "    20        1.1336             nan     0.1000   -0.0017\n",
      "    40        1.0800             nan     0.1000   -0.0043\n",
      "    60        1.0474             nan     0.1000   -0.0026\n",
      "    80        1.0208             nan     0.1000   -0.0058\n",
      "   100        0.9997             nan     0.1000   -0.0061\n",
      "   120        0.9831             nan     0.1000   -0.0071\n",
      "   140        0.9686             nan     0.1000   -0.0077\n",
      "   160        0.9574             nan     0.1000   -0.0077\n",
      "   180        0.9459             nan     0.1000   -0.0065\n",
      "   200        0.9339             nan     0.1000   -0.0063\n",
      "   220        0.9263             nan     0.1000   -0.0136\n",
      "   240        0.9181             nan     0.1000   -0.0064\n",
      "   260        0.9111             nan     0.1000   -0.0064\n",
      "   280        0.9029             nan     0.1000   -0.0065\n",
      "   300        0.8958             nan     0.1000   -0.0062\n",
      "   320        0.8903             nan     0.1000   -0.0059\n",
      "   340        0.8839             nan     0.1000   -0.0035\n",
      "   360        0.8776             nan     0.1000   -0.0073\n",
      "   380        0.8739             nan     0.1000   -0.0134\n",
      "   400        0.8697             nan     0.1000   -0.0069\n",
      "   420        0.8642             nan     0.1000   -0.0065\n",
      "   440        0.8605             nan     0.1000   -0.0090\n",
      "   460        0.8553             nan     0.1000   -0.0070\n",
      "   480        0.8510             nan     0.1000   -0.0064\n",
      "   500        0.8470             nan     0.1000   -0.0078\n",
      "   520        0.8443             nan     0.1000   -0.0072\n",
      "   540        0.8399             nan     0.1000   -0.0056\n",
      "   560        0.8345             nan     0.1000   -0.0064\n",
      "   580        0.8306             nan     0.1000   -0.0088\n",
      "   600        0.8270             nan     0.1000   -0.0088\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0702\n",
      "     2        1.3240             nan     0.1000    0.0546\n",
      "     3        1.2769             nan     0.1000    0.0350\n",
      "     4        1.2412             nan     0.1000    0.0264\n",
      "     5        1.2075             nan     0.1000    0.0223\n",
      "     6        1.1806             nan     0.1000    0.0120\n",
      "     7        1.1592             nan     0.1000    0.0085\n",
      "     8        1.1396             nan     0.1000    0.0060\n",
      "     9        1.1204             nan     0.1000    0.0054\n",
      "    10        1.1085             nan     0.1000    0.0051\n",
      "    20        1.0109             nan     0.1000   -0.0101\n",
      "    40        0.8978             nan     0.1000   -0.0174\n",
      "    60        0.8112             nan     0.1000   -0.0104\n",
      "    80        0.7460             nan     0.1000   -0.0070\n",
      "   100        0.6917             nan     0.1000   -0.0043\n",
      "   120        0.6436             nan     0.1000   -0.0079\n",
      "   140        0.6019             nan     0.1000   -0.0090\n",
      "   160        0.5637             nan     0.1000   -0.0095\n",
      "   180        0.5284             nan     0.1000   -0.0088\n",
      "   200        0.4988             nan     0.1000   -0.0077\n",
      "   220        0.4673             nan     0.1000   -0.0083\n",
      "   240        0.4399             nan     0.1000   -0.0059\n",
      "   260        0.4162             nan     0.1000   -0.0078\n",
      "   280        0.3921             nan     0.1000   -0.0094\n",
      "   300        0.3713             nan     0.1000   -0.0064\n",
      "   320        0.3514             nan     0.1000   -0.0060\n",
      "   340        0.3319             nan     0.1000   -0.0068\n",
      "   360        0.3151             nan     0.1000   -0.0049\n",
      "   380        0.2971             nan     0.1000   -0.0045\n",
      "   400        0.2823             nan     0.1000   -0.0062\n",
      "   420        0.2664             nan     0.1000   -0.0055\n",
      "   440        0.2525             nan     0.1000   -0.0042\n",
      "   460        0.2384             nan     0.1000   -0.0049\n",
      "   480        0.2270             nan     0.1000   -0.0036\n",
      "   500        0.2154             nan     0.1000   -0.0036\n",
      "   520        0.2052             nan     0.1000   -0.0044\n",
      "   540        0.1952             nan     0.1000   -0.0047\n",
      "   560        0.1868             nan     0.1000   -0.0025\n",
      "   580        0.1766             nan     0.1000   -0.0038\n",
      "   600        0.1686             nan     0.1000   -0.0037\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0741\n",
      "     2        1.3232             nan     0.1000    0.0532\n",
      "     3        1.2665             nan     0.1000    0.0395\n",
      "     4        1.2248             nan     0.1000    0.0345\n",
      "     5        1.1849             nan     0.1000    0.0149\n",
      "     6        1.1579             nan     0.1000    0.0166\n",
      "     7        1.1310             nan     0.1000   -0.0010\n",
      "     8        1.1106             nan     0.1000    0.0056\n",
      "     9        1.0878             nan     0.1000    0.0062\n",
      "    10        1.0682             nan     0.1000    0.0044\n",
      "    20        0.9304             nan     0.1000   -0.0080\n",
      "    40        0.7729             nan     0.1000   -0.0078\n",
      "    60        0.6607             nan     0.1000   -0.0163\n",
      "    80        0.5707             nan     0.1000   -0.0084\n",
      "   100        0.4983             nan     0.1000   -0.0102\n",
      "   120        0.4399             nan     0.1000   -0.0086\n",
      "   140        0.3847             nan     0.1000   -0.0074\n",
      "   160        0.3417             nan     0.1000   -0.0073\n",
      "   180        0.3028             nan     0.1000   -0.0066\n",
      "   200        0.2715             nan     0.1000   -0.0075\n",
      "   220        0.2441             nan     0.1000   -0.0077\n",
      "   240        0.2180             nan     0.1000   -0.0040\n",
      "   260        0.1966             nan     0.1000   -0.0051\n",
      "   280        0.1764             nan     0.1000   -0.0046\n",
      "   300        0.1583             nan     0.1000   -0.0030\n",
      "   320        0.1425             nan     0.1000   -0.0028\n",
      "   340        0.1286             nan     0.1000   -0.0032\n",
      "   360        0.1162             nan     0.1000   -0.0031\n",
      "   380        0.1057             nan     0.1000   -0.0025\n",
      "   400        0.0960             nan     0.1000   -0.0025\n",
      "   420        0.0869             nan     0.1000   -0.0021\n",
      "   440        0.0787             nan     0.1000   -0.0020\n",
      "   460        0.0708             nan     0.1000   -0.0020\n",
      "   480        0.0645             nan     0.1000   -0.0017\n",
      "   500        0.0589             nan     0.1000   -0.0023\n",
      "   520        0.0535             nan     0.1000   -0.0013\n",
      "   540        0.0487             nan     0.1000   -0.0010\n",
      "   560        0.0440             nan     0.1000   -0.0010\n",
      "   580        0.0403             nan     0.1000   -0.0007\n",
      "   600        0.0370             nan     0.1000   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0007\n",
      "     2        1.3858             nan     0.0010    0.0007\n",
      "     3        1.3853             nan     0.0010    0.0006\n",
      "     4        1.3848             nan     0.0010    0.0007\n",
      "     5        1.3844             nan     0.0010    0.0006\n",
      "     6        1.3840             nan     0.0010    0.0007\n",
      "     7        1.3834             nan     0.0010    0.0007\n",
      "     8        1.3830             nan     0.0010    0.0007\n",
      "     9        1.3824             nan     0.0010    0.0007\n",
      "    10        1.3820             nan     0.0010    0.0007\n",
      "    20        1.3772             nan     0.0010    0.0007\n",
      "    40        1.3680             nan     0.0010    0.0006\n",
      "    60        1.3594             nan     0.0010    0.0006\n",
      "    80        1.3512             nan     0.0010    0.0005\n",
      "   100        1.3433             nan     0.0010    0.0006\n",
      "   120        1.3359             nan     0.0010    0.0005\n",
      "   140        1.3286             nan     0.0010    0.0005\n",
      "   160        1.3218             nan     0.0010    0.0005\n",
      "   180        1.3152             nan     0.0010    0.0004\n",
      "   200        1.3089             nan     0.0010    0.0004\n",
      "   220        1.3029             nan     0.0010    0.0004\n",
      "   240        1.2974             nan     0.0010    0.0004\n",
      "   260        1.2920             nan     0.0010    0.0003\n",
      "   280        1.2869             nan     0.0010    0.0003\n",
      "   300        1.2819             nan     0.0010    0.0003\n",
      "   320        1.2771             nan     0.0010    0.0003\n",
      "   340        1.2726             nan     0.0010    0.0003\n",
      "   360        1.2682             nan     0.0010    0.0002\n",
      "   380        1.2640             nan     0.0010    0.0003\n",
      "   400        1.2598             nan     0.0010    0.0003\n",
      "   420        1.2560             nan     0.0010    0.0002\n",
      "   440        1.2522             nan     0.0010    0.0003\n",
      "   460        1.2485             nan     0.0010    0.0002\n",
      "   480        1.2450             nan     0.0010    0.0002\n",
      "   500        1.2417             nan     0.0010    0.0002\n",
      "   520        1.2386             nan     0.0010    0.0002\n",
      "   540        1.2354             nan     0.0010    0.0002\n",
      "   560        1.2325             nan     0.0010    0.0002\n",
      "   580        1.2296             nan     0.0010    0.0001\n",
      "   600        1.2267             nan     0.0010    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0008\n",
      "     2        1.3857             nan     0.0010    0.0006\n",
      "     3        1.3851             nan     0.0010    0.0007\n",
      "     4        1.3845             nan     0.0010    0.0008\n",
      "     5        1.3839             nan     0.0010    0.0008\n",
      "     6        1.3832             nan     0.0010    0.0008\n",
      "     7        1.3826             nan     0.0010    0.0008\n",
      "     8        1.3820             nan     0.0010    0.0008\n",
      "     9        1.3813             nan     0.0010    0.0007\n",
      "    10        1.3808             nan     0.0010    0.0007\n",
      "    20        1.3747             nan     0.0010    0.0006\n",
      "    40        1.3631             nan     0.0010    0.0007\n",
      "    60        1.3521             nan     0.0010    0.0006\n",
      "    80        1.3415             nan     0.0010    0.0006\n",
      "   100        1.3310             nan     0.0010    0.0006\n",
      "   120        1.3210             nan     0.0010    0.0006\n",
      "   140        1.3119             nan     0.0010    0.0005\n",
      "   160        1.3033             nan     0.0010    0.0005\n",
      "   180        1.2948             nan     0.0010    0.0005\n",
      "   200        1.2865             nan     0.0010    0.0005\n",
      "   220        1.2785             nan     0.0010    0.0004\n",
      "   240        1.2711             nan     0.0010    0.0004\n",
      "   260        1.2640             nan     0.0010    0.0004\n",
      "   280        1.2571             nan     0.0010    0.0005\n",
      "   300        1.2504             nan     0.0010    0.0003\n",
      "   320        1.2439             nan     0.0010    0.0004\n",
      "   340        1.2378             nan     0.0010    0.0003\n",
      "   360        1.2318             nan     0.0010    0.0004\n",
      "   380        1.2260             nan     0.0010    0.0003\n",
      "   400        1.2205             nan     0.0010    0.0003\n",
      "   420        1.2152             nan     0.0010    0.0003\n",
      "   440        1.2102             nan     0.0010    0.0003\n",
      "   460        1.2051             nan     0.0010    0.0003\n",
      "   480        1.2003             nan     0.0010    0.0003\n",
      "   500        1.1955             nan     0.0010    0.0002\n",
      "   520        1.1907             nan     0.0010    0.0002\n",
      "   540        1.1861             nan     0.0010    0.0002\n",
      "   560        1.1818             nan     0.0010    0.0001\n",
      "   580        1.1776             nan     0.0010    0.0001\n",
      "   600        1.1735             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0009\n",
      "     2        1.3855             nan     0.0010    0.0008\n",
      "     3        1.3848             nan     0.0010    0.0009\n",
      "     4        1.3841             nan     0.0010    0.0009\n",
      "     5        1.3833             nan     0.0010    0.0008\n",
      "     6        1.3826             nan     0.0010    0.0009\n",
      "     7        1.3819             nan     0.0010    0.0008\n",
      "     8        1.3812             nan     0.0010    0.0009\n",
      "     9        1.3804             nan     0.0010    0.0008\n",
      "    10        1.3796             nan     0.0010    0.0008\n",
      "    20        1.3726             nan     0.0010    0.0008\n",
      "    40        1.3594             nan     0.0010    0.0007\n",
      "    60        1.3463             nan     0.0010    0.0006\n",
      "    80        1.3342             nan     0.0010    0.0007\n",
      "   100        1.3223             nan     0.0010    0.0006\n",
      "   120        1.3110             nan     0.0010    0.0005\n",
      "   140        1.3002             nan     0.0010    0.0006\n",
      "   160        1.2901             nan     0.0010    0.0006\n",
      "   180        1.2803             nan     0.0010    0.0004\n",
      "   200        1.2707             nan     0.0010    0.0004\n",
      "   220        1.2616             nan     0.0010    0.0005\n",
      "   240        1.2527             nan     0.0010    0.0004\n",
      "   260        1.2442             nan     0.0010    0.0005\n",
      "   280        1.2360             nan     0.0010    0.0005\n",
      "   300        1.2280             nan     0.0010    0.0004\n",
      "   320        1.2205             nan     0.0010    0.0003\n",
      "   340        1.2131             nan     0.0010    0.0003\n",
      "   360        1.2061             nan     0.0010    0.0003\n",
      "   380        1.1992             nan     0.0010    0.0003\n",
      "   400        1.1925             nan     0.0010    0.0002\n",
      "   420        1.1861             nan     0.0010    0.0002\n",
      "   440        1.1800             nan     0.0010    0.0003\n",
      "   460        1.1739             nan     0.0010    0.0002\n",
      "   480        1.1679             nan     0.0010    0.0002\n",
      "   500        1.1622             nan     0.0010    0.0002\n",
      "   520        1.1564             nan     0.0010    0.0001\n",
      "   540        1.1510             nan     0.0010    0.0003\n",
      "   560        1.1456             nan     0.0010    0.0002\n",
      "   580        1.1404             nan     0.0010    0.0003\n",
      "   600        1.1353             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0069\n",
      "     2        1.3815             nan     0.0100    0.0068\n",
      "     3        1.3770             nan     0.0100    0.0066\n",
      "     4        1.3721             nan     0.0100    0.0062\n",
      "     5        1.3679             nan     0.0100    0.0057\n",
      "     6        1.3638             nan     0.0100    0.0054\n",
      "     7        1.3599             nan     0.0100    0.0055\n",
      "     8        1.3557             nan     0.0100    0.0058\n",
      "     9        1.3516             nan     0.0100    0.0062\n",
      "    10        1.3476             nan     0.0100    0.0054\n",
      "    20        1.3124             nan     0.0100    0.0041\n",
      "    40        1.2616             nan     0.0100    0.0024\n",
      "    60        1.2281             nan     0.0100    0.0018\n",
      "    80        1.2038             nan     0.0100    0.0008\n",
      "   100        1.1859             nan     0.0100    0.0005\n",
      "   120        1.1719             nan     0.0100    0.0003\n",
      "   140        1.1602             nan     0.0100    0.0000\n",
      "   160        1.1505             nan     0.0100   -0.0000\n",
      "   180        1.1423             nan     0.0100   -0.0001\n",
      "   200        1.1350             nan     0.0100   -0.0000\n",
      "   220        1.1281             nan     0.0100   -0.0001\n",
      "   240        1.1220             nan     0.0100   -0.0001\n",
      "   260        1.1165             nan     0.0100   -0.0006\n",
      "   280        1.1118             nan     0.0100   -0.0002\n",
      "   300        1.1076             nan     0.0100   -0.0006\n",
      "   320        1.1033             nan     0.0100   -0.0004\n",
      "   340        1.0992             nan     0.0100   -0.0004\n",
      "   360        1.0953             nan     0.0100   -0.0006\n",
      "   380        1.0915             nan     0.0100   -0.0005\n",
      "   400        1.0881             nan     0.0100   -0.0008\n",
      "   420        1.0849             nan     0.0100   -0.0003\n",
      "   440        1.0816             nan     0.0100   -0.0003\n",
      "   460        1.0784             nan     0.0100   -0.0006\n",
      "   480        1.0753             nan     0.0100   -0.0006\n",
      "   500        1.0721             nan     0.0100   -0.0003\n",
      "   520        1.0692             nan     0.0100   -0.0007\n",
      "   540        1.0664             nan     0.0100   -0.0006\n",
      "   560        1.0638             nan     0.0100   -0.0007\n",
      "   580        1.0609             nan     0.0100   -0.0007\n",
      "   600        1.0585             nan     0.0100   -0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0072\n",
      "     2        1.3798             nan     0.0100    0.0071\n",
      "     3        1.3742             nan     0.0100    0.0079\n",
      "     4        1.3681             nan     0.0100    0.0063\n",
      "     5        1.3622             nan     0.0100    0.0073\n",
      "     6        1.3564             nan     0.0100    0.0070\n",
      "     7        1.3510             nan     0.0100    0.0073\n",
      "     8        1.3456             nan     0.0100    0.0072\n",
      "     9        1.3396             nan     0.0100    0.0053\n",
      "    10        1.3345             nan     0.0100    0.0056\n",
      "    20        1.2892             nan     0.0100    0.0057\n",
      "    40        1.2225             nan     0.0100    0.0022\n",
      "    60        1.1762             nan     0.0100    0.0016\n",
      "    80        1.1400             nan     0.0100    0.0010\n",
      "   100        1.1113             nan     0.0100   -0.0001\n",
      "   120        1.0884             nan     0.0100    0.0004\n",
      "   140        1.0678             nan     0.0100   -0.0001\n",
      "   160        1.0500             nan     0.0100   -0.0004\n",
      "   180        1.0337             nan     0.0100   -0.0009\n",
      "   200        1.0200             nan     0.0100   -0.0007\n",
      "   220        1.0059             nan     0.0100   -0.0006\n",
      "   240        0.9924             nan     0.0100   -0.0011\n",
      "   260        0.9807             nan     0.0100   -0.0011\n",
      "   280        0.9686             nan     0.0100   -0.0009\n",
      "   300        0.9574             nan     0.0100   -0.0003\n",
      "   320        0.9473             nan     0.0100   -0.0009\n",
      "   340        0.9369             nan     0.0100   -0.0010\n",
      "   360        0.9273             nan     0.0100   -0.0008\n",
      "   380        0.9173             nan     0.0100   -0.0017\n",
      "   400        0.9078             nan     0.0100   -0.0012\n",
      "   420        0.8988             nan     0.0100   -0.0008\n",
      "   440        0.8890             nan     0.0100   -0.0010\n",
      "   460        0.8804             nan     0.0100   -0.0010\n",
      "   480        0.8728             nan     0.0100   -0.0013\n",
      "   500        0.8646             nan     0.0100   -0.0009\n",
      "   520        0.8569             nan     0.0100   -0.0011\n",
      "   540        0.8484             nan     0.0100   -0.0012\n",
      "   560        0.8407             nan     0.0100   -0.0011\n",
      "   580        0.8329             nan     0.0100   -0.0006\n",
      "   600        0.8257             nan     0.0100   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0092\n",
      "     2        1.3789             nan     0.0100    0.0092\n",
      "     3        1.3719             nan     0.0100    0.0070\n",
      "     4        1.3652             nan     0.0100    0.0068\n",
      "     5        1.3587             nan     0.0100    0.0070\n",
      "     6        1.3524             nan     0.0100    0.0073\n",
      "     7        1.3466             nan     0.0100    0.0076\n",
      "     8        1.3405             nan     0.0100    0.0077\n",
      "     9        1.3341             nan     0.0100    0.0069\n",
      "    10        1.3282             nan     0.0100    0.0057\n",
      "    20        1.2756             nan     0.0100    0.0048\n",
      "    40        1.1948             nan     0.0100    0.0020\n",
      "    60        1.1379             nan     0.0100    0.0020\n",
      "    80        1.0941             nan     0.0100    0.0011\n",
      "   100        1.0574             nan     0.0100    0.0005\n",
      "   120        1.0263             nan     0.0100   -0.0001\n",
      "   140        0.9990             nan     0.0100    0.0002\n",
      "   160        0.9748             nan     0.0100   -0.0011\n",
      "   180        0.9532             nan     0.0100   -0.0009\n",
      "   200        0.9330             nan     0.0100   -0.0013\n",
      "   220        0.9143             nan     0.0100   -0.0013\n",
      "   240        0.8965             nan     0.0100   -0.0014\n",
      "   260        0.8790             nan     0.0100   -0.0014\n",
      "   280        0.8621             nan     0.0100   -0.0014\n",
      "   300        0.8457             nan     0.0100   -0.0014\n",
      "   320        0.8311             nan     0.0100   -0.0010\n",
      "   340        0.8169             nan     0.0100   -0.0012\n",
      "   360        0.8030             nan     0.0100   -0.0008\n",
      "   380        0.7888             nan     0.0100   -0.0014\n",
      "   400        0.7760             nan     0.0100   -0.0014\n",
      "   420        0.7628             nan     0.0100   -0.0012\n",
      "   440        0.7504             nan     0.0100   -0.0008\n",
      "   460        0.7379             nan     0.0100   -0.0008\n",
      "   480        0.7261             nan     0.0100   -0.0010\n",
      "   500        0.7148             nan     0.0100   -0.0008\n",
      "   520        0.7030             nan     0.0100   -0.0014\n",
      "   540        0.6920             nan     0.0100   -0.0015\n",
      "   560        0.6813             nan     0.0100   -0.0012\n",
      "   580        0.6708             nan     0.0100   -0.0014\n",
      "   600        0.6607             nan     0.0100   -0.0014\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0619\n",
      "     2        1.3399             nan     0.1000    0.0484\n",
      "     3        1.3003             nan     0.1000    0.0329\n",
      "     4        1.2761             nan     0.1000    0.0278\n",
      "     5        1.2551             nan     0.1000    0.0186\n",
      "     6        1.2387             nan     0.1000    0.0161\n",
      "     7        1.2218             nan     0.1000    0.0140\n",
      "     8        1.2098             nan     0.1000    0.0105\n",
      "     9        1.2001             nan     0.1000    0.0095\n",
      "    10        1.1916             nan     0.1000    0.0064\n",
      "    20        1.1372             nan     0.1000    0.0009\n",
      "    40        1.0892             nan     0.1000   -0.0095\n",
      "    60        1.0614             nan     0.1000   -0.0076\n",
      "    80        1.0399             nan     0.1000   -0.0055\n",
      "   100        1.0227             nan     0.1000   -0.0059\n",
      "   120        1.0079             nan     0.1000   -0.0082\n",
      "   140        0.9957             nan     0.1000   -0.0086\n",
      "   160        0.9823             nan     0.1000   -0.0052\n",
      "   180        0.9723             nan     0.1000   -0.0070\n",
      "   200        0.9632             nan     0.1000   -0.0058\n",
      "   220        0.9548             nan     0.1000   -0.0091\n",
      "   240        0.9479             nan     0.1000   -0.0060\n",
      "   260        0.9426             nan     0.1000   -0.0102\n",
      "   280        0.9351             nan     0.1000   -0.0091\n",
      "   300        0.9290             nan     0.1000   -0.0107\n",
      "   320        0.9227             nan     0.1000   -0.0071\n",
      "   340        0.9172             nan     0.1000   -0.0059\n",
      "   360        0.9117             nan     0.1000   -0.0087\n",
      "   380        0.9060             nan     0.1000   -0.0108\n",
      "   400        0.9035             nan     0.1000   -0.0081\n",
      "   420        0.8983             nan     0.1000   -0.0067\n",
      "   440        0.8923             nan     0.1000   -0.0063\n",
      "   460        0.8895             nan     0.1000   -0.0069\n",
      "   480        0.8847             nan     0.1000   -0.0049\n",
      "   500        0.8789             nan     0.1000   -0.0073\n",
      "   520        0.8758             nan     0.1000   -0.0065\n",
      "   540        0.8724             nan     0.1000   -0.0061\n",
      "   560        0.8673             nan     0.1000   -0.0094\n",
      "   580        0.8636             nan     0.1000   -0.0059\n",
      "   600        0.8596             nan     0.1000   -0.0099\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0615\n",
      "     2        1.3325             nan     0.1000    0.0538\n",
      "     3        1.2829             nan     0.1000    0.0399\n",
      "     4        1.2447             nan     0.1000    0.0283\n",
      "     5        1.2156             nan     0.1000    0.0214\n",
      "     6        1.1889             nan     0.1000    0.0158\n",
      "     7        1.1700             nan     0.1000    0.0084\n",
      "     8        1.1528             nan     0.1000    0.0074\n",
      "     9        1.1370             nan     0.1000   -0.0015\n",
      "    10        1.1209             nan     0.1000    0.0068\n",
      "    20        1.0330             nan     0.1000   -0.0059\n",
      "    40        0.9193             nan     0.1000   -0.0074\n",
      "    60        0.8369             nan     0.1000   -0.0172\n",
      "    80        0.7775             nan     0.1000   -0.0107\n",
      "   100        0.7213             nan     0.1000   -0.0139\n",
      "   120        0.6718             nan     0.1000   -0.0142\n",
      "   140        0.6241             nan     0.1000   -0.0049\n",
      "   160        0.5890             nan     0.1000   -0.0116\n",
      "   180        0.5489             nan     0.1000   -0.0097\n",
      "   200        0.5185             nan     0.1000   -0.0065\n",
      "   220        0.4861             nan     0.1000   -0.0067\n",
      "   240        0.4551             nan     0.1000   -0.0050\n",
      "   260        0.4284             nan     0.1000   -0.0067\n",
      "   280        0.4044             nan     0.1000   -0.0064\n",
      "   300        0.3830             nan     0.1000   -0.0064\n",
      "   320        0.3618             nan     0.1000   -0.0049\n",
      "   340        0.3432             nan     0.1000   -0.0054\n",
      "   360        0.3239             nan     0.1000   -0.0078\n",
      "   380        0.3078             nan     0.1000   -0.0064\n",
      "   400        0.2945             nan     0.1000   -0.0051\n",
      "   420        0.2785             nan     0.1000   -0.0041\n",
      "   440        0.2653             nan     0.1000   -0.0047\n",
      "   460        0.2522             nan     0.1000   -0.0024\n",
      "   480        0.2384             nan     0.1000   -0.0041\n",
      "   500        0.2270             nan     0.1000   -0.0026\n",
      "   520        0.2165             nan     0.1000   -0.0043\n",
      "   540        0.2054             nan     0.1000   -0.0032\n",
      "   560        0.1938             nan     0.1000   -0.0034\n",
      "   580        0.1854             nan     0.1000   -0.0038\n",
      "   600        0.1762             nan     0.1000   -0.0030\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0703\n",
      "     2        1.3235             nan     0.1000    0.0650\n",
      "     3        1.2687             nan     0.1000    0.0315\n",
      "     4        1.2272             nan     0.1000    0.0274\n",
      "     5        1.1913             nan     0.1000    0.0230\n",
      "     6        1.1623             nan     0.1000    0.0163\n",
      "     7        1.1367             nan     0.1000    0.0033\n",
      "     8        1.1173             nan     0.1000   -0.0020\n",
      "     9        1.0980             nan     0.1000    0.0046\n",
      "    10        1.0819             nan     0.1000    0.0038\n",
      "    20        0.9473             nan     0.1000   -0.0086\n",
      "    40        0.7878             nan     0.1000   -0.0156\n",
      "    60        0.6712             nan     0.1000   -0.0168\n",
      "    80        0.5855             nan     0.1000   -0.0136\n",
      "   100        0.5137             nan     0.1000   -0.0073\n",
      "   120        0.4532             nan     0.1000   -0.0140\n",
      "   140        0.4016             nan     0.1000   -0.0108\n",
      "   160        0.3545             nan     0.1000   -0.0090\n",
      "   180        0.3178             nan     0.1000   -0.0074\n",
      "   200        0.2863             nan     0.1000   -0.0059\n",
      "   220        0.2568             nan     0.1000   -0.0065\n",
      "   240        0.2323             nan     0.1000   -0.0051\n",
      "   260        0.2091             nan     0.1000   -0.0040\n",
      "   280        0.1886             nan     0.1000   -0.0026\n",
      "   300        0.1682             nan     0.1000   -0.0032\n",
      "   320        0.1524             nan     0.1000   -0.0035\n",
      "   340        0.1381             nan     0.1000   -0.0029\n",
      "   360        0.1246             nan     0.1000   -0.0027\n",
      "   380        0.1131             nan     0.1000   -0.0018\n",
      "   400        0.1039             nan     0.1000   -0.0021\n",
      "   420        0.0946             nan     0.1000   -0.0018\n",
      "   440        0.0861             nan     0.1000   -0.0027\n",
      "   460        0.0781             nan     0.1000   -0.0017\n",
      "   480        0.0710             nan     0.1000   -0.0023\n",
      "   500        0.0651             nan     0.1000   -0.0016\n",
      "   520        0.0594             nan     0.1000   -0.0013\n",
      "   540        0.0540             nan     0.1000   -0.0013\n",
      "   560        0.0494             nan     0.1000   -0.0010\n",
      "   580        0.0450             nan     0.1000   -0.0010\n",
      "   600        0.0413             nan     0.1000   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0007\n",
      "     2        1.3858             nan     0.0010    0.0007\n",
      "     3        1.3853             nan     0.0010    0.0007\n",
      "     4        1.3848             nan     0.0010    0.0006\n",
      "     5        1.3844             nan     0.0010    0.0007\n",
      "     6        1.3838             nan     0.0010    0.0007\n",
      "     7        1.3833             nan     0.0010    0.0007\n",
      "     8        1.3828             nan     0.0010    0.0007\n",
      "     9        1.3824             nan     0.0010    0.0007\n",
      "    10        1.3819             nan     0.0010    0.0006\n",
      "    20        1.3773             nan     0.0010    0.0007\n",
      "    40        1.3679             nan     0.0010    0.0006\n",
      "    60        1.3592             nan     0.0010    0.0006\n",
      "    80        1.3509             nan     0.0010    0.0006\n",
      "   100        1.3431             nan     0.0010    0.0006\n",
      "   120        1.3355             nan     0.0010    0.0005\n",
      "   140        1.3284             nan     0.0010    0.0005\n",
      "   160        1.3216             nan     0.0010    0.0004\n",
      "   180        1.3155             nan     0.0010    0.0004\n",
      "   200        1.3093             nan     0.0010    0.0004\n",
      "   220        1.3034             nan     0.0010    0.0004\n",
      "   240        1.2977             nan     0.0010    0.0004\n",
      "   260        1.2921             nan     0.0010    0.0004\n",
      "   280        1.2868             nan     0.0010    0.0003\n",
      "   300        1.2818             nan     0.0010    0.0003\n",
      "   320        1.2770             nan     0.0010    0.0003\n",
      "   340        1.2723             nan     0.0010    0.0003\n",
      "   360        1.2679             nan     0.0010    0.0003\n",
      "   380        1.2637             nan     0.0010    0.0003\n",
      "   400        1.2595             nan     0.0010    0.0003\n",
      "   420        1.2556             nan     0.0010    0.0002\n",
      "   440        1.2519             nan     0.0010    0.0002\n",
      "   460        1.2484             nan     0.0010    0.0003\n",
      "   480        1.2449             nan     0.0010    0.0002\n",
      "   500        1.2415             nan     0.0010    0.0002\n",
      "   520        1.2383             nan     0.0010    0.0002\n",
      "   540        1.2351             nan     0.0010    0.0001\n",
      "   560        1.2320             nan     0.0010    0.0002\n",
      "   580        1.2291             nan     0.0010    0.0001\n",
      "   600        1.2263             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0008\n",
      "     2        1.3857             nan     0.0010    0.0008\n",
      "     3        1.3850             nan     0.0010    0.0009\n",
      "     4        1.3844             nan     0.0010    0.0008\n",
      "     5        1.3837             nan     0.0010    0.0008\n",
      "     6        1.3831             nan     0.0010    0.0008\n",
      "     7        1.3825             nan     0.0010    0.0009\n",
      "     8        1.3818             nan     0.0010    0.0008\n",
      "     9        1.3812             nan     0.0010    0.0008\n",
      "    10        1.3805             nan     0.0010    0.0008\n",
      "    20        1.3743             nan     0.0010    0.0008\n",
      "    40        1.3623             nan     0.0010    0.0007\n",
      "    60        1.3505             nan     0.0010    0.0007\n",
      "    80        1.3398             nan     0.0010    0.0007\n",
      "   100        1.3294             nan     0.0010    0.0006\n",
      "   120        1.3194             nan     0.0010    0.0006\n",
      "   140        1.3098             nan     0.0010    0.0006\n",
      "   160        1.3008             nan     0.0010    0.0006\n",
      "   180        1.2922             nan     0.0010    0.0004\n",
      "   200        1.2840             nan     0.0010    0.0005\n",
      "   220        1.2759             nan     0.0010    0.0005\n",
      "   240        1.2682             nan     0.0010    0.0005\n",
      "   260        1.2610             nan     0.0010    0.0004\n",
      "   280        1.2540             nan     0.0010    0.0004\n",
      "   300        1.2472             nan     0.0010    0.0004\n",
      "   320        1.2406             nan     0.0010    0.0003\n",
      "   340        1.2341             nan     0.0010    0.0004\n",
      "   360        1.2280             nan     0.0010    0.0003\n",
      "   380        1.2220             nan     0.0010    0.0002\n",
      "   400        1.2164             nan     0.0010    0.0003\n",
      "   420        1.2109             nan     0.0010    0.0002\n",
      "   440        1.2056             nan     0.0010    0.0003\n",
      "   460        1.2003             nan     0.0010    0.0003\n",
      "   480        1.1952             nan     0.0010    0.0002\n",
      "   500        1.1904             nan     0.0010    0.0002\n",
      "   520        1.1855             nan     0.0010    0.0002\n",
      "   540        1.1808             nan     0.0010    0.0002\n",
      "   560        1.1764             nan     0.0010    0.0002\n",
      "   580        1.1720             nan     0.0010    0.0003\n",
      "   600        1.1677             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0010\n",
      "     2        1.3856             nan     0.0010    0.0009\n",
      "     3        1.3848             nan     0.0010    0.0010\n",
      "     4        1.3841             nan     0.0010    0.0009\n",
      "     5        1.3833             nan     0.0010    0.0009\n",
      "     6        1.3826             nan     0.0010    0.0010\n",
      "     7        1.3819             nan     0.0010    0.0009\n",
      "     8        1.3811             nan     0.0010    0.0008\n",
      "     9        1.3804             nan     0.0010    0.0007\n",
      "    10        1.3797             nan     0.0010    0.0009\n",
      "    20        1.3723             nan     0.0010    0.0008\n",
      "    40        1.3587             nan     0.0010    0.0008\n",
      "    60        1.3451             nan     0.0010    0.0007\n",
      "    80        1.3324             nan     0.0010    0.0006\n",
      "   100        1.3204             nan     0.0010    0.0007\n",
      "   120        1.3089             nan     0.0010    0.0006\n",
      "   140        1.2976             nan     0.0010    0.0007\n",
      "   160        1.2870             nan     0.0010    0.0006\n",
      "   180        1.2769             nan     0.0010    0.0005\n",
      "   200        1.2670             nan     0.0010    0.0005\n",
      "   220        1.2576             nan     0.0010    0.0006\n",
      "   240        1.2485             nan     0.0010    0.0005\n",
      "   260        1.2396             nan     0.0010    0.0005\n",
      "   280        1.2311             nan     0.0010    0.0004\n",
      "   300        1.2230             nan     0.0010    0.0004\n",
      "   320        1.2151             nan     0.0010    0.0003\n",
      "   340        1.2076             nan     0.0010    0.0003\n",
      "   360        1.2000             nan     0.0010    0.0003\n",
      "   380        1.1929             nan     0.0010    0.0003\n",
      "   400        1.1859             nan     0.0010    0.0003\n",
      "   420        1.1792             nan     0.0010    0.0003\n",
      "   440        1.1726             nan     0.0010    0.0003\n",
      "   460        1.1664             nan     0.0010    0.0003\n",
      "   480        1.1602             nan     0.0010    0.0003\n",
      "   500        1.1544             nan     0.0010    0.0003\n",
      "   520        1.1486             nan     0.0010    0.0002\n",
      "   540        1.1430             nan     0.0010    0.0002\n",
      "   560        1.1376             nan     0.0010    0.0003\n",
      "   580        1.1322             nan     0.0010    0.0002\n",
      "   600        1.1269             nan     0.0010    0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0072\n",
      "     2        1.3811             nan     0.0100    0.0067\n",
      "     3        1.3761             nan     0.0100    0.0064\n",
      "     4        1.3713             nan     0.0100    0.0064\n",
      "     5        1.3665             nan     0.0100    0.0062\n",
      "     6        1.3618             nan     0.0100    0.0065\n",
      "     7        1.3574             nan     0.0100    0.0063\n",
      "     8        1.3533             nan     0.0100    0.0058\n",
      "     9        1.3493             nan     0.0100    0.0059\n",
      "    10        1.3451             nan     0.0100    0.0060\n",
      "    20        1.3100             nan     0.0100    0.0041\n",
      "    40        1.2609             nan     0.0100    0.0024\n",
      "    60        1.2270             nan     0.0100    0.0014\n",
      "    80        1.2021             nan     0.0100    0.0008\n",
      "   100        1.1835             nan     0.0100    0.0006\n",
      "   120        1.1693             nan     0.0100    0.0005\n",
      "   140        1.1569             nan     0.0100    0.0005\n",
      "   160        1.1466             nan     0.0100   -0.0004\n",
      "   180        1.1378             nan     0.0100   -0.0003\n",
      "   200        1.1301             nan     0.0100    0.0001\n",
      "   220        1.1232             nan     0.0100   -0.0004\n",
      "   240        1.1172             nan     0.0100   -0.0001\n",
      "   260        1.1112             nan     0.0100   -0.0002\n",
      "   280        1.1055             nan     0.0100   -0.0004\n",
      "   300        1.1004             nan     0.0100   -0.0004\n",
      "   320        1.0959             nan     0.0100   -0.0004\n",
      "   340        1.0917             nan     0.0100   -0.0001\n",
      "   360        1.0875             nan     0.0100   -0.0008\n",
      "   380        1.0835             nan     0.0100   -0.0005\n",
      "   400        1.0799             nan     0.0100   -0.0005\n",
      "   420        1.0761             nan     0.0100   -0.0002\n",
      "   440        1.0725             nan     0.0100   -0.0006\n",
      "   460        1.0691             nan     0.0100   -0.0005\n",
      "   480        1.0658             nan     0.0100   -0.0006\n",
      "   500        1.0625             nan     0.0100   -0.0003\n",
      "   520        1.0591             nan     0.0100   -0.0011\n",
      "   540        1.0565             nan     0.0100   -0.0006\n",
      "   560        1.0534             nan     0.0100   -0.0006\n",
      "   580        1.0502             nan     0.0100   -0.0004\n",
      "   600        1.0475             nan     0.0100   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0084\n",
      "     2        1.3790             nan     0.0100    0.0087\n",
      "     3        1.3727             nan     0.0100    0.0077\n",
      "     4        1.3669             nan     0.0100    0.0079\n",
      "     5        1.3606             nan     0.0100    0.0071\n",
      "     6        1.3548             nan     0.0100    0.0066\n",
      "     7        1.3493             nan     0.0100    0.0071\n",
      "     8        1.3436             nan     0.0100    0.0066\n",
      "     9        1.3379             nan     0.0100    0.0077\n",
      "    10        1.3325             nan     0.0100    0.0066\n",
      "    20        1.2853             nan     0.0100    0.0058\n",
      "    40        1.2176             nan     0.0100    0.0031\n",
      "    60        1.1690             nan     0.0100    0.0017\n",
      "    80        1.1322             nan     0.0100    0.0012\n",
      "   100        1.1016             nan     0.0100    0.0007\n",
      "   120        1.0757             nan     0.0100    0.0006\n",
      "   140        1.0557             nan     0.0100    0.0000\n",
      "   160        1.0362             nan     0.0100   -0.0000\n",
      "   180        1.0191             nan     0.0100   -0.0004\n",
      "   200        1.0035             nan     0.0100    0.0001\n",
      "   220        0.9890             nan     0.0100   -0.0008\n",
      "   240        0.9748             nan     0.0100   -0.0010\n",
      "   260        0.9617             nan     0.0100   -0.0007\n",
      "   280        0.9490             nan     0.0100   -0.0011\n",
      "   300        0.9382             nan     0.0100   -0.0004\n",
      "   320        0.9268             nan     0.0100   -0.0006\n",
      "   340        0.9159             nan     0.0100   -0.0010\n",
      "   360        0.9061             nan     0.0100   -0.0006\n",
      "   380        0.8955             nan     0.0100   -0.0002\n",
      "   400        0.8852             nan     0.0100   -0.0005\n",
      "   420        0.8761             nan     0.0100   -0.0009\n",
      "   440        0.8669             nan     0.0100   -0.0003\n",
      "   460        0.8578             nan     0.0100   -0.0010\n",
      "   480        0.8494             nan     0.0100   -0.0010\n",
      "   500        0.8414             nan     0.0100   -0.0003\n",
      "   520        0.8335             nan     0.0100   -0.0011\n",
      "   540        0.8253             nan     0.0100   -0.0012\n",
      "   560        0.8174             nan     0.0100   -0.0007\n",
      "   580        0.8099             nan     0.0100   -0.0014\n",
      "   600        0.8028             nan     0.0100   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0085\n",
      "     2        1.3796             nan     0.0100    0.0083\n",
      "     3        1.3719             nan     0.0100    0.0094\n",
      "     4        1.3646             nan     0.0100    0.0084\n",
      "     5        1.3572             nan     0.0100    0.0088\n",
      "     6        1.3499             nan     0.0100    0.0078\n",
      "     7        1.3436             nan     0.0100    0.0068\n",
      "     8        1.3375             nan     0.0100    0.0076\n",
      "     9        1.3309             nan     0.0100    0.0077\n",
      "    10        1.3248             nan     0.0100    0.0069\n",
      "    20        1.2722             nan     0.0100    0.0057\n",
      "    40        1.1902             nan     0.0100    0.0028\n",
      "    60        1.1318             nan     0.0100    0.0015\n",
      "    80        1.0856             nan     0.0100    0.0003\n",
      "   100        1.0466             nan     0.0100    0.0006\n",
      "   120        1.0143             nan     0.0100    0.0002\n",
      "   140        0.9841             nan     0.0100   -0.0005\n",
      "   160        0.9588             nan     0.0100    0.0000\n",
      "   180        0.9354             nan     0.0100   -0.0005\n",
      "   200        0.9137             nan     0.0100   -0.0010\n",
      "   220        0.8940             nan     0.0100   -0.0005\n",
      "   240        0.8748             nan     0.0100   -0.0016\n",
      "   260        0.8574             nan     0.0100   -0.0009\n",
      "   280        0.8403             nan     0.0100   -0.0011\n",
      "   300        0.8240             nan     0.0100   -0.0010\n",
      "   320        0.8073             nan     0.0100   -0.0014\n",
      "   340        0.7925             nan     0.0100   -0.0017\n",
      "   360        0.7778             nan     0.0100   -0.0012\n",
      "   380        0.7636             nan     0.0100   -0.0015\n",
      "   400        0.7499             nan     0.0100   -0.0009\n",
      "   420        0.7366             nan     0.0100   -0.0008\n",
      "   440        0.7236             nan     0.0100   -0.0011\n",
      "   460        0.7117             nan     0.0100   -0.0010\n",
      "   480        0.7014             nan     0.0100   -0.0009\n",
      "   500        0.6899             nan     0.0100   -0.0013\n",
      "   520        0.6792             nan     0.0100   -0.0010\n",
      "   540        0.6677             nan     0.0100   -0.0009\n",
      "   560        0.6572             nan     0.0100   -0.0008\n",
      "   580        0.6469             nan     0.0100   -0.0013\n",
      "   600        0.6369             nan     0.0100   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0571\n",
      "     2        1.3396             nan     0.1000    0.0412\n",
      "     3        1.3048             nan     0.1000    0.0345\n",
      "     4        1.2768             nan     0.1000    0.0331\n",
      "     5        1.2534             nan     0.1000    0.0223\n",
      "     6        1.2333             nan     0.1000    0.0135\n",
      "     7        1.2203             nan     0.1000    0.0151\n",
      "     8        1.2075             nan     0.1000    0.0099\n",
      "     9        1.1960             nan     0.1000    0.0094\n",
      "    10        1.1881             nan     0.1000    0.0044\n",
      "    20        1.1320             nan     0.1000   -0.0011\n",
      "    40        1.0781             nan     0.1000   -0.0027\n",
      "    60        1.0432             nan     0.1000   -0.0085\n",
      "    80        1.0224             nan     0.1000   -0.0057\n",
      "   100        1.0042             nan     0.1000   -0.0049\n",
      "   120        0.9894             nan     0.1000   -0.0049\n",
      "   140        0.9750             nan     0.1000   -0.0074\n",
      "   160        0.9643             nan     0.1000   -0.0055\n",
      "   180        0.9548             nan     0.1000   -0.0092\n",
      "   200        0.9480             nan     0.1000   -0.0074\n",
      "   220        0.9392             nan     0.1000   -0.0046\n",
      "   240        0.9297             nan     0.1000   -0.0073\n",
      "   260        0.9216             nan     0.1000   -0.0084\n",
      "   280        0.9150             nan     0.1000   -0.0063\n",
      "   300        0.9065             nan     0.1000   -0.0065\n",
      "   320        0.8996             nan     0.1000   -0.0098\n",
      "   340        0.8950             nan     0.1000   -0.0058\n",
      "   360        0.8902             nan     0.1000   -0.0055\n",
      "   380        0.8845             nan     0.1000   -0.0085\n",
      "   400        0.8802             nan     0.1000   -0.0079\n",
      "   420        0.8746             nan     0.1000   -0.0072\n",
      "   440        0.8701             nan     0.1000   -0.0067\n",
      "   460        0.8647             nan     0.1000   -0.0079\n",
      "   480        0.8590             nan     0.1000   -0.0068\n",
      "   500        0.8551             nan     0.1000   -0.0052\n",
      "   520        0.8523             nan     0.1000   -0.0091\n",
      "   540        0.8483             nan     0.1000   -0.0052\n",
      "   560        0.8450             nan     0.1000   -0.0064\n",
      "   580        0.8401             nan     0.1000   -0.0061\n",
      "   600        0.8359             nan     0.1000   -0.0073\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0730\n",
      "     2        1.3283             nan     0.1000    0.0485\n",
      "     3        1.2830             nan     0.1000    0.0375\n",
      "     4        1.2447             nan     0.1000    0.0343\n",
      "     5        1.2139             nan     0.1000    0.0278\n",
      "     6        1.1867             nan     0.1000    0.0136\n",
      "     7        1.1668             nan     0.1000    0.0080\n",
      "     8        1.1501             nan     0.1000    0.0065\n",
      "     9        1.1341             nan     0.1000    0.0070\n",
      "    10        1.1183             nan     0.1000    0.0001\n",
      "    20        1.0159             nan     0.1000   -0.0062\n",
      "    40        0.8983             nan     0.1000   -0.0187\n",
      "    60        0.8183             nan     0.1000   -0.0122\n",
      "    80        0.7516             nan     0.1000   -0.0101\n",
      "   100        0.6896             nan     0.1000   -0.0065\n",
      "   120        0.6437             nan     0.1000   -0.0133\n",
      "   140        0.5978             nan     0.1000   -0.0059\n",
      "   160        0.5561             nan     0.1000   -0.0088\n",
      "   180        0.5200             nan     0.1000   -0.0078\n",
      "   200        0.4901             nan     0.1000   -0.0086\n",
      "   220        0.4631             nan     0.1000   -0.0052\n",
      "   240        0.4351             nan     0.1000   -0.0062\n",
      "   260        0.4088             nan     0.1000   -0.0089\n",
      "   280        0.3839             nan     0.1000   -0.0078\n",
      "   300        0.3610             nan     0.1000   -0.0064\n",
      "   320        0.3411             nan     0.1000   -0.0050\n",
      "   340        0.3233             nan     0.1000   -0.0056\n",
      "   360        0.3048             nan     0.1000   -0.0069\n",
      "   380        0.2883             nan     0.1000   -0.0031\n",
      "   400        0.2722             nan     0.1000   -0.0047\n",
      "   420        0.2587             nan     0.1000   -0.0055\n",
      "   440        0.2452             nan     0.1000   -0.0076\n",
      "   460        0.2332             nan     0.1000   -0.0036\n",
      "   480        0.2228             nan     0.1000   -0.0030\n",
      "   500        0.2111             nan     0.1000   -0.0041\n",
      "   520        0.2005             nan     0.1000   -0.0042\n",
      "   540        0.1913             nan     0.1000   -0.0037\n",
      "   560        0.1809             nan     0.1000   -0.0022\n",
      "   580        0.1725             nan     0.1000   -0.0030\n",
      "   600        0.1638             nan     0.1000   -0.0034\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0711\n",
      "     2        1.3206             nan     0.1000    0.0516\n",
      "     3        1.2693             nan     0.1000    0.0409\n",
      "     4        1.2217             nan     0.1000    0.0279\n",
      "     5        1.1826             nan     0.1000    0.0122\n",
      "     6        1.1508             nan     0.1000    0.0224\n",
      "     7        1.1216             nan     0.1000    0.0062\n",
      "     8        1.1021             nan     0.1000   -0.0058\n",
      "     9        1.0817             nan     0.1000    0.0033\n",
      "    10        1.0623             nan     0.1000   -0.0020\n",
      "    20        0.9343             nan     0.1000   -0.0128\n",
      "    40        0.7703             nan     0.1000   -0.0176\n",
      "    60        0.6548             nan     0.1000   -0.0158\n",
      "    80        0.5683             nan     0.1000   -0.0091\n",
      "   100        0.4933             nan     0.1000   -0.0072\n",
      "   120        0.4269             nan     0.1000   -0.0116\n",
      "   140        0.3764             nan     0.1000   -0.0067\n",
      "   160        0.3325             nan     0.1000   -0.0069\n",
      "   180        0.2947             nan     0.1000   -0.0066\n",
      "   200        0.2617             nan     0.1000   -0.0071\n",
      "   220        0.2331             nan     0.1000   -0.0050\n",
      "   240        0.2083             nan     0.1000   -0.0048\n",
      "   260        0.1886             nan     0.1000   -0.0050\n",
      "   280        0.1707             nan     0.1000   -0.0036\n",
      "   300        0.1533             nan     0.1000   -0.0043\n",
      "   320        0.1387             nan     0.1000   -0.0031\n",
      "   340        0.1245             nan     0.1000   -0.0026\n",
      "   360        0.1129             nan     0.1000   -0.0030\n",
      "   380        0.1016             nan     0.1000   -0.0018\n",
      "   400        0.0924             nan     0.1000   -0.0026\n",
      "   420        0.0833             nan     0.1000   -0.0027\n",
      "   440        0.0755             nan     0.1000   -0.0021\n",
      "   460        0.0692             nan     0.1000   -0.0012\n",
      "   480        0.0628             nan     0.1000   -0.0019\n",
      "   500        0.0570             nan     0.1000   -0.0016\n",
      "   520        0.0516             nan     0.1000   -0.0013\n",
      "   540        0.0473             nan     0.1000   -0.0012\n",
      "   560        0.0429             nan     0.1000   -0.0012\n",
      "   580        0.0390             nan     0.1000   -0.0009\n",
      "   600        0.0358             nan     0.1000   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0007\n",
      "     2        1.3858             nan     0.0010    0.0007\n",
      "     3        1.3853             nan     0.0010    0.0007\n",
      "     4        1.3848             nan     0.0010    0.0007\n",
      "     5        1.3842             nan     0.0010    0.0007\n",
      "     6        1.3837             nan     0.0010    0.0007\n",
      "     7        1.3832             nan     0.0010    0.0007\n",
      "     8        1.3827             nan     0.0010    0.0006\n",
      "     9        1.3822             nan     0.0010    0.0007\n",
      "    10        1.3817             nan     0.0010    0.0007\n",
      "    20        1.3770             nan     0.0010    0.0006\n",
      "    40        1.3680             nan     0.0010    0.0006\n",
      "    60        1.3593             nan     0.0010    0.0006\n",
      "    80        1.3511             nan     0.0010    0.0005\n",
      "   100        1.3433             nan     0.0010    0.0006\n",
      "   120        1.3360             nan     0.0010    0.0005\n",
      "   140        1.3288             nan     0.0010    0.0005\n",
      "   160        1.3221             nan     0.0010    0.0005\n",
      "   180        1.3156             nan     0.0010    0.0004\n",
      "   200        1.3093             nan     0.0010    0.0004\n",
      "   220        1.3033             nan     0.0010    0.0004\n",
      "   240        1.2977             nan     0.0010    0.0004\n",
      "   260        1.2922             nan     0.0010    0.0003\n",
      "   280        1.2871             nan     0.0010    0.0003\n",
      "   300        1.2821             nan     0.0010    0.0003\n",
      "   320        1.2774             nan     0.0010    0.0003\n",
      "   340        1.2729             nan     0.0010    0.0003\n",
      "   360        1.2685             nan     0.0010    0.0003\n",
      "   380        1.2642             nan     0.0010    0.0003\n",
      "   400        1.2602             nan     0.0010    0.0003\n",
      "   420        1.2562             nan     0.0010    0.0003\n",
      "   440        1.2524             nan     0.0010    0.0002\n",
      "   460        1.2487             nan     0.0010    0.0002\n",
      "   480        1.2452             nan     0.0010    0.0002\n",
      "   500        1.2418             nan     0.0010    0.0002\n",
      "   520        1.2384             nan     0.0010    0.0002\n",
      "   540        1.2351             nan     0.0010    0.0002\n",
      "   560        1.2320             nan     0.0010    0.0002\n",
      "   580        1.2291             nan     0.0010    0.0002\n",
      "   600        1.2262             nan     0.0010    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0005\n",
      "     2        1.3857             nan     0.0010    0.0009\n",
      "     3        1.3851             nan     0.0010    0.0008\n",
      "     4        1.3844             nan     0.0010    0.0008\n",
      "     5        1.3838             nan     0.0010    0.0009\n",
      "     6        1.3831             nan     0.0010    0.0007\n",
      "     7        1.3825             nan     0.0010    0.0007\n",
      "     8        1.3819             nan     0.0010    0.0008\n",
      "     9        1.3812             nan     0.0010    0.0009\n",
      "    10        1.3806             nan     0.0010    0.0008\n",
      "    20        1.3744             nan     0.0010    0.0009\n",
      "    40        1.3625             nan     0.0010    0.0008\n",
      "    60        1.3514             nan     0.0010    0.0007\n",
      "    80        1.3404             nan     0.0010    0.0006\n",
      "   100        1.3301             nan     0.0010    0.0007\n",
      "   120        1.3201             nan     0.0010    0.0006\n",
      "   140        1.3109             nan     0.0010    0.0006\n",
      "   160        1.3017             nan     0.0010    0.0004\n",
      "   180        1.2931             nan     0.0010    0.0006\n",
      "   200        1.2849             nan     0.0010    0.0004\n",
      "   220        1.2769             nan     0.0010    0.0005\n",
      "   240        1.2692             nan     0.0010    0.0004\n",
      "   260        1.2619             nan     0.0010    0.0005\n",
      "   280        1.2548             nan     0.0010    0.0004\n",
      "   300        1.2478             nan     0.0010    0.0004\n",
      "   320        1.2413             nan     0.0010    0.0003\n",
      "   340        1.2350             nan     0.0010    0.0003\n",
      "   360        1.2288             nan     0.0010    0.0003\n",
      "   380        1.2229             nan     0.0010    0.0004\n",
      "   400        1.2173             nan     0.0010    0.0004\n",
      "   420        1.2117             nan     0.0010    0.0003\n",
      "   440        1.2064             nan     0.0010    0.0003\n",
      "   460        1.2012             nan     0.0010    0.0002\n",
      "   480        1.1962             nan     0.0010    0.0003\n",
      "   500        1.1912             nan     0.0010    0.0003\n",
      "   520        1.1865             nan     0.0010    0.0002\n",
      "   540        1.1819             nan     0.0010    0.0002\n",
      "   560        1.1773             nan     0.0010    0.0003\n",
      "   580        1.1730             nan     0.0010    0.0002\n",
      "   600        1.1687             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0008\n",
      "     2        1.3855             nan     0.0010    0.0010\n",
      "     3        1.3848             nan     0.0010    0.0008\n",
      "     4        1.3841             nan     0.0010    0.0009\n",
      "     5        1.3833             nan     0.0010    0.0008\n",
      "     6        1.3826             nan     0.0010    0.0008\n",
      "     7        1.3819             nan     0.0010    0.0008\n",
      "     8        1.3811             nan     0.0010    0.0009\n",
      "     9        1.3804             nan     0.0010    0.0009\n",
      "    10        1.3796             nan     0.0010    0.0008\n",
      "    20        1.3725             nan     0.0010    0.0009\n",
      "    40        1.3589             nan     0.0010    0.0009\n",
      "    60        1.3457             nan     0.0010    0.0007\n",
      "    80        1.3331             nan     0.0010    0.0008\n",
      "   100        1.3212             nan     0.0010    0.0007\n",
      "   120        1.3097             nan     0.0010    0.0006\n",
      "   140        1.2986             nan     0.0010    0.0006\n",
      "   160        1.2879             nan     0.0010    0.0006\n",
      "   180        1.2779             nan     0.0010    0.0005\n",
      "   200        1.2681             nan     0.0010    0.0005\n",
      "   220        1.2587             nan     0.0010    0.0006\n",
      "   240        1.2494             nan     0.0010    0.0005\n",
      "   260        1.2407             nan     0.0010    0.0004\n",
      "   280        1.2323             nan     0.0010    0.0005\n",
      "   300        1.2240             nan     0.0010    0.0003\n",
      "   320        1.2162             nan     0.0010    0.0004\n",
      "   340        1.2085             nan     0.0010    0.0004\n",
      "   360        1.2013             nan     0.0010    0.0004\n",
      "   380        1.1942             nan     0.0010    0.0003\n",
      "   400        1.1872             nan     0.0010    0.0003\n",
      "   420        1.1805             nan     0.0010    0.0004\n",
      "   440        1.1743             nan     0.0010    0.0003\n",
      "   460        1.1678             nan     0.0010    0.0002\n",
      "   480        1.1616             nan     0.0010    0.0003\n",
      "   500        1.1557             nan     0.0010    0.0002\n",
      "   520        1.1499             nan     0.0010    0.0002\n",
      "   540        1.1443             nan     0.0010    0.0003\n",
      "   560        1.1388             nan     0.0010    0.0002\n",
      "   580        1.1334             nan     0.0010    0.0002\n",
      "   600        1.1283             nan     0.0010    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0073\n",
      "     2        1.3812             nan     0.0100    0.0061\n",
      "     3        1.3768             nan     0.0100    0.0059\n",
      "     4        1.3723             nan     0.0100    0.0065\n",
      "     5        1.3677             nan     0.0100    0.0061\n",
      "     6        1.3636             nan     0.0100    0.0061\n",
      "     7        1.3597             nan     0.0100    0.0061\n",
      "     8        1.3553             nan     0.0100    0.0058\n",
      "     9        1.3511             nan     0.0100    0.0057\n",
      "    10        1.3470             nan     0.0100    0.0057\n",
      "    20        1.3115             nan     0.0100    0.0043\n",
      "    40        1.2614             nan     0.0100    0.0026\n",
      "    60        1.2268             nan     0.0100    0.0011\n",
      "    80        1.2024             nan     0.0100    0.0012\n",
      "   100        1.1838             nan     0.0100    0.0005\n",
      "   120        1.1691             nan     0.0100    0.0000\n",
      "   140        1.1570             nan     0.0100    0.0000\n",
      "   160        1.1468             nan     0.0100   -0.0001\n",
      "   180        1.1380             nan     0.0100   -0.0004\n",
      "   200        1.1310             nan     0.0100    0.0002\n",
      "   220        1.1243             nan     0.0100   -0.0005\n",
      "   240        1.1182             nan     0.0100   -0.0000\n",
      "   260        1.1124             nan     0.0100   -0.0000\n",
      "   280        1.1073             nan     0.0100   -0.0004\n",
      "   300        1.1026             nan     0.0100   -0.0005\n",
      "   320        1.0982             nan     0.0100   -0.0002\n",
      "   340        1.0935             nan     0.0100   -0.0004\n",
      "   360        1.0894             nan     0.0100   -0.0004\n",
      "   380        1.0853             nan     0.0100   -0.0005\n",
      "   400        1.0817             nan     0.0100   -0.0002\n",
      "   420        1.0776             nan     0.0100   -0.0006\n",
      "   440        1.0739             nan     0.0100   -0.0004\n",
      "   460        1.0704             nan     0.0100   -0.0004\n",
      "   480        1.0674             nan     0.0100   -0.0007\n",
      "   500        1.0641             nan     0.0100   -0.0005\n",
      "   520        1.0610             nan     0.0100   -0.0005\n",
      "   540        1.0582             nan     0.0100   -0.0004\n",
      "   560        1.0551             nan     0.0100   -0.0004\n",
      "   580        1.0523             nan     0.0100   -0.0003\n",
      "   600        1.0493             nan     0.0100   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0077\n",
      "     2        1.3807             nan     0.0100    0.0069\n",
      "     3        1.3744             nan     0.0100    0.0094\n",
      "     4        1.3682             nan     0.0100    0.0078\n",
      "     5        1.3618             nan     0.0100    0.0072\n",
      "     6        1.3556             nan     0.0100    0.0075\n",
      "     7        1.3497             nan     0.0100    0.0071\n",
      "     8        1.3438             nan     0.0100    0.0057\n",
      "     9        1.3384             nan     0.0100    0.0059\n",
      "    10        1.3334             nan     0.0100    0.0062\n",
      "    20        1.2865             nan     0.0100    0.0046\n",
      "    40        1.2181             nan     0.0100    0.0042\n",
      "    60        1.1701             nan     0.0100    0.0020\n",
      "    80        1.1336             nan     0.0100    0.0013\n",
      "   100        1.1043             nan     0.0100    0.0004\n",
      "   120        1.0794             nan     0.0100    0.0006\n",
      "   140        1.0581             nan     0.0100   -0.0000\n",
      "   160        1.0397             nan     0.0100   -0.0001\n",
      "   180        1.0225             nan     0.0100    0.0001\n",
      "   200        1.0076             nan     0.0100   -0.0008\n",
      "   220        0.9931             nan     0.0100   -0.0004\n",
      "   240        0.9794             nan     0.0100   -0.0003\n",
      "   260        0.9671             nan     0.0100   -0.0004\n",
      "   280        0.9556             nan     0.0100   -0.0011\n",
      "   300        0.9431             nan     0.0100   -0.0008\n",
      "   320        0.9326             nan     0.0100   -0.0006\n",
      "   340        0.9221             nan     0.0100   -0.0011\n",
      "   360        0.9117             nan     0.0100   -0.0007\n",
      "   380        0.9024             nan     0.0100   -0.0007\n",
      "   400        0.8923             nan     0.0100   -0.0009\n",
      "   420        0.8834             nan     0.0100   -0.0006\n",
      "   440        0.8746             nan     0.0100   -0.0009\n",
      "   460        0.8660             nan     0.0100   -0.0012\n",
      "   480        0.8565             nan     0.0100   -0.0014\n",
      "   500        0.8474             nan     0.0100   -0.0014\n",
      "   520        0.8391             nan     0.0100   -0.0005\n",
      "   540        0.8318             nan     0.0100   -0.0011\n",
      "   560        0.8241             nan     0.0100   -0.0013\n",
      "   580        0.8172             nan     0.0100   -0.0008\n",
      "   600        0.8098             nan     0.0100   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0074\n",
      "     2        1.3797             nan     0.0100    0.0084\n",
      "     3        1.3722             nan     0.0100    0.0091\n",
      "     4        1.3647             nan     0.0100    0.0083\n",
      "     5        1.3579             nan     0.0100    0.0070\n",
      "     6        1.3513             nan     0.0100    0.0069\n",
      "     7        1.3452             nan     0.0100    0.0074\n",
      "     8        1.3386             nan     0.0100    0.0084\n",
      "     9        1.3320             nan     0.0100    0.0067\n",
      "    10        1.3260             nan     0.0100    0.0065\n",
      "    20        1.2707             nan     0.0100    0.0043\n",
      "    40        1.1904             nan     0.0100    0.0030\n",
      "    60        1.1315             nan     0.0100    0.0023\n",
      "    80        1.0852             nan     0.0100    0.0012\n",
      "   100        1.0467             nan     0.0100    0.0006\n",
      "   120        1.0145             nan     0.0100   -0.0005\n",
      "   140        0.9870             nan     0.0100   -0.0002\n",
      "   160        0.9620             nan     0.0100    0.0003\n",
      "   180        0.9380             nan     0.0100   -0.0009\n",
      "   200        0.9176             nan     0.0100   -0.0012\n",
      "   220        0.8988             nan     0.0100   -0.0009\n",
      "   240        0.8805             nan     0.0100   -0.0004\n",
      "   260        0.8632             nan     0.0100   -0.0013\n",
      "   280        0.8472             nan     0.0100   -0.0011\n",
      "   300        0.8324             nan     0.0100   -0.0004\n",
      "   320        0.8170             nan     0.0100   -0.0012\n",
      "   340        0.8030             nan     0.0100   -0.0012\n",
      "   360        0.7886             nan     0.0100   -0.0013\n",
      "   380        0.7751             nan     0.0100   -0.0011\n",
      "   400        0.7619             nan     0.0100   -0.0012\n",
      "   420        0.7491             nan     0.0100   -0.0006\n",
      "   440        0.7365             nan     0.0100   -0.0006\n",
      "   460        0.7232             nan     0.0100   -0.0010\n",
      "   480        0.7111             nan     0.0100   -0.0009\n",
      "   500        0.6998             nan     0.0100   -0.0012\n",
      "   520        0.6887             nan     0.0100   -0.0011\n",
      "   540        0.6774             nan     0.0100   -0.0010\n",
      "   560        0.6668             nan     0.0100   -0.0016\n",
      "   580        0.6566             nan     0.0100   -0.0018\n",
      "   600        0.6472             nan     0.0100   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0575\n",
      "     2        1.3448             nan     0.1000    0.0471\n",
      "     3        1.3088             nan     0.1000    0.0324\n",
      "     4        1.2838             nan     0.1000    0.0308\n",
      "     5        1.2584             nan     0.1000    0.0147\n",
      "     6        1.2419             nan     0.1000    0.0203\n",
      "     7        1.2252             nan     0.1000    0.0092\n",
      "     8        1.2140             nan     0.1000    0.0148\n",
      "     9        1.2013             nan     0.1000    0.0080\n",
      "    10        1.1922             nan     0.1000    0.0020\n",
      "    20        1.1321             nan     0.1000   -0.0017\n",
      "    40        1.0826             nan     0.1000   -0.0043\n",
      "    60        1.0531             nan     0.1000   -0.0053\n",
      "    80        1.0257             nan     0.1000   -0.0096\n",
      "   100        1.0067             nan     0.1000   -0.0054\n",
      "   120        0.9900             nan     0.1000   -0.0072\n",
      "   140        0.9770             nan     0.1000   -0.0042\n",
      "   160        0.9651             nan     0.1000   -0.0064\n",
      "   180        0.9543             nan     0.1000   -0.0046\n",
      "   200        0.9455             nan     0.1000   -0.0045\n",
      "   220        0.9353             nan     0.1000   -0.0068\n",
      "   240        0.9279             nan     0.1000   -0.0067\n",
      "   260        0.9212             nan     0.1000   -0.0115\n",
      "   280        0.9161             nan     0.1000   -0.0105\n",
      "   300        0.9087             nan     0.1000   -0.0087\n",
      "   320        0.9029             nan     0.1000   -0.0057\n",
      "   340        0.8978             nan     0.1000   -0.0064\n",
      "   360        0.8934             nan     0.1000   -0.0103\n",
      "   380        0.8876             nan     0.1000   -0.0084\n",
      "   400        0.8824             nan     0.1000   -0.0068\n",
      "   420        0.8768             nan     0.1000   -0.0054\n",
      "   440        0.8725             nan     0.1000   -0.0081\n",
      "   460        0.8688             nan     0.1000   -0.0090\n",
      "   480        0.8620             nan     0.1000   -0.0070\n",
      "   500        0.8578             nan     0.1000   -0.0069\n",
      "   520        0.8540             nan     0.1000   -0.0068\n",
      "   540        0.8484             nan     0.1000   -0.0110\n",
      "   560        0.8447             nan     0.1000   -0.0053\n",
      "   580        0.8415             nan     0.1000   -0.0062\n",
      "   600        0.8395             nan     0.1000   -0.0067\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0718\n",
      "     2        1.3234             nan     0.1000    0.0595\n",
      "     3        1.2727             nan     0.1000    0.0388\n",
      "     4        1.2378             nan     0.1000    0.0147\n",
      "     5        1.2129             nan     0.1000    0.0221\n",
      "     6        1.1885             nan     0.1000    0.0184\n",
      "     7        1.1661             nan     0.1000    0.0211\n",
      "     8        1.1441             nan     0.1000    0.0090\n",
      "     9        1.1272             nan     0.1000    0.0091\n",
      "    10        1.1115             nan     0.1000    0.0021\n",
      "    20        1.0176             nan     0.1000   -0.0040\n",
      "    40        0.9018             nan     0.1000   -0.0093\n",
      "    60        0.8270             nan     0.1000   -0.0101\n",
      "    80        0.7576             nan     0.1000   -0.0134\n",
      "   100        0.6993             nan     0.1000   -0.0109\n",
      "   120        0.6485             nan     0.1000   -0.0100\n",
      "   140        0.6030             nan     0.1000   -0.0101\n",
      "   160        0.5634             nan     0.1000   -0.0076\n",
      "   180        0.5271             nan     0.1000   -0.0074\n",
      "   200        0.4949             nan     0.1000   -0.0069\n",
      "   220        0.4638             nan     0.1000   -0.0050\n",
      "   240        0.4359             nan     0.1000   -0.0099\n",
      "   260        0.4105             nan     0.1000   -0.0071\n",
      "   280        0.3900             nan     0.1000   -0.0054\n",
      "   300        0.3675             nan     0.1000   -0.0067\n",
      "   320        0.3495             nan     0.1000   -0.0066\n",
      "   340        0.3317             nan     0.1000   -0.0049\n",
      "   360        0.3138             nan     0.1000   -0.0077\n",
      "   380        0.2961             nan     0.1000   -0.0047\n",
      "   400        0.2804             nan     0.1000   -0.0034\n",
      "   420        0.2662             nan     0.1000   -0.0040\n",
      "   440        0.2528             nan     0.1000   -0.0052\n",
      "   460        0.2409             nan     0.1000   -0.0036\n",
      "   480        0.2301             nan     0.1000   -0.0056\n",
      "   500        0.2194             nan     0.1000   -0.0038\n",
      "   520        0.2099             nan     0.1000   -0.0046\n",
      "   540        0.2003             nan     0.1000   -0.0053\n",
      "   560        0.1921             nan     0.1000   -0.0034\n",
      "   580        0.1829             nan     0.1000   -0.0044\n",
      "   600        0.1755             nan     0.1000   -0.0030\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0597\n",
      "     2        1.3238             nan     0.1000    0.0653\n",
      "     3        1.2697             nan     0.1000    0.0470\n",
      "     4        1.2237             nan     0.1000    0.0370\n",
      "     5        1.1871             nan     0.1000    0.0254\n",
      "     6        1.1568             nan     0.1000    0.0032\n",
      "     7        1.1324             nan     0.1000    0.0139\n",
      "     8        1.1074             nan     0.1000    0.0123\n",
      "     9        1.0864             nan     0.1000    0.0075\n",
      "    10        1.0664             nan     0.1000   -0.0109\n",
      "    20        0.9365             nan     0.1000   -0.0150\n",
      "    40        0.7827             nan     0.1000   -0.0206\n",
      "    60        0.6653             nan     0.1000   -0.0158\n",
      "    80        0.5786             nan     0.1000   -0.0085\n",
      "   100        0.5069             nan     0.1000   -0.0118\n",
      "   120        0.4489             nan     0.1000   -0.0089\n",
      "   140        0.3978             nan     0.1000   -0.0088\n",
      "   160        0.3548             nan     0.1000   -0.0106\n",
      "   180        0.3156             nan     0.1000   -0.0068\n",
      "   200        0.2829             nan     0.1000   -0.0065\n",
      "   220        0.2539             nan     0.1000   -0.0065\n",
      "   240        0.2299             nan     0.1000   -0.0042\n",
      "   260        0.2082             nan     0.1000   -0.0035\n",
      "   280        0.1879             nan     0.1000   -0.0044\n",
      "   300        0.1681             nan     0.1000   -0.0024\n",
      "   320        0.1516             nan     0.1000   -0.0031\n",
      "   340        0.1365             nan     0.1000   -0.0038\n",
      "   360        0.1250             nan     0.1000   -0.0032\n",
      "   380        0.1127             nan     0.1000   -0.0025\n",
      "   400        0.1021             nan     0.1000   -0.0021\n",
      "   420        0.0924             nan     0.1000   -0.0029\n",
      "   440        0.0843             nan     0.1000   -0.0018\n",
      "   460        0.0762             nan     0.1000   -0.0017\n",
      "   480        0.0699             nan     0.1000   -0.0012\n",
      "   500        0.0637             nan     0.1000   -0.0014\n",
      "   520        0.0581             nan     0.1000   -0.0010\n",
      "   540        0.0527             nan     0.1000   -0.0019\n",
      "   560        0.0478             nan     0.1000   -0.0010\n",
      "   580        0.0435             nan     0.1000   -0.0011\n",
      "   600        0.0393             nan     0.1000   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0007\n",
      "     2        1.3858             nan     0.0010    0.0007\n",
      "     3        1.3853             nan     0.0010    0.0007\n",
      "     4        1.3848             nan     0.0010    0.0007\n",
      "     5        1.3843             nan     0.0010    0.0007\n",
      "     6        1.3838             nan     0.0010    0.0007\n",
      "     7        1.3834             nan     0.0010    0.0007\n",
      "     8        1.3828             nan     0.0010    0.0007\n",
      "     9        1.3823             nan     0.0010    0.0006\n",
      "    10        1.3819             nan     0.0010    0.0007\n",
      "    20        1.3772             nan     0.0010    0.0007\n",
      "    40        1.3680             nan     0.0010    0.0006\n",
      "    60        1.3595             nan     0.0010    0.0006\n",
      "    80        1.3513             nan     0.0010    0.0005\n",
      "   100        1.3432             nan     0.0010    0.0005\n",
      "   120        1.3358             nan     0.0010    0.0005\n",
      "   140        1.3286             nan     0.0010    0.0005\n",
      "   160        1.3219             nan     0.0010    0.0004\n",
      "   180        1.3153             nan     0.0010    0.0004\n",
      "   200        1.3092             nan     0.0010    0.0004\n",
      "   220        1.3032             nan     0.0010    0.0004\n",
      "   240        1.2976             nan     0.0010    0.0004\n",
      "   260        1.2921             nan     0.0010    0.0003\n",
      "   280        1.2869             nan     0.0010    0.0003\n",
      "   300        1.2820             nan     0.0010    0.0002\n",
      "   320        1.2771             nan     0.0010    0.0003\n",
      "   340        1.2727             nan     0.0010    0.0003\n",
      "   360        1.2685             nan     0.0010    0.0003\n",
      "   380        1.2644             nan     0.0010    0.0002\n",
      "   400        1.2604             nan     0.0010    0.0003\n",
      "   420        1.2564             nan     0.0010    0.0002\n",
      "   440        1.2526             nan     0.0010    0.0002\n",
      "   460        1.2489             nan     0.0010    0.0003\n",
      "   480        1.2454             nan     0.0010    0.0002\n",
      "   500        1.2420             nan     0.0010    0.0002\n",
      "   520        1.2388             nan     0.0010    0.0002\n",
      "   540        1.2358             nan     0.0010    0.0002\n",
      "   560        1.2328             nan     0.0010    0.0002\n",
      "   580        1.2298             nan     0.0010    0.0002\n",
      "   600        1.2269             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0008\n",
      "     2        1.3857             nan     0.0010    0.0008\n",
      "     3        1.3851             nan     0.0010    0.0007\n",
      "     4        1.3845             nan     0.0010    0.0008\n",
      "     5        1.3839             nan     0.0010    0.0008\n",
      "     6        1.3833             nan     0.0010    0.0008\n",
      "     7        1.3826             nan     0.0010    0.0008\n",
      "     8        1.3820             nan     0.0010    0.0008\n",
      "     9        1.3813             nan     0.0010    0.0008\n",
      "    10        1.3807             nan     0.0010    0.0009\n",
      "    20        1.3744             nan     0.0010    0.0008\n",
      "    40        1.3626             nan     0.0010    0.0007\n",
      "    60        1.3512             nan     0.0010    0.0006\n",
      "    80        1.3404             nan     0.0010    0.0007\n",
      "   100        1.3301             nan     0.0010    0.0007\n",
      "   120        1.3202             nan     0.0010    0.0005\n",
      "   140        1.3106             nan     0.0010    0.0006\n",
      "   160        1.3015             nan     0.0010    0.0005\n",
      "   180        1.2928             nan     0.0010    0.0005\n",
      "   200        1.2845             nan     0.0010    0.0005\n",
      "   220        1.2764             nan     0.0010    0.0005\n",
      "   240        1.2687             nan     0.0010    0.0004\n",
      "   260        1.2614             nan     0.0010    0.0004\n",
      "   280        1.2545             nan     0.0010    0.0004\n",
      "   300        1.2477             nan     0.0010    0.0004\n",
      "   320        1.2411             nan     0.0010    0.0003\n",
      "   340        1.2348             nan     0.0010    0.0003\n",
      "   360        1.2287             nan     0.0010    0.0003\n",
      "   380        1.2229             nan     0.0010    0.0002\n",
      "   400        1.2174             nan     0.0010    0.0002\n",
      "   420        1.2119             nan     0.0010    0.0003\n",
      "   440        1.2066             nan     0.0010    0.0002\n",
      "   460        1.2015             nan     0.0010    0.0002\n",
      "   480        1.1966             nan     0.0010    0.0003\n",
      "   500        1.1918             nan     0.0010    0.0002\n",
      "   520        1.1872             nan     0.0010    0.0002\n",
      "   540        1.1825             nan     0.0010    0.0002\n",
      "   560        1.1782             nan     0.0010    0.0001\n",
      "   580        1.1739             nan     0.0010    0.0002\n",
      "   600        1.1699             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0008\n",
      "     2        1.3856             nan     0.0010    0.0009\n",
      "     3        1.3848             nan     0.0010    0.0010\n",
      "     4        1.3841             nan     0.0010    0.0009\n",
      "     5        1.3833             nan     0.0010    0.0010\n",
      "     6        1.3825             nan     0.0010    0.0010\n",
      "     7        1.3818             nan     0.0010    0.0008\n",
      "     8        1.3810             nan     0.0010    0.0008\n",
      "     9        1.3803             nan     0.0010    0.0010\n",
      "    10        1.3795             nan     0.0010    0.0010\n",
      "    20        1.3722             nan     0.0010    0.0009\n",
      "    40        1.3585             nan     0.0010    0.0009\n",
      "    60        1.3458             nan     0.0010    0.0007\n",
      "    80        1.3332             nan     0.0010    0.0007\n",
      "   100        1.3211             nan     0.0010    0.0006\n",
      "   120        1.3096             nan     0.0010    0.0006\n",
      "   140        1.2987             nan     0.0010    0.0006\n",
      "   160        1.2884             nan     0.0010    0.0006\n",
      "   180        1.2783             nan     0.0010    0.0005\n",
      "   200        1.2687             nan     0.0010    0.0005\n",
      "   220        1.2594             nan     0.0010    0.0005\n",
      "   240        1.2504             nan     0.0010    0.0005\n",
      "   260        1.2416             nan     0.0010    0.0005\n",
      "   280        1.2334             nan     0.0010    0.0004\n",
      "   300        1.2254             nan     0.0010    0.0004\n",
      "   320        1.2177             nan     0.0010    0.0004\n",
      "   340        1.2102             nan     0.0010    0.0004\n",
      "   360        1.2031             nan     0.0010    0.0004\n",
      "   380        1.1961             nan     0.0010    0.0003\n",
      "   400        1.1894             nan     0.0010    0.0002\n",
      "   420        1.1826             nan     0.0010    0.0002\n",
      "   440        1.1765             nan     0.0010    0.0002\n",
      "   460        1.1703             nan     0.0010    0.0002\n",
      "   480        1.1642             nan     0.0010    0.0002\n",
      "   500        1.1583             nan     0.0010    0.0003\n",
      "   520        1.1527             nan     0.0010    0.0002\n",
      "   540        1.1471             nan     0.0010    0.0002\n",
      "   560        1.1418             nan     0.0010    0.0001\n",
      "   580        1.1365             nan     0.0010    0.0003\n",
      "   600        1.1313             nan     0.0010    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0074\n",
      "     2        1.3814             nan     0.0100    0.0072\n",
      "     3        1.3764             nan     0.0100    0.0064\n",
      "     4        1.3721             nan     0.0100    0.0061\n",
      "     5        1.3675             nan     0.0100    0.0055\n",
      "     6        1.3633             nan     0.0100    0.0059\n",
      "     7        1.3585             nan     0.0100    0.0061\n",
      "     8        1.3543             nan     0.0100    0.0064\n",
      "     9        1.3503             nan     0.0100    0.0054\n",
      "    10        1.3468             nan     0.0100    0.0060\n",
      "    20        1.3118             nan     0.0100    0.0040\n",
      "    40        1.2612             nan     0.0100    0.0026\n",
      "    60        1.2272             nan     0.0100    0.0013\n",
      "    80        1.2021             nan     0.0100    0.0008\n",
      "   100        1.1842             nan     0.0100    0.0004\n",
      "   120        1.1689             nan     0.0100    0.0002\n",
      "   140        1.1570             nan     0.0100   -0.0004\n",
      "   160        1.1476             nan     0.0100   -0.0000\n",
      "   180        1.1392             nan     0.0100   -0.0002\n",
      "   200        1.1318             nan     0.0100   -0.0002\n",
      "   220        1.1247             nan     0.0100   -0.0000\n",
      "   240        1.1186             nan     0.0100   -0.0004\n",
      "   260        1.1132             nan     0.0100   -0.0005\n",
      "   280        1.1080             nan     0.0100   -0.0003\n",
      "   300        1.1031             nan     0.0100   -0.0003\n",
      "   320        1.0988             nan     0.0100   -0.0002\n",
      "   340        1.0945             nan     0.0100   -0.0005\n",
      "   360        1.0903             nan     0.0100   -0.0006\n",
      "   380        1.0862             nan     0.0100   -0.0004\n",
      "   400        1.0821             nan     0.0100   -0.0005\n",
      "   420        1.0782             nan     0.0100   -0.0006\n",
      "   440        1.0748             nan     0.0100   -0.0003\n",
      "   460        1.0716             nan     0.0100   -0.0007\n",
      "   480        1.0684             nan     0.0100   -0.0003\n",
      "   500        1.0653             nan     0.0100   -0.0005\n",
      "   520        1.0622             nan     0.0100   -0.0009\n",
      "   540        1.0593             nan     0.0100   -0.0003\n",
      "   560        1.0566             nan     0.0100   -0.0008\n",
      "   580        1.0539             nan     0.0100   -0.0005\n",
      "   600        1.0512             nan     0.0100   -0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0087\n",
      "     2        1.3795             nan     0.0100    0.0091\n",
      "     3        1.3730             nan     0.0100    0.0081\n",
      "     4        1.3668             nan     0.0100    0.0074\n",
      "     5        1.3613             nan     0.0100    0.0075\n",
      "     6        1.3556             nan     0.0100    0.0070\n",
      "     7        1.3496             nan     0.0100    0.0063\n",
      "     8        1.3448             nan     0.0100    0.0069\n",
      "     9        1.3391             nan     0.0100    0.0070\n",
      "    10        1.3337             nan     0.0100    0.0060\n",
      "    20        1.2881             nan     0.0100    0.0049\n",
      "    40        1.2205             nan     0.0100    0.0039\n",
      "    60        1.1709             nan     0.0100    0.0013\n",
      "    80        1.1339             nan     0.0100    0.0014\n",
      "   100        1.1052             nan     0.0100    0.0003\n",
      "   120        1.0812             nan     0.0100    0.0001\n",
      "   140        1.0602             nan     0.0100   -0.0002\n",
      "   160        1.0427             nan     0.0100   -0.0006\n",
      "   180        1.0261             nan     0.0100   -0.0008\n",
      "   200        1.0099             nan     0.0100   -0.0006\n",
      "   220        0.9960             nan     0.0100   -0.0004\n",
      "   240        0.9824             nan     0.0100   -0.0006\n",
      "   260        0.9694             nan     0.0100   -0.0005\n",
      "   280        0.9582             nan     0.0100   -0.0008\n",
      "   300        0.9466             nan     0.0100   -0.0008\n",
      "   320        0.9352             nan     0.0100   -0.0009\n",
      "   340        0.9241             nan     0.0100   -0.0007\n",
      "   360        0.9131             nan     0.0100   -0.0010\n",
      "   380        0.9033             nan     0.0100   -0.0012\n",
      "   400        0.8940             nan     0.0100   -0.0006\n",
      "   420        0.8853             nan     0.0100   -0.0010\n",
      "   440        0.8762             nan     0.0100   -0.0014\n",
      "   460        0.8673             nan     0.0100   -0.0011\n",
      "   480        0.8590             nan     0.0100   -0.0012\n",
      "   500        0.8508             nan     0.0100   -0.0004\n",
      "   520        0.8426             nan     0.0100   -0.0009\n",
      "   540        0.8343             nan     0.0100   -0.0015\n",
      "   560        0.8268             nan     0.0100   -0.0009\n",
      "   580        0.8192             nan     0.0100   -0.0016\n",
      "   600        0.8113             nan     0.0100   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0090\n",
      "     2        1.3790             nan     0.0100    0.0066\n",
      "     3        1.3732             nan     0.0100    0.0074\n",
      "     4        1.3653             nan     0.0100    0.0079\n",
      "     5        1.3582             nan     0.0100    0.0069\n",
      "     6        1.3515             nan     0.0100    0.0076\n",
      "     7        1.3452             nan     0.0100    0.0064\n",
      "     8        1.3390             nan     0.0100    0.0070\n",
      "     9        1.3328             nan     0.0100    0.0076\n",
      "    10        1.3269             nan     0.0100    0.0061\n",
      "    20        1.2713             nan     0.0100    0.0064\n",
      "    40        1.1911             nan     0.0100    0.0029\n",
      "    60        1.1323             nan     0.0100    0.0023\n",
      "    80        1.0861             nan     0.0100    0.0004\n",
      "   100        1.0482             nan     0.0100   -0.0000\n",
      "   120        1.0156             nan     0.0100   -0.0004\n",
      "   140        0.9881             nan     0.0100   -0.0005\n",
      "   160        0.9626             nan     0.0100   -0.0000\n",
      "   180        0.9387             nan     0.0100   -0.0014\n",
      "   200        0.9178             nan     0.0100   -0.0006\n",
      "   220        0.8993             nan     0.0100   -0.0010\n",
      "   240        0.8808             nan     0.0100   -0.0009\n",
      "   260        0.8622             nan     0.0100   -0.0009\n",
      "   280        0.8450             nan     0.0100   -0.0008\n",
      "   300        0.8291             nan     0.0100   -0.0006\n",
      "   320        0.8138             nan     0.0100   -0.0010\n",
      "   340        0.7981             nan     0.0100   -0.0008\n",
      "   360        0.7844             nan     0.0100   -0.0007\n",
      "   380        0.7709             nan     0.0100   -0.0009\n",
      "   400        0.7577             nan     0.0100   -0.0006\n",
      "   420        0.7451             nan     0.0100   -0.0014\n",
      "   440        0.7328             nan     0.0100   -0.0008\n",
      "   460        0.7210             nan     0.0100   -0.0012\n",
      "   480        0.7101             nan     0.0100   -0.0008\n",
      "   500        0.6986             nan     0.0100   -0.0012\n",
      "   520        0.6868             nan     0.0100   -0.0012\n",
      "   540        0.6756             nan     0.0100   -0.0010\n",
      "   560        0.6651             nan     0.0100   -0.0008\n",
      "   580        0.6551             nan     0.0100   -0.0012\n",
      "   600        0.6457             nan     0.0100   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0610\n",
      "     2        1.3397             nan     0.1000    0.0493\n",
      "     3        1.3015             nan     0.1000    0.0264\n",
      "     4        1.2746             nan     0.1000    0.0305\n",
      "     5        1.2558             nan     0.1000    0.0229\n",
      "     6        1.2367             nan     0.1000    0.0163\n",
      "     7        1.2209             nan     0.1000    0.0134\n",
      "     8        1.2080             nan     0.1000    0.0062\n",
      "     9        1.1978             nan     0.1000    0.0056\n",
      "    10        1.1880             nan     0.1000    0.0068\n",
      "    20        1.1327             nan     0.1000    0.0004\n",
      "    40        1.0852             nan     0.1000   -0.0086\n",
      "    60        1.0518             nan     0.1000   -0.0065\n",
      "    80        1.0295             nan     0.1000   -0.0076\n",
      "   100        1.0104             nan     0.1000   -0.0058\n",
      "   120        0.9938             nan     0.1000   -0.0060\n",
      "   140        0.9786             nan     0.1000   -0.0076\n",
      "   160        0.9685             nan     0.1000   -0.0065\n",
      "   180        0.9571             nan     0.1000   -0.0067\n",
      "   200        0.9472             nan     0.1000   -0.0065\n",
      "   220        0.9397             nan     0.1000   -0.0062\n",
      "   240        0.9318             nan     0.1000   -0.0099\n",
      "   260        0.9240             nan     0.1000   -0.0055\n",
      "   280        0.9168             nan     0.1000   -0.0115\n",
      "   300        0.9093             nan     0.1000   -0.0072\n",
      "   320        0.9032             nan     0.1000   -0.0086\n",
      "   340        0.8991             nan     0.1000   -0.0052\n",
      "   360        0.8928             nan     0.1000   -0.0061\n",
      "   380        0.8884             nan     0.1000   -0.0087\n",
      "   400        0.8818             nan     0.1000   -0.0067\n",
      "   420        0.8760             nan     0.1000   -0.0079\n",
      "   440        0.8722             nan     0.1000   -0.0064\n",
      "   460        0.8663             nan     0.1000   -0.0068\n",
      "   480        0.8627             nan     0.1000   -0.0050\n",
      "   500        0.8577             nan     0.1000   -0.0066\n",
      "   520        0.8543             nan     0.1000   -0.0087\n",
      "   540        0.8484             nan     0.1000   -0.0077\n",
      "   560        0.8438             nan     0.1000   -0.0067\n",
      "   580        0.8399             nan     0.1000   -0.0105\n",
      "   600        0.8382             nan     0.1000   -0.0059\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0628\n",
      "     2        1.3308             nan     0.1000    0.0537\n",
      "     3        1.2837             nan     0.1000    0.0378\n",
      "     4        1.2448             nan     0.1000    0.0227\n",
      "     5        1.2192             nan     0.1000    0.0211\n",
      "     6        1.1957             nan     0.1000    0.0144\n",
      "     7        1.1743             nan     0.1000    0.0162\n",
      "     8        1.1520             nan     0.1000    0.0143\n",
      "     9        1.1340             nan     0.1000    0.0076\n",
      "    10        1.1205             nan     0.1000    0.0025\n",
      "    20        1.0206             nan     0.1000   -0.0059\n",
      "    40        0.9067             nan     0.1000   -0.0143\n",
      "    60        0.8162             nan     0.1000   -0.0105\n",
      "    80        0.7549             nan     0.1000   -0.0118\n",
      "   100        0.6975             nan     0.1000   -0.0136\n",
      "   120        0.6503             nan     0.1000   -0.0102\n",
      "   140        0.6037             nan     0.1000   -0.0108\n",
      "   160        0.5641             nan     0.1000   -0.0103\n",
      "   180        0.5278             nan     0.1000   -0.0064\n",
      "   200        0.4955             nan     0.1000   -0.0070\n",
      "   220        0.4687             nan     0.1000   -0.0076\n",
      "   240        0.4407             nan     0.1000   -0.0050\n",
      "   260        0.4160             nan     0.1000   -0.0087\n",
      "   280        0.3945             nan     0.1000   -0.0068\n",
      "   300        0.3726             nan     0.1000   -0.0072\n",
      "   320        0.3515             nan     0.1000   -0.0066\n",
      "   340        0.3312             nan     0.1000   -0.0094\n",
      "   360        0.3132             nan     0.1000   -0.0059\n",
      "   380        0.2984             nan     0.1000   -0.0074\n",
      "   400        0.2823             nan     0.1000   -0.0039\n",
      "   420        0.2681             nan     0.1000   -0.0051\n",
      "   440        0.2557             nan     0.1000   -0.0029\n",
      "   460        0.2414             nan     0.1000   -0.0037\n",
      "   480        0.2298             nan     0.1000   -0.0034\n",
      "   500        0.2172             nan     0.1000   -0.0028\n",
      "   520        0.2058             nan     0.1000   -0.0030\n",
      "   540        0.1951             nan     0.1000   -0.0028\n",
      "   560        0.1857             nan     0.1000   -0.0043\n",
      "   580        0.1761             nan     0.1000   -0.0039\n",
      "   600        0.1676             nan     0.1000   -0.0031\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0623\n",
      "     2        1.3194             nan     0.1000    0.0415\n",
      "     3        1.2660             nan     0.1000    0.0370\n",
      "     4        1.2226             nan     0.1000    0.0286\n",
      "     5        1.1886             nan     0.1000    0.0171\n",
      "     6        1.1595             nan     0.1000    0.0190\n",
      "     7        1.1342             nan     0.1000    0.0051\n",
      "     8        1.1119             nan     0.1000    0.0024\n",
      "     9        1.0889             nan     0.1000    0.0005\n",
      "    10        1.0718             nan     0.1000   -0.0021\n",
      "    20        0.9409             nan     0.1000   -0.0100\n",
      "    40        0.7708             nan     0.1000   -0.0119\n",
      "    60        0.6542             nan     0.1000   -0.0150\n",
      "    80        0.5659             nan     0.1000   -0.0106\n",
      "   100        0.4969             nan     0.1000   -0.0139\n",
      "   120        0.4386             nan     0.1000   -0.0111\n",
      "   140        0.3892             nan     0.1000   -0.0073\n",
      "   160        0.3425             nan     0.1000   -0.0065\n",
      "   180        0.3059             nan     0.1000   -0.0061\n",
      "   200        0.2721             nan     0.1000   -0.0045\n",
      "   220        0.2424             nan     0.1000   -0.0079\n",
      "   240        0.2183             nan     0.1000   -0.0068\n",
      "   260        0.1959             nan     0.1000   -0.0057\n",
      "   280        0.1760             nan     0.1000   -0.0034\n",
      "   300        0.1590             nan     0.1000   -0.0039\n",
      "   320        0.1441             nan     0.1000   -0.0032\n",
      "   340        0.1300             nan     0.1000   -0.0034\n",
      "   360        0.1175             nan     0.1000   -0.0019\n",
      "   380        0.1058             nan     0.1000   -0.0020\n",
      "   400        0.0952             nan     0.1000   -0.0025\n",
      "   420        0.0860             nan     0.1000   -0.0009\n",
      "   440        0.0785             nan     0.1000   -0.0014\n",
      "   460        0.0713             nan     0.1000   -0.0021\n",
      "   480        0.0651             nan     0.1000   -0.0016\n",
      "   500        0.0592             nan     0.1000   -0.0013\n",
      "   520        0.0545             nan     0.1000   -0.0011\n",
      "   540        0.0495             nan     0.1000   -0.0008\n",
      "   560        0.0451             nan     0.1000   -0.0008\n",
      "   580        0.0411             nan     0.1000   -0.0008\n",
      "   600        0.0378             nan     0.1000   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0007\n",
      "     2        1.3858             nan     0.0010    0.0007\n",
      "     3        1.3854             nan     0.0010    0.0007\n",
      "     4        1.3849             nan     0.0010    0.0007\n",
      "     5        1.3844             nan     0.0010    0.0007\n",
      "     6        1.3839             nan     0.0010    0.0007\n",
      "     7        1.3835             nan     0.0010    0.0007\n",
      "     8        1.3830             nan     0.0010    0.0006\n",
      "     9        1.3825             nan     0.0010    0.0007\n",
      "    10        1.3820             nan     0.0010    0.0007\n",
      "    20        1.3771             nan     0.0010    0.0007\n",
      "    40        1.3680             nan     0.0010    0.0007\n",
      "    60        1.3593             nan     0.0010    0.0006\n",
      "    80        1.3511             nan     0.0010    0.0006\n",
      "   100        1.3434             nan     0.0010    0.0006\n",
      "   120        1.3359             nan     0.0010    0.0005\n",
      "   140        1.3287             nan     0.0010    0.0005\n",
      "   160        1.3218             nan     0.0010    0.0005\n",
      "   180        1.3153             nan     0.0010    0.0004\n",
      "   200        1.3093             nan     0.0010    0.0004\n",
      "   220        1.3033             nan     0.0010    0.0004\n",
      "   240        1.2977             nan     0.0010    0.0004\n",
      "   260        1.2924             nan     0.0010    0.0003\n",
      "   280        1.2873             nan     0.0010    0.0003\n",
      "   300        1.2822             nan     0.0010    0.0003\n",
      "   320        1.2773             nan     0.0010    0.0003\n",
      "   340        1.2729             nan     0.0010    0.0003\n",
      "   360        1.2684             nan     0.0010    0.0003\n",
      "   380        1.2641             nan     0.0010    0.0003\n",
      "   400        1.2601             nan     0.0010    0.0003\n",
      "   420        1.2563             nan     0.0010    0.0003\n",
      "   440        1.2524             nan     0.0010    0.0003\n",
      "   460        1.2488             nan     0.0010    0.0002\n",
      "   480        1.2453             nan     0.0010    0.0002\n",
      "   500        1.2420             nan     0.0010    0.0002\n",
      "   520        1.2389             nan     0.0010    0.0002\n",
      "   540        1.2358             nan     0.0010    0.0002\n",
      "   560        1.2328             nan     0.0010    0.0002\n",
      "   580        1.2298             nan     0.0010    0.0002\n",
      "   600        1.2270             nan     0.0010    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0008\n",
      "     2        1.3857             nan     0.0010    0.0008\n",
      "     3        1.3850             nan     0.0010    0.0009\n",
      "     4        1.3844             nan     0.0010    0.0007\n",
      "     5        1.3837             nan     0.0010    0.0008\n",
      "     6        1.3830             nan     0.0010    0.0009\n",
      "     7        1.3824             nan     0.0010    0.0008\n",
      "     8        1.3818             nan     0.0010    0.0008\n",
      "     9        1.3811             nan     0.0010    0.0007\n",
      "    10        1.3805             nan     0.0010    0.0008\n",
      "    20        1.3744             nan     0.0010    0.0008\n",
      "    40        1.3627             nan     0.0010    0.0008\n",
      "    60        1.3513             nan     0.0010    0.0005\n",
      "    80        1.3404             nan     0.0010    0.0007\n",
      "   100        1.3302             nan     0.0010    0.0006\n",
      "   120        1.3202             nan     0.0010    0.0006\n",
      "   140        1.3106             nan     0.0010    0.0006\n",
      "   160        1.3016             nan     0.0010    0.0006\n",
      "   180        1.2929             nan     0.0010    0.0006\n",
      "   200        1.2846             nan     0.0010    0.0005\n",
      "   220        1.2767             nan     0.0010    0.0004\n",
      "   240        1.2691             nan     0.0010    0.0004\n",
      "   260        1.2618             nan     0.0010    0.0004\n",
      "   280        1.2547             nan     0.0010    0.0004\n",
      "   300        1.2479             nan     0.0010    0.0004\n",
      "   320        1.2413             nan     0.0010    0.0003\n",
      "   340        1.2349             nan     0.0010    0.0004\n",
      "   360        1.2285             nan     0.0010    0.0003\n",
      "   380        1.2227             nan     0.0010    0.0003\n",
      "   400        1.2169             nan     0.0010    0.0003\n",
      "   420        1.2115             nan     0.0010    0.0002\n",
      "   440        1.2062             nan     0.0010    0.0003\n",
      "   460        1.2010             nan     0.0010    0.0002\n",
      "   480        1.1961             nan     0.0010    0.0003\n",
      "   500        1.1912             nan     0.0010    0.0002\n",
      "   520        1.1865             nan     0.0010    0.0002\n",
      "   540        1.1819             nan     0.0010    0.0002\n",
      "   560        1.1774             nan     0.0010    0.0002\n",
      "   580        1.1731             nan     0.0010    0.0002\n",
      "   600        1.1688             nan     0.0010    0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0010    0.0008\n",
      "     2        1.3856             nan     0.0010    0.0009\n",
      "     3        1.3849             nan     0.0010    0.0009\n",
      "     4        1.3841             nan     0.0010    0.0010\n",
      "     5        1.3833             nan     0.0010    0.0009\n",
      "     6        1.3826             nan     0.0010    0.0009\n",
      "     7        1.3818             nan     0.0010    0.0008\n",
      "     8        1.3811             nan     0.0010    0.0009\n",
      "     9        1.3803             nan     0.0010    0.0007\n",
      "    10        1.3797             nan     0.0010    0.0010\n",
      "    20        1.3724             nan     0.0010    0.0009\n",
      "    40        1.3588             nan     0.0010    0.0009\n",
      "    60        1.3456             nan     0.0010    0.0008\n",
      "    80        1.3329             nan     0.0010    0.0007\n",
      "   100        1.3208             nan     0.0010    0.0006\n",
      "   120        1.3093             nan     0.0010    0.0006\n",
      "   140        1.2982             nan     0.0010    0.0007\n",
      "   160        1.2877             nan     0.0010    0.0007\n",
      "   180        1.2778             nan     0.0010    0.0006\n",
      "   200        1.2679             nan     0.0010    0.0007\n",
      "   220        1.2586             nan     0.0010    0.0005\n",
      "   240        1.2496             nan     0.0010    0.0004\n",
      "   260        1.2409             nan     0.0010    0.0004\n",
      "   280        1.2324             nan     0.0010    0.0004\n",
      "   300        1.2242             nan     0.0010    0.0005\n",
      "   320        1.2165             nan     0.0010    0.0004\n",
      "   340        1.2088             nan     0.0010    0.0004\n",
      "   360        1.2014             nan     0.0010    0.0003\n",
      "   380        1.1944             nan     0.0010    0.0003\n",
      "   400        1.1875             nan     0.0010    0.0002\n",
      "   420        1.1808             nan     0.0010    0.0003\n",
      "   440        1.1744             nan     0.0010    0.0003\n",
      "   460        1.1680             nan     0.0010    0.0003\n",
      "   480        1.1620             nan     0.0010    0.0002\n",
      "   500        1.1561             nan     0.0010    0.0002\n",
      "   520        1.1503             nan     0.0010    0.0001\n",
      "   540        1.1446             nan     0.0010    0.0003\n",
      "   560        1.1391             nan     0.0010    0.0002\n",
      "   580        1.1338             nan     0.0010    0.0002\n",
      "   600        1.1286             nan     0.0010    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0073\n",
      "     2        1.3814             nan     0.0100    0.0064\n",
      "     3        1.3762             nan     0.0100    0.0057\n",
      "     4        1.3722             nan     0.0100    0.0055\n",
      "     5        1.3681             nan     0.0100    0.0063\n",
      "     6        1.3638             nan     0.0100    0.0056\n",
      "     7        1.3601             nan     0.0100    0.0060\n",
      "     8        1.3558             nan     0.0100    0.0060\n",
      "     9        1.3516             nan     0.0100    0.0061\n",
      "    10        1.3477             nan     0.0100    0.0055\n",
      "    20        1.3130             nan     0.0100    0.0047\n",
      "    40        1.2627             nan     0.0100    0.0026\n",
      "    60        1.2292             nan     0.0100    0.0017\n",
      "    80        1.2051             nan     0.0100    0.0007\n",
      "   100        1.1864             nan     0.0100    0.0007\n",
      "   120        1.1709             nan     0.0100    0.0005\n",
      "   140        1.1595             nan     0.0100    0.0005\n",
      "   160        1.1497             nan     0.0100    0.0002\n",
      "   180        1.1411             nan     0.0100   -0.0000\n",
      "   200        1.1336             nan     0.0100   -0.0002\n",
      "   220        1.1272             nan     0.0100   -0.0000\n",
      "   240        1.1208             nan     0.0100   -0.0003\n",
      "   260        1.1149             nan     0.0100   -0.0003\n",
      "   280        1.1096             nan     0.0100   -0.0005\n",
      "   300        1.1047             nan     0.0100   -0.0006\n",
      "   320        1.0999             nan     0.0100   -0.0006\n",
      "   340        1.0954             nan     0.0100   -0.0005\n",
      "   360        1.0915             nan     0.0100   -0.0003\n",
      "   380        1.0877             nan     0.0100   -0.0004\n",
      "   400        1.0835             nan     0.0100   -0.0004\n",
      "   420        1.0795             nan     0.0100   -0.0004\n",
      "   440        1.0756             nan     0.0100   -0.0003\n",
      "   460        1.0722             nan     0.0100   -0.0004\n",
      "   480        1.0689             nan     0.0100   -0.0006\n",
      "   500        1.0659             nan     0.0100   -0.0004\n",
      "   520        1.0631             nan     0.0100   -0.0003\n",
      "   540        1.0601             nan     0.0100   -0.0004\n",
      "   560        1.0573             nan     0.0100   -0.0005\n",
      "   580        1.0545             nan     0.0100   -0.0008\n",
      "   600        1.0518             nan     0.0100   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0079\n",
      "     2        1.3798             nan     0.0100    0.0079\n",
      "     3        1.3729             nan     0.0100    0.0072\n",
      "     4        1.3668             nan     0.0100    0.0082\n",
      "     5        1.3607             nan     0.0100    0.0081\n",
      "     6        1.3544             nan     0.0100    0.0076\n",
      "     7        1.3481             nan     0.0100    0.0070\n",
      "     8        1.3427             nan     0.0100    0.0066\n",
      "     9        1.3372             nan     0.0100    0.0060\n",
      "    10        1.3327             nan     0.0100    0.0061\n",
      "    20        1.2857             nan     0.0100    0.0046\n",
      "    40        1.2173             nan     0.0100    0.0029\n",
      "    60        1.1692             nan     0.0100    0.0013\n",
      "    80        1.1329             nan     0.0100    0.0011\n",
      "   100        1.1032             nan     0.0100    0.0004\n",
      "   120        1.0783             nan     0.0100   -0.0001\n",
      "   140        1.0574             nan     0.0100   -0.0004\n",
      "   160        1.0393             nan     0.0100   -0.0006\n",
      "   180        1.0221             nan     0.0100   -0.0006\n",
      "   200        1.0065             nan     0.0100   -0.0008\n",
      "   220        0.9922             nan     0.0100   -0.0006\n",
      "   240        0.9784             nan     0.0100   -0.0007\n",
      "   260        0.9656             nan     0.0100   -0.0006\n",
      "   280        0.9533             nan     0.0100   -0.0005\n",
      "   300        0.9420             nan     0.0100   -0.0011\n",
      "   320        0.9303             nan     0.0100   -0.0005\n",
      "   340        0.9194             nan     0.0100   -0.0005\n",
      "   360        0.9078             nan     0.0100   -0.0011\n",
      "   380        0.8985             nan     0.0100   -0.0006\n",
      "   400        0.8887             nan     0.0100   -0.0008\n",
      "   420        0.8801             nan     0.0100   -0.0005\n",
      "   440        0.8704             nan     0.0100   -0.0006\n",
      "   460        0.8611             nan     0.0100   -0.0010\n",
      "   480        0.8523             nan     0.0100   -0.0010\n",
      "   500        0.8442             nan     0.0100   -0.0003\n",
      "   520        0.8361             nan     0.0100   -0.0009\n",
      "   540        0.8278             nan     0.0100   -0.0011\n",
      "   560        0.8200             nan     0.0100   -0.0010\n",
      "   580        0.8127             nan     0.0100   -0.0011\n",
      "   600        0.8053             nan     0.0100   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.0100    0.0076\n",
      "     2        1.3796             nan     0.0100    0.0089\n",
      "     3        1.3725             nan     0.0100    0.0076\n",
      "     4        1.3652             nan     0.0100    0.0085\n",
      "     5        1.3579             nan     0.0100    0.0076\n",
      "     6        1.3511             nan     0.0100    0.0081\n",
      "     7        1.3445             nan     0.0100    0.0074\n",
      "     8        1.3376             nan     0.0100    0.0069\n",
      "     9        1.3312             nan     0.0100    0.0067\n",
      "    10        1.3250             nan     0.0100    0.0063\n",
      "    20        1.2710             nan     0.0100    0.0060\n",
      "    40        1.1897             nan     0.0100    0.0029\n",
      "    60        1.1312             nan     0.0100    0.0021\n",
      "    80        1.0856             nan     0.0100    0.0013\n",
      "   100        1.0487             nan     0.0100    0.0003\n",
      "   120        1.0164             nan     0.0100   -0.0002\n",
      "   140        0.9888             nan     0.0100   -0.0006\n",
      "   160        0.9641             nan     0.0100   -0.0004\n",
      "   180        0.9415             nan     0.0100   -0.0014\n",
      "   200        0.9218             nan     0.0100   -0.0008\n",
      "   220        0.9015             nan     0.0100   -0.0016\n",
      "   240        0.8836             nan     0.0100   -0.0013\n",
      "   260        0.8659             nan     0.0100   -0.0012\n",
      "   280        0.8479             nan     0.0100   -0.0005\n",
      "   300        0.8318             nan     0.0100   -0.0007\n",
      "   320        0.8155             nan     0.0100   -0.0016\n",
      "   340        0.8005             nan     0.0100   -0.0006\n",
      "   360        0.7859             nan     0.0100   -0.0012\n",
      "   380        0.7727             nan     0.0100   -0.0014\n",
      "   400        0.7593             nan     0.0100   -0.0006\n",
      "   420        0.7466             nan     0.0100   -0.0008\n",
      "   440        0.7343             nan     0.0100   -0.0014\n",
      "   460        0.7228             nan     0.0100   -0.0010\n",
      "   480        0.7110             nan     0.0100   -0.0006\n",
      "   500        0.6994             nan     0.0100   -0.0010\n",
      "   520        0.6886             nan     0.0100   -0.0009\n",
      "   540        0.6779             nan     0.0100   -0.0013\n",
      "   560        0.6669             nan     0.0100   -0.0009\n",
      "   580        0.6571             nan     0.0100   -0.0016\n",
      "   600        0.6471             nan     0.0100   -0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0626\n",
      "     2        1.3433             nan     0.1000    0.0424\n",
      "     3        1.3059             nan     0.1000    0.0369\n",
      "     4        1.2800             nan     0.1000    0.0221\n",
      "     5        1.2612             nan     0.1000    0.0210\n",
      "     6        1.2443             nan     0.1000    0.0187\n",
      "     7        1.2298             nan     0.1000    0.0150\n",
      "     8        1.2153             nan     0.1000    0.0082\n",
      "     9        1.2051             nan     0.1000    0.0078\n",
      "    10        1.1950             nan     0.1000    0.0065\n",
      "    20        1.1371             nan     0.1000   -0.0030\n",
      "    40        1.0858             nan     0.1000   -0.0029\n",
      "    60        1.0558             nan     0.1000   -0.0040\n",
      "    80        1.0349             nan     0.1000   -0.0046\n",
      "   100        1.0135             nan     0.1000   -0.0071\n",
      "   120        0.9952             nan     0.1000   -0.0065\n",
      "   140        0.9854             nan     0.1000   -0.0052\n",
      "   160        0.9738             nan     0.1000   -0.0045\n",
      "   180        0.9626             nan     0.1000   -0.0071\n",
      "   200        0.9500             nan     0.1000   -0.0094\n",
      "   220        0.9426             nan     0.1000   -0.0086\n",
      "   240        0.9348             nan     0.1000   -0.0074\n",
      "   260        0.9271             nan     0.1000   -0.0064\n",
      "   280        0.9214             nan     0.1000   -0.0063\n",
      "   300        0.9165             nan     0.1000   -0.0073\n",
      "   320        0.9093             nan     0.1000   -0.0082\n",
      "   340        0.9020             nan     0.1000   -0.0045\n",
      "   360        0.8964             nan     0.1000   -0.0080\n",
      "   380        0.8913             nan     0.1000   -0.0087\n",
      "   400        0.8859             nan     0.1000   -0.0057\n",
      "   420        0.8822             nan     0.1000   -0.0048\n",
      "   440        0.8772             nan     0.1000   -0.0051\n",
      "   460        0.8735             nan     0.1000   -0.0075\n",
      "   480        0.8687             nan     0.1000   -0.0065\n",
      "   500        0.8652             nan     0.1000   -0.0111\n",
      "   520        0.8608             nan     0.1000   -0.0073\n",
      "   540        0.8564             nan     0.1000   -0.0056\n",
      "   560        0.8530             nan     0.1000   -0.0059\n",
      "   580        0.8489             nan     0.1000   -0.0049\n",
      "   600        0.8451             nan     0.1000   -0.0066\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0645\n",
      "     2        1.3282             nan     0.1000    0.0529\n",
      "     3        1.2827             nan     0.1000    0.0392\n",
      "     4        1.2475             nan     0.1000    0.0304\n",
      "     5        1.2144             nan     0.1000    0.0246\n",
      "     6        1.1891             nan     0.1000    0.0242\n",
      "     7        1.1675             nan     0.1000    0.0134\n",
      "     8        1.1492             nan     0.1000    0.0096\n",
      "     9        1.1331             nan     0.1000    0.0019\n",
      "    10        1.1183             nan     0.1000    0.0081\n",
      "    20        1.0219             nan     0.1000   -0.0087\n",
      "    40        0.9063             nan     0.1000   -0.0079\n",
      "    60        0.8247             nan     0.1000   -0.0092\n",
      "    80        0.7545             nan     0.1000   -0.0122\n",
      "   100        0.7006             nan     0.1000   -0.0077\n",
      "   120        0.6496             nan     0.1000   -0.0087\n",
      "   140        0.6102             nan     0.1000   -0.0087\n",
      "   160        0.5681             nan     0.1000   -0.0076\n",
      "   180        0.5302             nan     0.1000   -0.0052\n",
      "   200        0.4986             nan     0.1000   -0.0080\n",
      "   220        0.4684             nan     0.1000   -0.0086\n",
      "   240        0.4408             nan     0.1000   -0.0077\n",
      "   260        0.4152             nan     0.1000   -0.0083\n",
      "   280        0.3940             nan     0.1000   -0.0087\n",
      "   300        0.3738             nan     0.1000   -0.0042\n",
      "   320        0.3540             nan     0.1000   -0.0071\n",
      "   340        0.3353             nan     0.1000   -0.0051\n",
      "   360        0.3164             nan     0.1000   -0.0059\n",
      "   380        0.3004             nan     0.1000   -0.0054\n",
      "   400        0.2850             nan     0.1000   -0.0059\n",
      "   420        0.2713             nan     0.1000   -0.0043\n",
      "   440        0.2569             nan     0.1000   -0.0049\n",
      "   460        0.2436             nan     0.1000   -0.0052\n",
      "   480        0.2311             nan     0.1000   -0.0045\n",
      "   500        0.2199             nan     0.1000   -0.0062\n",
      "   520        0.2079             nan     0.1000   -0.0037\n",
      "   540        0.1977             nan     0.1000   -0.0035\n",
      "   560        0.1876             nan     0.1000   -0.0018\n",
      "   580        0.1776             nan     0.1000   -0.0019\n",
      "   600        0.1692             nan     0.1000   -0.0022\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0755\n",
      "     2        1.3192             nan     0.1000    0.0569\n",
      "     3        1.2657             nan     0.1000    0.0409\n",
      "     4        1.2175             nan     0.1000    0.0378\n",
      "     5        1.1793             nan     0.1000    0.0206\n",
      "     6        1.1525             nan     0.1000    0.0139\n",
      "     7        1.1282             nan     0.1000    0.0176\n",
      "     8        1.1030             nan     0.1000    0.0049\n",
      "     9        1.0835             nan     0.1000   -0.0014\n",
      "    10        1.0661             nan     0.1000    0.0107\n",
      "    20        0.9374             nan     0.1000   -0.0042\n",
      "    40        0.7729             nan     0.1000   -0.0128\n",
      "    60        0.6596             nan     0.1000   -0.0145\n",
      "    80        0.5776             nan     0.1000   -0.0155\n",
      "   100        0.5054             nan     0.1000   -0.0088\n",
      "   120        0.4418             nan     0.1000   -0.0049\n",
      "   140        0.3932             nan     0.1000   -0.0071\n",
      "   160        0.3492             nan     0.1000   -0.0119\n",
      "   180        0.3107             nan     0.1000   -0.0073\n",
      "   200        0.2781             nan     0.1000   -0.0082\n",
      "   220        0.2496             nan     0.1000   -0.0046\n",
      "   240        0.2233             nan     0.1000   -0.0040\n",
      "   260        0.2020             nan     0.1000   -0.0036\n",
      "   280        0.1816             nan     0.1000   -0.0049\n",
      "   300        0.1655             nan     0.1000   -0.0036\n",
      "   320        0.1502             nan     0.1000   -0.0042\n",
      "   340        0.1370             nan     0.1000   -0.0036\n",
      "   360        0.1240             nan     0.1000   -0.0041\n",
      "   380        0.1115             nan     0.1000   -0.0029\n",
      "   400        0.1013             nan     0.1000   -0.0023\n",
      "   420        0.0917             nan     0.1000   -0.0017\n",
      "   440        0.0830             nan     0.1000   -0.0023\n",
      "   460        0.0758             nan     0.1000   -0.0018\n",
      "   480        0.0686             nan     0.1000   -0.0018\n",
      "   500        0.0632             nan     0.1000   -0.0022\n",
      "   520        0.0577             nan     0.1000   -0.0015\n",
      "   540        0.0527             nan     0.1000   -0.0010\n",
      "   560        0.0475             nan     0.1000   -0.0007\n",
      "   580        0.0435             nan     0.1000   -0.0010\n",
      "   600        0.0399             nan     0.1000   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3863             nan     0.1000    0.0765\n",
      "     2        1.3152             nan     0.1000    0.0514\n",
      "     3        1.2639             nan     0.1000    0.0430\n",
      "     4        1.2178             nan     0.1000    0.0226\n",
      "     5        1.1856             nan     0.1000    0.0231\n",
      "     6        1.1559             nan     0.1000    0.0201\n",
      "     7        1.1309             nan     0.1000    0.0100\n",
      "     8        1.1098             nan     0.1000   -0.0027\n",
      "     9        1.0902             nan     0.1000    0.0010\n",
      "    10        1.0714             nan     0.1000    0.0008\n",
      "    20        0.9499             nan     0.1000   -0.0083\n",
      "    40        0.7978             nan     0.1000   -0.0105\n",
      "    60        0.6869             nan     0.1000   -0.0175\n",
      "    80        0.6002             nan     0.1000   -0.0091\n",
      "   100        0.5334             nan     0.1000   -0.0144\n",
      "   120        0.4771             nan     0.1000   -0.0057\n",
      "   140        0.4222             nan     0.1000   -0.0088\n",
      "   160        0.3767             nan     0.1000   -0.0088\n",
      "   180        0.3388             nan     0.1000   -0.0047\n",
      "   200        0.3027             nan     0.1000   -0.0073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 4: Stochastic Gradient Boosting\n",
    "set.seed(1)\n",
    "n_folds=10\n",
    "Control=trainControl(method = \"cv\",\n",
    "                           number = n_folds)  \n",
    "#Number of trees are set to 200, 400 and 600\n",
    "#Interaction depth is set to 1, 3, and 5\n",
    "#Learning rate is et to 0.001,0.01,0.1\n",
    "#minobsinnode is set to 10 to avoid underfitting\n",
    "grid_sgb <- expand.grid(n.trees = c(200,400,600), interaction.depth =c(1,3,5),shrinkage = c(0.001,0.01,0.1),n.minobsinnode = 10) \n",
    "\n",
    "sgb_fit = train(class~ ., data=train_set3,\n",
    "                method = 'gbm',\n",
    "                 trControl = Control,\n",
    "                 tuneGrid = grid_sgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stochastic Gradient Boosting \n",
       "\n",
       "750 samples\n",
       " 20 predictor\n",
       "  4 classes: 'A11', 'A12', 'A13', 'A14' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 677, 675, 675, 675, 674, 674, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  shrinkage  interaction.depth  n.trees  Accuracy   Kappa    \n",
       "  0.001      1                  200      0.4749320  0.1924869\n",
       "  0.001      1                  400      0.4828428  0.2036424\n",
       "  0.001      1                  600      0.4802127  0.1995189\n",
       "  0.001      3                  200      0.4934574  0.2237068\n",
       "  0.001      3                  400      0.4961430  0.2286624\n",
       "  0.001      3                  600      0.4961795  0.2293594\n",
       "  0.001      5                  200      0.4988462  0.2353733\n",
       "  0.001      5                  400      0.5013872  0.2392084\n",
       "  0.001      5                  600      0.4987561  0.2362413\n",
       "  0.010      1                  200      0.4814944  0.2026436\n",
       "  0.010      1                  400      0.4908818  0.2226828\n",
       "  0.010      1                  600      0.4815109  0.2137772\n",
       "  0.010      3                  200      0.4934398  0.2297026\n",
       "  0.010      3                  400      0.4905568  0.2341241\n",
       "  0.010      3                  600      0.4973867  0.2475829\n",
       "  0.010      5                  200      0.5133691  0.2650671\n",
       "  0.010      5                  400      0.5027224  0.2575489\n",
       "  0.010      5                  600      0.5093160  0.2696786\n",
       "  0.100      1                  200      0.4760130  0.2206666\n",
       "  0.100      1                  400      0.4880315  0.2425530\n",
       "  0.100      1                  600      0.4774706  0.2306795\n",
       "  0.100      3                  200      0.4934023  0.2568163\n",
       "  0.100      3                  400      0.4879219  0.2501315\n",
       "  0.100      3                  600      0.4587465  0.2093779\n",
       "  0.100      5                  200      0.5176195  0.2897134\n",
       "  0.100      5                  400      0.5013122  0.2664905\n",
       "  0.100      5                  600      0.4907347  0.2538960\n",
       "\n",
       "Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were n.trees = 200, interaction.depth =\n",
       " 5, shrinkage = 0.1 and n.minobsinnode = 10."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgb_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy of sgb at n.trees = 200, interaction.depth = 5, shrinkage = 0.1 and n.minobsinnode = 10.\n",
    "model_forest_accuracy = 0.5176195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAaVBMVEUAAAAAZAAAgP9NRT5N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\nCIBIABAAkQAg4P9gWrtAXh0jEgAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(sgb_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction A11 A12 A13 A14\n",
       "       A11  34  13   5  16\n",
       "       A12  20  18   3  22\n",
       "       A13   2   0   0   1\n",
       "       A14  22  24   4  67\n",
       "\n",
       "Overall Statistics\n",
       "                                         \n",
       "               Accuracy : 0.4741         \n",
       "                 95% CI : (0.411, 0.5379)\n",
       "    No Information Rate : 0.4223         \n",
       "    P-Value [Acc > NIR] : 0.05556        \n",
       "                                         \n",
       "                  Kappa : 0.2073         \n",
       "                                         \n",
       " Mcnemar's Test P-Value : 0.19705        \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: A11 Class: A12 Class: A13 Class: A14\n",
       "Sensitivity              0.4359    0.32727    0.00000     0.6321\n",
       "Specificity              0.8035    0.77041    0.98745     0.6552\n",
       "Pos Pred Value           0.5000    0.28571    0.00000     0.5726\n",
       "Neg Pred Value           0.7596    0.80319    0.95161     0.7090\n",
       "Prevalence               0.3108    0.21912    0.04781     0.4223\n",
       "Detection Rate           0.1355    0.07171    0.00000     0.2669\n",
       "Detection Prevalence     0.2709    0.25100    0.01195     0.4661\n",
       "Balanced Accuracy        0.6197    0.54884    0.49372     0.6436"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prediction by using Stochastic Gradient Boosting\n",
    "predict_sgb = predict(sgb_fit, test_set3 )\n",
    "confusionMatrix(predict_sgb, test_set3$class)\n",
    "cm_3 = confusionMatrix(predict_sgb, test_set3$class)\n",
    "overall_3 <- cm_3$overall\n",
    "overall.accuracy_3 <- overall_3['Accuracy'] \n",
    "comp_sgb = c()\n",
    "comp_sgb[1]=as.numeric(model_forest_accuracy)\n",
    "comp_sgb[2]= as.numeric(overall.accuracy_3)\n",
    "overall.kappa_3 = overall_3['Kappa']\n",
    "overall.pvalue_3 = overall_3['AccuracyPValue']\n",
    "comp_sgb[3] = as.numeric(overall.kappa_3)\n",
    "comp_sgb[4] = as.numeric(overall.pvalue_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Comparison\n",
    "model = c()\n",
    "model[1] = \"Penalized Regression Approaches (PRA)\"\n",
    "model[2] = \"Decision Trees (DT)\"\n",
    "model[3] = \"Random Forests (RF)\"\n",
    "model[4] = \"Stochastic Gradient Boosting (SGB)\"\n",
    "data=matrix(0,4,5)\n",
    "data[,1] = t(model)\n",
    "data[1,2:5] = signif(comp_lasso,digits = 4)\n",
    "data[2,2:5] = signif(comp_tree, digits =4)\n",
    "data[3,2:5] = signif(comp_forest, digits =4)\n",
    "data[4,2:5] = signif(comp_sgb, digits=4)\n",
    "colnames(data) = c('Model','Accuracy of Model', 'Accuracy Calculated from Confusion Matrix', 'Kappa Calculated from Confusion Matrix',  'P-value Calculated from Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Model</th><th scope=col>Accuracy of Model</th><th scope=col>Accuracy Calculated from Confusion Matrix</th><th scope=col>Kappa Calculated from Confusion Matrix</th><th scope=col>P-value Calculated from Confusion Matrix</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Penalized Regression Approaches (PRA)</td><td>0.4822                               </td><td>0.5418                               </td><td>0.308                                </td><td>9.089e-05                            </td></tr>\n",
       "\t<tr><td>Decision Trees (DT)                  </td><td>0.5131                               </td><td>0.5578                               </td><td>0.291                                </td><td>1.075e-05                            </td></tr>\n",
       "\t<tr><td>Random Forests (RF)                  </td><td>0.5401                               </td><td>0.5219                               </td><td>0.2526                               </td><td>0.0009316                            </td></tr>\n",
       "\t<tr><td>Stochastic Gradient Boosting (SGB)   </td><td>0.5176                               </td><td>0.4741                               </td><td>0.2073                               </td><td>0.05556                              </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllll}\n",
       " Model & Accuracy of Model & Accuracy Calculated from Confusion Matrix & Kappa Calculated from Confusion Matrix & P-value Calculated from Confusion Matrix\\\\\n",
       "\\hline\n",
       "\t Penalized Regression Approaches (PRA) & 0.4822                                & 0.5418                                & 0.308                                 & 9.089e-05                            \\\\\n",
       "\t Decision Trees (DT)                   & 0.5131                                & 0.5578                                & 0.291                                 & 1.075e-05                            \\\\\n",
       "\t Random Forests (RF)                   & 0.5401                                & 0.5219                                & 0.2526                                & 0.0009316                            \\\\\n",
       "\t Stochastic Gradient Boosting (SGB)    & 0.5176                                & 0.4741                                & 0.2073                                & 0.05556                              \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Model | Accuracy of Model | Accuracy Calculated from Confusion Matrix | Kappa Calculated from Confusion Matrix | P-value Calculated from Confusion Matrix |\n",
       "|---|---|---|---|---|\n",
       "| Penalized Regression Approaches (PRA) | 0.4822                                | 0.5418                                | 0.308                                 | 9.089e-05                             |\n",
       "| Decision Trees (DT)                   | 0.5131                                | 0.5578                                | 0.291                                 | 1.075e-05                             |\n",
       "| Random Forests (RF)                   | 0.5401                                | 0.5219                                | 0.2526                                | 0.0009316                             |\n",
       "| Stochastic Gradient Boosting (SGB)    | 0.5176                                | 0.4741                                | 0.2073                                | 0.05556                               |\n",
       "\n"
      ],
      "text/plain": [
       "     Model                                 Accuracy of Model\n",
       "[1,] Penalized Regression Approaches (PRA) 0.4822           \n",
       "[2,] Decision Trees (DT)                   0.5131           \n",
       "[3,] Random Forests (RF)                   0.5401           \n",
       "[4,] Stochastic Gradient Boosting (SGB)    0.5176           \n",
       "     Accuracy Calculated from Confusion Matrix\n",
       "[1,] 0.5418                                   \n",
       "[2,] 0.5578                                   \n",
       "[3,] 0.5219                                   \n",
       "[4,] 0.4741                                   \n",
       "     Kappa Calculated from Confusion Matrix\n",
       "[1,] 0.308                                 \n",
       "[2,] 0.291                                 \n",
       "[3,] 0.2526                                \n",
       "[4,] 0.2073                                \n",
       "     P-value Calculated from Confusion Matrix\n",
       "[1,] 9.089e-05                               \n",
       "[2,] 1.075e-05                               \n",
       "[3,] 0.0009316                               \n",
       "[4,] 0.05556                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When four model is compared with each other, random forest approach has highest accuracy in modelling. However, penalized regression approach and decision tree have higher accuracy values when the predicted data compared with the test data. For all cases, it can be said that accuracy of model is low, which is an indication of underfitting. For this reason, accuracy calculated by confusion matrix is also low for each approach. When we look at the kappa values calculated by confusion matrix, it is seen that they are very low. As a conclusion, neither of models are good enough to represent the training data becuse of the accuracy values. Random forest has highest value in accuracy of model. Decision tree approach has the highest accuracy when comparing the predicted values with test data, also it has highest kappa value. For this reason, decision tree can be called as best method for this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
